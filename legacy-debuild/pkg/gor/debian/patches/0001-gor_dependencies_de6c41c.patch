diff -Nur a/src/github.com/bitly/go-hostpool/LICENSE b/src/github.com/bitly/go-hostpool/LICENSE
--- a/src/github.com/bitly/go-hostpool/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/LICENSE	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,21 @@
+The MIT License (MIT)
+
+Copyright (c) 2015 Bitly
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff -Nur a/src/github.com/bitly/go-hostpool/README.md b/src/github.com/bitly/go-hostpool/README.md
--- a/src/github.com/bitly/go-hostpool/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/README.md	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,17 @@
+go-hostpool
+===========
+
+A Go package to intelligently and flexibly pool among multiple hosts from your Go application.
+Host selection can operate in round robin or epsilon greedy mode, and unresponsive hosts are
+avoided.
+Usage example:
+
+```go
+hp := hostpool.NewEpsilonGreedy([]string{"a", "b"}, 0, &hostpool.LinearEpsilonValueCalculator{})
+hostResponse := hp.Get()
+hostname := hostResponse.Host()
+err := _ // (make a request with hostname)
+hostResponse.Mark(err)
+```
+
+View more detailed documentation on [godoc.org](http://godoc.org/github.com/bitly/go-hostpool)
diff -Nur a/src/github.com/bitly/go-hostpool/epsilon_greedy.go b/src/github.com/bitly/go-hostpool/epsilon_greedy.go
--- a/src/github.com/bitly/go-hostpool/epsilon_greedy.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/epsilon_greedy.go	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,205 @@
+package hostpool
+
+import (
+	"log"
+	"math/rand"
+	"time"
+)
+
+type epsilonHostPoolResponse struct {
+	standardHostPoolResponse
+	started time.Time
+	ended   time.Time
+}
+
+func (r *epsilonHostPoolResponse) Mark(err error) {
+	r.Do(func() {
+		r.ended = time.Now()
+		doMark(err, r)
+	})
+}
+
+type epsilonGreedyHostPool struct {
+	standardHostPool               // TODO - would be nifty if we could embed HostPool and Locker interfaces
+	epsilon                float32 // this is our exploration factor
+	decayDuration          time.Duration
+	EpsilonValueCalculator // embed the epsilonValueCalculator
+	timer
+	quit chan bool
+}
+
+// Construct an Epsilon Greedy HostPool
+//
+// Epsilon Greedy is an algorithm that allows HostPool not only to track failure state,
+// but also to learn about "better" options in terms of speed, and to pick from available hosts
+// based on how well they perform. This gives a weighted request rate to better
+// performing hosts, while still distributing requests to all hosts (proportionate to their performance).
+// The interface is the same as the standard HostPool, but be sure to mark the HostResponse immediately
+// after executing the request to the host, as that will stop the implicitly running request timer.
+//
+// A good overview of Epsilon Greedy is here http://stevehanov.ca/blog/index.php?id=132
+//
+// To compute the weighting scores, we perform a weighted average of recent response times, over the course of
+// `decayDuration`. decayDuration may be set to 0 to use the default value of 5 minutes
+// We then use the supplied EpsilonValueCalculator to calculate a score from that weighted average response time.
+func NewEpsilonGreedy(hosts []string, decayDuration time.Duration, calc EpsilonValueCalculator) HostPool {
+
+	if decayDuration <= 0 {
+		decayDuration = defaultDecayDuration
+	}
+	stdHP := New(hosts).(*standardHostPool)
+	p := &epsilonGreedyHostPool{
+		standardHostPool:       *stdHP,
+		epsilon:                float32(initialEpsilon),
+		decayDuration:          decayDuration,
+		EpsilonValueCalculator: calc,
+		timer: &realTimer{},
+		quit:  make(chan bool),
+	}
+
+	// allocate structures
+	for _, h := range p.hostList {
+		h.epsilonCounts = make([]int64, epsilonBuckets)
+		h.epsilonValues = make([]int64, epsilonBuckets)
+	}
+	go p.epsilonGreedyDecay()
+	return p
+}
+
+func (p *epsilonGreedyHostPool) Close() {
+	// No need to do p.quit <- true as close(p.quit) does the trick.
+	close(p.quit)
+}
+
+func (p *epsilonGreedyHostPool) SetEpsilon(newEpsilon float32) {
+	p.Lock()
+	defer p.Unlock()
+	p.epsilon = newEpsilon
+}
+
+func (p *epsilonGreedyHostPool) epsilonGreedyDecay() {
+	durationPerBucket := p.decayDuration / epsilonBuckets
+	ticker := time.NewTicker(durationPerBucket)
+	for {
+		select {
+		case <-p.quit:
+			ticker.Stop()
+			return
+		case <-ticker.C:
+			p.performEpsilonGreedyDecay()
+		}
+	}
+}
+func (p *epsilonGreedyHostPool) performEpsilonGreedyDecay() {
+	p.Lock()
+	for _, h := range p.hostList {
+		h.epsilonIndex += 1
+		h.epsilonIndex = h.epsilonIndex % epsilonBuckets
+		h.epsilonCounts[h.epsilonIndex] = 0
+		h.epsilonValues[h.epsilonIndex] = 0
+	}
+	p.Unlock()
+}
+
+func (p *epsilonGreedyHostPool) Get() HostPoolResponse {
+	p.Lock()
+	defer p.Unlock()
+	host := p.getEpsilonGreedy()
+	started := time.Now()
+	return &epsilonHostPoolResponse{
+		standardHostPoolResponse: standardHostPoolResponse{host: host, pool: p},
+		started:                  started,
+	}
+}
+
+func (p *epsilonGreedyHostPool) getEpsilonGreedy() string {
+	var hostToUse *hostEntry
+
+	// this is our exploration phase
+	if rand.Float32() < p.epsilon {
+		p.epsilon = p.epsilon * epsilonDecay
+		if p.epsilon < minEpsilon {
+			p.epsilon = minEpsilon
+		}
+		return p.getRoundRobin()
+	}
+
+	// calculate values for each host in the 0..1 range (but not ormalized)
+	var possibleHosts []*hostEntry
+	now := time.Now()
+	var sumValues float64
+	for _, h := range p.hostList {
+		if h.canTryHost(now) {
+			v := h.getWeightedAverageResponseTime()
+			if v > 0 {
+				ev := p.CalcValueFromAvgResponseTime(v)
+				h.epsilonValue = ev
+				sumValues += ev
+				possibleHosts = append(possibleHosts, h)
+			}
+		}
+	}
+
+	if len(possibleHosts) != 0 {
+		// now normalize to the 0..1 range to get a percentage
+		for _, h := range possibleHosts {
+			h.epsilonPercentage = h.epsilonValue / sumValues
+		}
+
+		// do a weighted random choice among hosts
+		ceiling := 0.0
+		pickPercentage := rand.Float64()
+		for _, h := range possibleHosts {
+			ceiling += h.epsilonPercentage
+			if pickPercentage <= ceiling {
+				hostToUse = h
+				break
+			}
+		}
+	}
+
+	if hostToUse == nil {
+		if len(possibleHosts) != 0 {
+			log.Println("Failed to randomly choose a host, Dan loses")
+		}
+		return p.getRoundRobin()
+	}
+
+	if hostToUse.dead {
+		hostToUse.willRetryHost(p.maxRetryInterval)
+	}
+	return hostToUse.host
+}
+
+func (p *epsilonGreedyHostPool) markSuccess(hostR HostPoolResponse) {
+	// first do the base markSuccess - a little redundant with host lookup but cleaner than repeating logic
+	p.standardHostPool.markSuccess(hostR)
+	eHostR, ok := hostR.(*epsilonHostPoolResponse)
+	if !ok {
+		log.Printf("Incorrect type in eps markSuccess!") // TODO reflection to print out offending type
+		return
+	}
+	host := eHostR.host
+	duration := p.between(eHostR.started, eHostR.ended)
+
+	p.Lock()
+	defer p.Unlock()
+	h, ok := p.hosts[host]
+	if !ok {
+		log.Fatalf("host %s not in HostPool %v", host, p.Hosts())
+	}
+	h.epsilonCounts[h.epsilonIndex]++
+	h.epsilonValues[h.epsilonIndex] += int64(duration.Seconds() * 1000)
+}
+
+// --- timer: this just exists for testing
+
+type timer interface {
+	between(time.Time, time.Time) time.Duration
+}
+
+type realTimer struct{}
+
+func (rt *realTimer) between(start time.Time, end time.Time) time.Duration {
+	return end.Sub(start)
+}
diff -Nur a/src/github.com/bitly/go-hostpool/epsilon_value_calculators.go b/src/github.com/bitly/go-hostpool/epsilon_value_calculators.go
--- a/src/github.com/bitly/go-hostpool/epsilon_value_calculators.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/epsilon_value_calculators.go	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,40 @@
+package hostpool
+
+// --- Value Calculators -----------------
+
+import (
+	"math"
+)
+
+// --- Definitions -----------------------
+
+// Structs implementing this interface are used to convert the average response time for a host
+// into a score that can be used to weight hosts in the epsilon greedy hostpool. Lower response
+// times should yield higher scores (we want to select the faster hosts more often) The default
+// LinearEpsilonValueCalculator just uses the reciprocal of the response time. In practice, any
+// decreasing function from the positive reals to the positive reals should work.
+type EpsilonValueCalculator interface {
+	CalcValueFromAvgResponseTime(float64) float64
+}
+
+type LinearEpsilonValueCalculator struct{}
+type LogEpsilonValueCalculator struct{ LinearEpsilonValueCalculator }
+type PolynomialEpsilonValueCalculator struct {
+	LinearEpsilonValueCalculator
+	Exp float64 // the exponent to which we will raise the value to reweight
+}
+
+// -------- Methods -----------------------
+
+func (c *LinearEpsilonValueCalculator) CalcValueFromAvgResponseTime(v float64) float64 {
+	return 1.0 / v
+}
+
+func (c *LogEpsilonValueCalculator) CalcValueFromAvgResponseTime(v float64) float64 {
+	// we need to add 1 to v so that this will be defined on all positive floats
+	return c.LinearEpsilonValueCalculator.CalcValueFromAvgResponseTime(math.Log(v + 1.0))
+}
+
+func (c *PolynomialEpsilonValueCalculator) CalcValueFromAvgResponseTime(v float64) float64 {
+	return c.LinearEpsilonValueCalculator.CalcValueFromAvgResponseTime(math.Pow(v, c.Exp))
+}
diff -Nur a/src/github.com/bitly/go-hostpool/example_test.go b/src/github.com/bitly/go-hostpool/example_test.go
--- a/src/github.com/bitly/go-hostpool/example_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/example_test.go	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,13 @@
+package hostpool
+
+import (
+	"github.com/bitly/go-hostpool"
+)
+
+func ExampleNewEpsilonGreedy() {
+	hp := hostpool.NewEpsilonGreedy([]string{"a", "b"}, 0, &hostpool.LinearEpsilonValueCalculator{})
+	hostResponse := hp.Get()
+	hostname := hostResponse.Host()
+	err := nil // (make a request with hostname)
+	hostResponse.Mark(err)
+}
diff -Nur a/src/github.com/bitly/go-hostpool/host_entry.go b/src/github.com/bitly/go-hostpool/host_entry.go
--- a/src/github.com/bitly/go-hostpool/host_entry.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/host_entry.go	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,62 @@
+package hostpool
+
+import (
+	"time"
+)
+
+// --- hostEntry - this is due to get upgraded
+
+type hostEntry struct {
+	host              string
+	nextRetry         time.Time
+	retryCount        int16
+	retryDelay        time.Duration
+	dead              bool
+	epsilonCounts     []int64
+	epsilonValues     []int64
+	epsilonIndex      int
+	epsilonValue      float64
+	epsilonPercentage float64
+}
+
+func (h *hostEntry) canTryHost(now time.Time) bool {
+	if !h.dead {
+		return true
+	}
+	if h.nextRetry.Before(now) {
+		return true
+	}
+	return false
+}
+
+func (h *hostEntry) willRetryHost(maxRetryInterval time.Duration) {
+	h.retryCount += 1
+	newDelay := h.retryDelay * 2
+	if newDelay < maxRetryInterval {
+		h.retryDelay = newDelay
+	} else {
+		h.retryDelay = maxRetryInterval
+	}
+	h.nextRetry = time.Now().Add(h.retryDelay)
+}
+
+func (h *hostEntry) getWeightedAverageResponseTime() float64 {
+	var value float64
+	var lastValue float64
+
+	// start at 1 so we start with the oldest entry
+	for i := 1; i <= epsilonBuckets; i += 1 {
+		pos := (h.epsilonIndex + i) % epsilonBuckets
+		bucketCount := h.epsilonCounts[pos]
+		// Changing the line below to what I think it should be to get the weights right
+		weight := float64(i) / float64(epsilonBuckets)
+		if bucketCount > 0 {
+			currentValue := float64(h.epsilonValues[pos]) / float64(bucketCount)
+			value += currentValue * weight
+			lastValue = currentValue
+		} else {
+			value += lastValue * weight
+		}
+	}
+	return value
+}
diff -Nur a/src/github.com/bitly/go-hostpool/hostpool.go b/src/github.com/bitly/go-hostpool/hostpool.go
--- a/src/github.com/bitly/go-hostpool/hostpool.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/hostpool.go	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,201 @@
+// A Go package to intelligently and flexibly pool among multiple hosts from your Go application.
+// Host selection can operate in round robin or epsilon greedy mode, and unresponsive hosts are
+// avoided. A good overview of Epsilon Greedy is here http://stevehanov.ca/blog/index.php?id=132
+package hostpool
+
+import (
+	"log"
+	"sync"
+	"time"
+)
+
+// Returns current version
+func Version() string {
+	return "0.1"
+}
+
+// --- Response interfaces and structs ----
+
+// This interface represents the response from HostPool. You can retrieve the
+// hostname by calling Host(), and after making a request to the host you should
+// call Mark with any error encountered, which will inform the HostPool issuing
+// the HostPoolResponse of what happened to the request and allow it to update.
+type HostPoolResponse interface {
+	Host() string
+	Mark(error)
+	hostPool() HostPool
+}
+
+type standardHostPoolResponse struct {
+	host string
+	sync.Once
+	pool HostPool
+}
+
+// --- HostPool structs and interfaces ----
+
+// This is the main HostPool interface. Structs implementing this interface
+// allow you to Get a HostPoolResponse (which includes a hostname to use),
+// get the list of all Hosts, and use ResetAll to reset state.
+type HostPool interface {
+	Get() HostPoolResponse
+	// keep the marks separate so we can override independently
+	markSuccess(HostPoolResponse)
+	markFailed(HostPoolResponse)
+
+	ResetAll()
+	Hosts() []string
+
+	// Close the hostpool and release all resources.
+	Close()
+}
+
+type standardHostPool struct {
+	sync.RWMutex
+	hosts             map[string]*hostEntry
+	hostList          []*hostEntry
+	initialRetryDelay time.Duration
+	maxRetryInterval  time.Duration
+	nextHostIndex     int
+}
+
+// ------ constants -------------------
+
+const epsilonBuckets = 120
+const epsilonDecay = 0.90 // decay the exploration rate
+const minEpsilon = 0.01   // explore one percent of the time
+const initialEpsilon = 0.3
+const defaultDecayDuration = time.Duration(5) * time.Minute
+
+// Construct a basic HostPool using the hostnames provided
+func New(hosts []string) HostPool {
+	p := &standardHostPool{
+		hosts:             make(map[string]*hostEntry, len(hosts)),
+		hostList:          make([]*hostEntry, len(hosts)),
+		initialRetryDelay: time.Duration(30) * time.Second,
+		maxRetryInterval:  time.Duration(900) * time.Second,
+	}
+
+	for i, h := range hosts {
+		e := &hostEntry{
+			host:       h,
+			retryDelay: p.initialRetryDelay,
+		}
+		p.hosts[h] = e
+		p.hostList[i] = e
+	}
+
+	return p
+}
+
+func (r *standardHostPoolResponse) Host() string {
+	return r.host
+}
+
+func (r *standardHostPoolResponse) hostPool() HostPool {
+	return r.pool
+}
+
+func (r *standardHostPoolResponse) Mark(err error) {
+	r.Do(func() {
+		doMark(err, r)
+	})
+}
+
+func doMark(err error, r HostPoolResponse) {
+	if err == nil {
+		r.hostPool().markSuccess(r)
+	} else {
+		r.hostPool().markFailed(r)
+	}
+}
+
+// return an entry from the HostPool
+func (p *standardHostPool) Get() HostPoolResponse {
+	p.Lock()
+	defer p.Unlock()
+	host := p.getRoundRobin()
+	return &standardHostPoolResponse{host: host, pool: p}
+}
+
+func (p *standardHostPool) getRoundRobin() string {
+	now := time.Now()
+	hostCount := len(p.hostList)
+	for i := range p.hostList {
+		// iterate via sequenece from where we last iterated
+		currentIndex := (i + p.nextHostIndex) % hostCount
+
+		h := p.hostList[currentIndex]
+		if !h.dead {
+			p.nextHostIndex = currentIndex + 1
+			return h.host
+		}
+		if h.nextRetry.Before(now) {
+			h.willRetryHost(p.maxRetryInterval)
+			p.nextHostIndex = currentIndex + 1
+			return h.host
+		}
+	}
+
+	// all hosts are down. re-add them
+	p.doResetAll()
+	p.nextHostIndex = 0
+	return p.hostList[0].host
+}
+
+func (p *standardHostPool) ResetAll() {
+	p.Lock()
+	defer p.Unlock()
+	p.doResetAll()
+}
+
+// this actually performs the logic to reset,
+// and should only be called when the lock has
+// already been acquired
+func (p *standardHostPool) doResetAll() {
+	for _, h := range p.hosts {
+		h.dead = false
+	}
+}
+
+func (p *standardHostPool) Close() {
+	for _, h := range p.hosts {
+		h.dead = true
+	}
+}
+
+func (p *standardHostPool) markSuccess(hostR HostPoolResponse) {
+	host := hostR.Host()
+	p.Lock()
+	defer p.Unlock()
+
+	h, ok := p.hosts[host]
+	if !ok {
+		log.Fatalf("host %s not in HostPool %v", host, p.Hosts())
+	}
+	h.dead = false
+}
+
+func (p *standardHostPool) markFailed(hostR HostPoolResponse) {
+	host := hostR.Host()
+	p.Lock()
+	defer p.Unlock()
+	h, ok := p.hosts[host]
+	if !ok {
+		log.Fatalf("host %s not in HostPool %v", host, p.Hosts())
+	}
+	if !h.dead {
+		h.dead = true
+		h.retryCount = 0
+		h.retryDelay = p.initialRetryDelay
+		h.nextRetry = time.Now().Add(h.retryDelay)
+	}
+
+}
+func (p *standardHostPool) Hosts() []string {
+	hosts := make([]string, 0, len(p.hosts))
+	for host := range p.hosts {
+		hosts = append(hosts, host)
+	}
+	return hosts
+}
diff -Nur a/src/github.com/bitly/go-hostpool/hostpool_test.go b/src/github.com/bitly/go-hostpool/hostpool_test.go
--- a/src/github.com/bitly/go-hostpool/hostpool_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/bitly/go-hostpool/hostpool_test.go	2015-08-10 16:28:39.000000000 +0100
@@ -0,0 +1,145 @@
+package hostpool
+
+import (
+	"errors"
+	"github.com/bmizerany/assert"
+	"io/ioutil"
+	"log"
+	"math/rand"
+	"os"
+	"testing"
+	"time"
+)
+
+func TestHostPool(t *testing.T) {
+	log.SetOutput(ioutil.Discard)
+	defer log.SetOutput(os.Stdout)
+
+	dummyErr := errors.New("Dummy Error")
+
+	p := New([]string{"a", "b", "c"})
+	assert.Equal(t, p.Get().Host(), "a")
+	assert.Equal(t, p.Get().Host(), "b")
+	assert.Equal(t, p.Get().Host(), "c")
+	respA := p.Get()
+	assert.Equal(t, respA.Host(), "a")
+
+	respA.Mark(dummyErr)
+	respB := p.Get()
+	respB.Mark(dummyErr)
+	respC := p.Get()
+	assert.Equal(t, respC.Host(), "c")
+	respC.Mark(nil)
+	// get again, and verify that it's still c
+	assert.Equal(t, p.Get().Host(), "c")
+	// now try to mark b as success; should fail because already marked
+	respB.Mark(nil)
+	assert.Equal(t, p.Get().Host(), "c") // would be b if it were not dead
+	// now restore a
+	respA = &standardHostPoolResponse{host: "a", pool: p}
+	respA.Mark(nil)
+	assert.Equal(t, p.Get().Host(), "a")
+	assert.Equal(t, p.Get().Host(), "c")
+
+	// ensure that we get *something* back when all hosts fail
+	for _, host := range []string{"a", "b", "c"} {
+		response := &standardHostPoolResponse{host: host, pool: p}
+		response.Mark(dummyErr)
+	}
+	resp := p.Get()
+	assert.NotEqual(t, resp, nil)
+}
+
+type mockTimer struct {
+	t int // the time it will always return
+}
+
+func (t *mockTimer) between(start time.Time, end time.Time) time.Duration {
+	return time.Duration(t.t) * time.Millisecond
+}
+
+func TestEpsilonGreedy(t *testing.T) {
+	log.SetOutput(ioutil.Discard)
+	defer log.SetOutput(os.Stdout)
+
+	rand.Seed(10)
+
+	iterations := 12000
+	p := NewEpsilonGreedy([]string{"a", "b"}, 0, &LinearEpsilonValueCalculator{}).(*epsilonGreedyHostPool)
+
+	timings := make(map[string]int64)
+	timings["a"] = 200
+	timings["b"] = 300
+
+	hitCounts := make(map[string]int)
+	hitCounts["a"] = 0
+	hitCounts["b"] = 0
+
+	log.Printf("starting first run (a, b)")
+
+	for i := 0; i < iterations; i += 1 {
+		if i != 0 && i%100 == 0 {
+			p.performEpsilonGreedyDecay()
+		}
+		hostR := p.Get()
+		host := hostR.Host()
+		hitCounts[host]++
+		timing := timings[host]
+		p.timer = &mockTimer{t: int(timing)}
+		hostR.Mark(nil)
+	}
+
+	for host := range hitCounts {
+		log.Printf("host %s hit %d times (%0.2f percent)", host, hitCounts[host], (float64(hitCounts[host])/float64(iterations))*100.0)
+	}
+
+	assert.Equal(t, hitCounts["a"] > hitCounts["b"], true)
+
+	hitCounts["a"] = 0
+	hitCounts["b"] = 0
+	log.Printf("starting second run (b, a)")
+	timings["a"] = 500
+	timings["b"] = 100
+
+	for i := 0; i < iterations; i += 1 {
+		if i != 0 && i%100 == 0 {
+			p.performEpsilonGreedyDecay()
+		}
+		hostR := p.Get()
+		host := hostR.Host()
+		hitCounts[host]++
+		timing := timings[host]
+		p.timer = &mockTimer{t: int(timing)}
+		hostR.Mark(nil)
+	}
+
+	for host := range hitCounts {
+		log.Printf("host %s hit %d times (%0.2f percent)", host, hitCounts[host], (float64(hitCounts[host])/float64(iterations))*100.0)
+	}
+
+	assert.Equal(t, hitCounts["b"] > hitCounts["a"], true)
+}
+
+func BenchmarkEpsilonGreedy(b *testing.B) {
+	b.StopTimer()
+
+	// Make up some response times
+	zipfDist := rand.NewZipf(rand.New(rand.NewSource(0)), 1.1, 5, 5000)
+	timings := make([]uint64, b.N)
+	for i := 0; i < b.N; i++ {
+		timings[i] = zipfDist.Uint64()
+	}
+
+	// Make the hostpool with a few hosts
+	p := NewEpsilonGreedy([]string{"a", "b"}, 0, &LinearEpsilonValueCalculator{}).(*epsilonGreedyHostPool)
+
+	b.StartTimer()
+	for i := 0; i < b.N; i++ {
+		if i != 0 && i%100 == 0 {
+			p.performEpsilonGreedyDecay()
+		}
+		hostR := p.Get()
+		p.timer = &mockTimer{t: int(timings[i])}
+		hostR.Mark(nil)
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/.travis.yml b/src/github.com/buger/elastigo/.travis.yml
--- a/src/github.com/buger/elastigo/.travis.yml	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/.travis.yml	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,16 @@
+language: go
+
+go:
+  - 1.2
+
+install:
+  - wget https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-1.1.0.deb
+  - sudo dpkg -i elasticsearch-1.1.0.deb
+  - sudo service elasticsearch start
+
+script:
+  - cd core
+  - go get -t
+  - go build
+  - go test -v -eshost localhost -loaddata
+  - go install
diff -Nur a/src/github.com/buger/elastigo/HACKING.md b/src/github.com/buger/elastigo/HACKING.md
--- a/src/github.com/buger/elastigo/HACKING.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/HACKING.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,21 @@
+
+Testing
+-----------------
+
+To run tests, this library loads data into an elasticsearch server and tests against that.
+
+See core/test_test.go.   The data set should remain the same as it pulls a known set of github archive data.
+
+usage:
+
+	$cd core
+	
+    $go test -v -host eshost -loaddata # load the data
+    
+    $go test -v -host eshost # without load data, which only needs to run once
+
+Clean out the Elasticsearch index:
+    
+    http -v DELETE http://localhost:9200/github
+    or
+    curl -XDELETE http://localhost:9200/github
diff -Nur a/src/github.com/buger/elastigo/LICENSE b/src/github.com/buger/elastigo/LICENSE
--- a/src/github.com/buger/elastigo/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/LICENSE	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,176 @@
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
\ No newline at end of file
diff -Nur a/src/github.com/buger/elastigo/README.md b/src/github.com/buger/elastigo/README.md
--- a/src/github.com/buger/elastigo/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/README.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,215 @@
+elastigo
+--------
+[![Total views](https://sourcegraph.com/api/repos/github.com/mattbaird/elastigo/counters/views.png)](https://sourcegraph.com/github.com/mattbaird/elastigo)
+
+[![Build Status][1]][2]
+
+[1]: https://drone.io/github.com/mattbaird/elastigo/status.png
+[2]: https://drone.io/github.com/mattbaird/elastigo/latest
+
+
+A Go (Golang) based Elasticsearch client, implements core api for Indexing and searching.   GoDoc http://godoc.org/github.com/mattbaird/elastigo
+
+To get the Chef based Vagrantfile working, be sure to pull like so::
+
+    # This will pull submodules.
+    git clone --recursive git@github.com:mattbaird/elastigo.git
+
+It's easier to use the ElasticSearch provided Docker image found here: https://github.com/dockerfile/elasticsearch
+
+Non-persistent usage is:
+```bash
+docker run -d -p 9200:9200 -p 9300:9300 dockerfile/elasticsearch
+```
+
+Quick Start with Docker
+=======================
+Make sure docker is installed. If you are running docker on a mac, you must expose ports 9200 and 9300. Shut down docker:
+```bash
+boot2docker stop
+```
+and run
+```bash
+for i in {9200..9300}; do
+ VBoxManage modifyvm "boot2docker-vm" --natpf1 "tcp-port$i,tcp,,$i,,$i";
+ VBoxManage modifyvm "boot2docker-vm" --natpf1 "udp-port$i,udp,,$i,,$i";
+done
+```
+The following will allow you to get the code, and run the tests against your docker based non-persistent elasticsearch:
+
+```bash
+docker run -d -p 9200:9200 -p 9300:9300 dockerfile/elasticsearch
+git clone git@github.com:mattbaird/elastigo.git
+cd elastigo
+go get -u ./...
+cd core
+go test -v -host localhost -loaddata
+cd ..
+go test -v ./...
+```
+
+status updates
+========================
+
+* *2014-5-21* Note: Drone.io tests are failing, I don't know why because the build and tests are working fine for me on my ubuntu box running the docker elasticsearch image. It's possible there is a timing issue. Any Ideas?
+* *2013-9-27* Fleshing out cluster and indices APIs, updated vagrant image to 0.90.3
+* *2013-7-10* Improvements/changes to bulk indexer (includes breaking changes to support TTL),
+         Search dsl supports And/Or/Not
+    * *SearchDsl* should still be considered beta at this
+         point, there will be minor breaking changes as more of the
+         elasticsearch feature set is implemented.
+* *2013-1-26* expansion of search dsl for greater coverage
+* *2012-12-30* new bulk indexing and search dsl
+* *2012-10-12* early in development, not ready for production yet.
+
+
+Adding content to Elasticsearch
+----------------------------------------------
+
+examples:
+```go
+import "github.com/buger/elastigo/api"
+import "github.com/buger/elastigo/core"
+
+type Tweet struct {
+  User     string    `json:"user"`
+  Message  string    `json:"message"`
+}
+
+// Set the Elasticsearch Host to Connect to
+api.Domain = "localhost"
+// api.Port = "9300"
+
+// add single go struct entity
+response, _ := core.Index("twitter", "tweet", "1", nil, Tweet{"kimchy", "Search is cool"})
+
+// you have bytes
+tw := Tweet{"kimchy", "Search is cool part 2"}
+bytesLine, err := json.Marshal(tw)
+response, _ := core.Index("twitter", "tweet", "2", nil, bytesLine)
+
+// Bulk Indexing
+t := time.Now()
+core.IndexBulk("twitter", "tweet", "3", &t, Tweet{"kimchy", "Search is now cooler"})
+
+// Search Using Raw json String
+searchJson := `{
+    "query" : {
+        "term" : { "user" : "kimchy" }
+    }
+}`
+out, err := core.SearchRequest(true, "twitter", "tweet", searchJson, "")
+if len(out.Hits.Hits) == 1 {
+  fmt.Println(string(out.Hits.Hits[0].Source))
+}
+```
+
+Search DSL Examples
+-------------------------
+
+A Faceted, ranged Search using the `Search DSL` :
+
+```go
+import "github.com/buger/elastigo/api"
+import "github.com/buger/elastigo/core"
+
+// Set the Elasticsearch Host to Connect to
+api.Domain = "localhost"
+// api.Port = "9300"
+
+out, err := Search("github").Size("1").Facet(
+  Facet().Fields("actor").Size("500"),
+).Query(
+  Query().Range(
+     Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+  ).Search("add"),
+).Result()
+```
+
+A Ranged Search using the `Search DSL` :
+
+```go
+out, err := Search("github").Type("Issues").Pretty().Query(
+  Query().Range(
+     Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+  ).Search("add"),
+).Result()
+```
+
+A Simple Search using the `Search DSL` :
+
+```go
+out, err := Search("github").Type("Issues").Size("100").Search("add").Result()
+```
+
+A Direct Search using the api :
+
+```go
+qry := map[string]interface{}{
+  "query":map[string]interface{}{
+     "term":map[string]string{"user:"kimchy"},
+  },
+}
+core.SearchRequest(true, "github", "Issues", qry, "", 0)
+```
+
+A Direct Search using the query string Api :
+
+```go
+core.SearchUri("github", "Issues", "user:kimchy", "", 0)
+```
+
+A Filtered search `Search DSL` :
+
+```go
+out, err := Search("github").Filter(
+  Filter().Exists("repository.name"),
+).Result()
+```
+
+Adding content to Elasticsearch in Bulk
+----------------------------------------------
+
+example:
+
+```go
+import "github.com/buger/elastigo/api"
+import "github.com/buger/elastigo/core"
+
+// Set the Elasticsearch Host to Connect to
+api.Domain = "localhost"
+// api.Port = "9300"
+
+indexer := core.NewBulkIndexerErrors(10, 60)
+done := make(chan bool)
+indexer.Run(done)
+
+go func() {
+  for errBuf := range indexer.ErrorChannel {
+    // just blissfully print errors forever
+    fmt.Println(errBuf.Err)
+  }
+}()
+for i := 0; i < 20; i++ {
+  indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`, false)
+}
+done <- true
+// Indexing might take a while. So make sure the program runs
+// a little longer when trying this in main.
+```
+
+license
+=======
+    Copyright 2012 Matthew Baird, Aaron Raddon, and more!
+
+    Licensed under the Apache License, Version 2.0 (the "License");
+    you may not use this file except in compliance with the License.
+    You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+    Unless required by applicable law or agreed to in writing, software
+    distributed under the License is distributed on an "AS IS" BASIS,
+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+    See the License for the specific language governing permissions and
+    limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/Vagrantfile b/src/github.com/buger/elastigo/Vagrantfile
--- a/src/github.com/buger/elastigo/Vagrantfile	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/Vagrantfile	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,29 @@
+# -*- mode: ruby -*-
+# vi: set ft=ruby :
+
+Vagrant.configure("2") do |config|
+  config.vm.box = "lucid64"
+  config.vm.box_url = "http://files.vagrantup.com/lucid64.box"
+  config.vm.network :forwarded_port, guest: 9300, host: 9300, auto_correct: true
+  config.vm.provision :shell, :inline => "gem install chef --version 10.26.0 --no-rdoc --no-ri --conservative"
+
+  config.vm.provider :virtualbox do |vb|
+    vb.gui = false
+    vb.customize ["modifyvm", :id, "--memory", "1024"]
+    vb.customize ["modifyvm", :id, "--cpus", "1"]
+    # This allows symlinks to be created within the /vagrant root directory, 
+    # which is something librarian-puppet needs to be able to do. This might
+    # be enabled by default depending on what version of VirtualBox is used.
+    vb.customize ["setextradata", :id, "VBoxInternal2/SharedFoldersEnableSymlinksCreate/v-root", "1"]
+  end
+  config.vm.provision :chef_solo do |chef|
+    chef.cookbooks_path = "cookbooks"
+    chef.add_recipe("apt")
+    chef.add_recipe("java")
+    chef.add_recipe("elasticsearch")
+    chef.add_recipe("git")
+    chef.add_recipe("mercurial")
+    chef.add_recipe("build-essential")
+    chef.add_recipe("golang")
+  end
+end
\ No newline at end of file
diff -Nur a/src/github.com/buger/elastigo/api/baseRequest.go b/src/github.com/buger/elastigo/api/baseRequest.go
--- a/src/github.com/buger/elastigo/api/baseRequest.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/baseRequest.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,120 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import (
+	"encoding/json"
+	"fmt"
+	"io"
+	"log"
+	"time"
+)
+
+func DoCommand(method string, url string, args map[string]interface{}, data interface{}) ([]byte, error) {
+	var response map[string]interface{}
+	var body []byte
+	var httpStatusCode int
+
+	query, err := QueryString(args)
+	if err != nil {
+		return nil, err
+	}
+	req, err := ElasticSearchRequest(method, url, query)
+	if err != nil {
+		return body, err
+	}
+
+	if data != nil {
+		switch v := data.(type) {
+		case string:
+			req.SetBodyString(v)
+		case io.Reader:
+			req.SetBody(v)
+		case []byte:
+			req.SetBodyBytes(v)
+		default:
+			err = req.SetBodyJson(v)
+			if err != nil {
+				return body, err
+			}
+		}
+
+	}
+	httpStatusCode, body, err = req.Do(&response)
+
+	if err != nil {
+		return body, err
+	}
+	if httpStatusCode > 304 {
+
+		jsonErr := json.Unmarshal(body, &response)
+		if jsonErr == nil {
+			if res_err, ok := response["error"]; ok {
+				status, _ := response["status"]
+				return body, ESError{time.Now(), fmt.Sprintf("Error [%s] Status [%v]", res_err, status), httpStatusCode}
+			}
+		}
+		return body, jsonErr
+	}
+	return body, nil
+}
+
+// ESError is an error implementation that includes a time, message, and code.
+type ESError struct {
+	When time.Time
+	What string
+	Code int
+}
+
+func (e ESError) Error() string {
+	return fmt.Sprintf("%v: %v [%v]", e.When, e.What, e.Code)
+}
+
+// Exists allows the caller to check for the existance of a document using HEAD
+// This appears to be broken in the current version of elasticsearch 0.19.10, currently
+// returning nothing
+func Exists(index string, _type string, id string, args map[string]interface{}) (BaseResponse, error) {
+	var response map[string]interface{}
+	var body []byte
+	var url string
+	var retval BaseResponse
+	var httpStatusCode int
+
+	query, err := QueryString(args)
+	if err != nil {
+		return retval, err
+	}
+
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/%s", index, _type, id)
+	} else {
+		url = fmt.Sprintf("/%s/%s", index, id)
+	}
+	req, err := ElasticSearchRequest("HEAD", url, query)
+	if err != nil {
+		// some sort of generic error handler
+	}
+	httpStatusCode, body, err = req.Do(&response)
+	if httpStatusCode > 304 {
+		if error, ok := response["error"]; ok {
+			status, _ := response["status"]
+			log.Printf("Error: %v (%v)\n", error, status)
+		}
+	} else {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			log.Println(jsonErr)
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/api/baseResponse.go b/src/github.com/buger/elastigo/api/baseResponse.go
--- a/src/github.com/buger/elastigo/api/baseResponse.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/baseResponse.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,59 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import ()
+
+type BaseResponse struct {
+	Ok      bool        `json:"ok"`
+	Index   string      `json:"_index,omitempty"`
+	Type    string      `json:"_type,omitempty"`
+	Id      string      `json:"_id,omitempty"`
+	Source  interface{} `json:"_source,omitempty"` // depends on the schema you've defined
+	Version int         `json:"_version,omitempty"`
+	Found   bool        `json:"found,omitempty"`
+	Exists  bool        `json:"exists,omitempty"`
+	Matches []string    `json:"matches,omitempty"` // percolate matches
+}
+
+type ExtendedStatus struct {
+	Ok           bool   `json:"ok"`
+	ShardsStatus Status `json:"_shards"`
+}
+
+type Status struct {
+	Total      int `json:"total"`
+	Successful int `json:"successful"`
+	Failed     int `json:"failed"`
+}
+
+type Match struct {
+	OK          bool        `json:"ok"`
+	Matches     []string    `json:"matches"`
+	Explanation Explanation `json:"explanation,omitempty"`
+}
+
+type Explanation struct {
+	Value       float32       `json:"value"`
+	Description string        `json:"description"`
+	Details     []Explanation `json:"details,omitempty"`
+}
+
+func Scroll(duration string) string {
+	scrollString := ""
+	if duration != "" {
+		scrollString = "&scroll=" + duration
+	}
+	return scrollString
+}
+
+// http://www.elasticsearch.org/guide/reference/api/search/search-type/
diff -Nur a/src/github.com/buger/elastigo/api/clusterhealthresponses.go b/src/github.com/buger/elastigo/api/clusterhealthresponses.go
--- a/src/github.com/buger/elastigo/api/clusterhealthresponses.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/clusterhealthresponses.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,41 @@
+package api
+
+type ClusterHealthResponse struct {
+	ClusterName         string `json:"cluster_name"`
+	Status              string `json:"status"`
+	TimedOut            bool   `json:"timed_out"`
+	NumberOfNodes       int    `json:"number_of_nodes"`
+	NumberOfDataNodes   int    `json:"number_of_data_nodes"`
+	ActivePrimaryShards int    `json:"active_primary_shards"`
+	ActiveShards        int    `json:"active_shards"`
+	RelocatingShards    int    `json:"relocating_shards"`
+	InitializingShards  int    `json:"initializing_shards"`
+	UnassignedShards    int    `json:"unassigned_shards"`
+}
+
+type ClusterStateResponse struct {
+	ClusterName string                             `json:"cluster_name"`
+	MasterNode  string                             `json:"master_node"`
+	Nodes       map[string]ClusterStateNodeReponse `json:"nodes"`
+	// TODO: Metadata
+	// TODO: Routing Table
+	// TODO: Routing Nodes
+	// TODO: Allocations
+
+}
+
+type ClusterStateNodeReponse struct {
+	Name             string `json:"name"`
+	TransportAddress string `json:"transport_address"`
+	// TODO: Attributes
+}
+
+type ClusterStateMetadataResponse struct {
+	// TODO: templates
+	// TODO: indices
+}
+
+type ClusterStateRoutingTableResponse struct {
+	// TODO: unassigned
+	//
+}
diff -Nur a/src/github.com/buger/elastigo/api/clusterstatresponses.go b/src/github.com/buger/elastigo/api/clusterstatresponses.go
--- a/src/github.com/buger/elastigo/api/clusterstatresponses.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/clusterstatresponses.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,168 @@
+package api
+
+type NodeStatsReponse struct {
+	ClusterName string `json:"cluster_name"`
+	Nodes       map[string]NodeStatsNodeResponse
+}
+type NodeStatsNodeResponse struct {
+	Name             string                                     `json:"name"`
+	Timestamp        int64                                      `json:"timestamp"`
+	TransportAddress string                                     `json:"transport_address"`
+	Hostname         string                                     `json:"hostname"`
+	Indices          NodeStatsIndicesResponse                   `json:"indices"`
+	OS               NodeStatsOSResponse                        `json:"os"`
+	Network          NodeStatsNetworkResponse                   `json:"network"`
+	ThreadPool       map[string]NodeStatsThreadPoolPoolResponse `json:"thread_pool"`
+}
+
+type NodeStatsNetworkResponse struct {
+	TCP NodeStatsTCPResponse `json:"tcp"`
+}
+
+type NodeStatsTransportResponse struct {
+	ServerOpen int64 `json:"server_open"`
+	RxCount    int64 `json:"rx_count"`
+	RxSize     int64 `json:"rx_size_in_bytes"`
+	TxCount    int64 `json:"tx_count"`
+	TxSize     int64 `json:"tx_size_in_bytes"`
+}
+
+type NodeStatsThreadPoolPoolResponse struct {
+	Threads   int64 `json:"threads"`
+	Queue     int64 `json:"queue"`
+	Active    int64 `json:"active"`
+	Rejected  int64 `json:"rejected"`
+	Largest   int64 `json:"largest"`
+	Completed int64 `json:"completed"`
+}
+
+type NodeStatsTCPResponse struct {
+	ActiveOpens  int64 `json:"active_opens"`
+	PassiveOpens int64 `json:"passive_opens"`
+	CurrEstab    int64 `json:"curr_estab"`
+	InSegs       int64 `json:"in_segs"`
+	OutSegs      int64 `json:"out_segs"`
+	RetransSegs  int64 `json:"retrans_segs"`
+	EstabResets  int64 `json:"estab_resets"`
+	AttemptFails int64 `json:"attempt_fails"`
+	InErrs       int64 `json:"in_errs"`
+	OutRsts      int64 `json:"out_rsts"`
+}
+
+type NodeStatsIndicesResponse struct {
+	Docs     NodeStatsIndicesDocsResponse
+	Store    NodeStatsIndicesStoreResponse
+	Indexing NodeStatsIndicesIndexingResponse
+	Get      NodeStatsIndicesGetResponse
+	Search   NodeStatsIndicesSearchResponse
+}
+
+type NodeStatsIndicesDocsResponse struct {
+	Count   int64 `json:"count"`
+	Deleted int64 `json:"deleted"`
+}
+
+type NodeStatsIndicesStoreResponse struct {
+	Size         int64 `json:"size_in_bytes"`
+	ThrottleTime int64 `json:"throttle_time_in_millis"`
+}
+
+type NodeStatsIndicesIndexingResponse struct {
+	IndexTotal    int64 `json:"index_total"`
+	IndexTime     int64 `json:"index_time_in_millis"`
+	IndexCurrent  int64 `json:"index_current"`
+	DeleteTotal   int64 `json:"delete_total"`
+	DeleteTime    int64 `json:"delete_time_in_millis"`
+	DeleteCurrent int64 `json:"delete_current"`
+}
+
+type NodeStatsIndicesGetResponse struct {
+	Total        int64 `json:"total"`
+	Time         int64 `json:"time_in_millis"`
+	ExistsTotal  int64 `json:"exists_total"`
+	ExistsTime   int64 `json:"exists_time_in_millis"`
+	MissingTotal int64 `json:"missing_total"`
+	MissingTime  int64 `json:"missing_time_in_millis"`
+	Current      int64 `json:"current"`
+}
+
+type NodeStatsIndicesSearchResponse struct {
+	OpenContext  int64 `json:"open_contexts"`
+	QueryTotal   int64 `json:"query_total"`
+	QueryTime    int64 `json:"query_time_in_millis"`
+	QueryCurrent int64 `json:"query_current"`
+	FetchTotal   int64 `json:"fetch_total"`
+	FetchTime    int64 `json:"fetch_time_in_millis"`
+	FetchCurrent int64 `json:"fetch_current"`
+}
+
+type NodeStatsOSResponse struct {
+	Timestamp int64                   `json:"timestamp"`
+	Uptime    int64                   `json:"uptime_in_millis"`
+	LoadAvg   []float64               `json:"load_average"`
+	CPU       NodeStatsOSCPUResponse  `json:"cpu"`
+	Mem       NodeStatsOSMemResponse  `json:"mem"`
+	Swap      NodeStatsOSSwapResponse `json:"swap"`
+}
+
+type NodeStatsOSMemResponse struct {
+	Free       int64 `json:"free_in_bytes"`
+	Used       int64 `json:"used_in_bytes"`
+	ActualFree int64 `json:"actual_free_in_bytes"`
+	ActualUsed int64 `json:"actual_used_in_bytes"`
+}
+
+type NodeStatsOSSwapResponse struct {
+	Used int64 `json:"used_in_bytes"`
+	Free int64 `json:"free_in_bytes"`
+}
+
+type NodeStatsOSCPUResponse struct {
+	Sys   int64 `json:"sys"`
+	User  int64 `json:"user"`
+	Idle  int64 `json:"idle"`
+	Steal int64 `json:"stolen"`
+}
+
+type NodeStatsProcessResponse struct {
+	Timestamp int64                       `json:"timestamp"`
+	OpenFD    int64                       `json:"open_file_descriptors"`
+	CPU       NodeStatsProcessCPUResponse `json:"cpu"`
+	Memory    NodeStatsProcessMemResponse `json:"mem"`
+}
+
+type NodeStatsProcessMemResponse struct {
+	Resident     int64 `json:"resident_in_bytes"`
+	Share        int64 `json:"share_in_bytes"`
+	TotalVirtual int64 `json:"total_virtual_in_bytes"`
+}
+
+type NodeStatsProcessCPUResponse struct {
+	Percent int64 `json:"percent"`
+	Sys     int64 `json:"sys_in_millis"`
+	User    int64 `json:"user_in_millis"`
+	Total   int64 `json:"total_in_millis"`
+}
+
+type NodeStatsHTTPResponse struct {
+	CurrentOpen int64 `json:"current_open"`
+	TotalOpen   int64 `json:"total_open"`
+}
+
+type NodeStatsFSResponse struct {
+	Timestamp int64                              `json:"timestamp"`
+	Data      map[string]NodeStatsFSDataResponse `json:"data"`
+}
+
+type NodeStatsFSDataResponse struct {
+	Path          string `json:"path"`
+	Mount         string `json:"mount"`
+	Device        string `json:"dev"`
+	Total         int64  `json:"total_in_bytes"`
+	Free          int64  `json:"free_in_bytes"`
+	Available     int64  `json:"available_in_bytes"`
+	DiskReads     int64  `json:"disk_reads"`
+	DiskWrites    int64  `json:"disk_writes"`
+	DiskReadSize  int64  `json:"disk_read_size_in_bytes"`
+	DiskWriteSize int64  `json:"disk_write_size_in_bytes"`
+}
diff -Nur a/src/github.com/buger/elastigo/api/request.go b/src/github.com/buger/elastigo/api/request.go
--- a/src/github.com/buger/elastigo/api/request.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/request.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,235 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import (
+        "bytes"
+        "encoding/json"
+        "fmt"
+        hostpool "github.com/bitly/go-hostpool"
+        "io"
+        "io/ioutil"
+        "log"
+        "net/http"
+        "net/url"
+        "runtime"
+        "strconv"
+        "strings"
+        "sync"
+        "time"
+)
+
+type Request struct {
+        *http.Request
+        hostResponse hostpool.HostPoolResponse
+}
+
+const (
+        Version         = "0.0.2"
+        DefaultProtocol = "http"
+        DefaultDomain   = "localhost"
+        DefaultPort     = "9200"
+        // A decay duration of zero results in the default behaviour
+        DefaultDecayDuration = 0
+)
+
+var (
+        _ = log.Ldate
+        // Maintain these for backwards compatibility
+        Protocol       string    = DefaultProtocol
+        Domain         string    = DefaultDomain
+        ClusterDomains [1]string = [1]string{DefaultDomain}
+        Port           string    = DefaultPort
+        Username       string
+        Password       string
+        // Store a slice of hosts in a hostpool
+        Hosts []string
+        hp    hostpool.HostPool
+        once  sync.Once
+
+        // To compute the weighting scores, we perform a weighted average of recent response times,
+        // over the course of `DecayDuration`. DecayDuration may be set to 0 to use the default
+        // value of 5 minutes. The EpsilonValueCalculator uses this to calculate a score
+        // from the weighted average response time.
+        DecayDuration time.Duration = time.Duration(DefaultDecayDuration * time.Second)
+)
+
+func ElasticSearchRequest(method, path, query string) (*Request, error) {
+        // Setup the hostpool on our first run
+        once.Do(initializeHostPool)
+
+        // Get a host from the host pool
+        hr := hp.Get()
+
+        // Get the final host and port
+        host, portNum := splitHostnamePartsFromHost(hr.Host(), Port)
+
+        // Build request
+        var uri string
+        // If query parameters are provided, the add them to the URL,
+        // otherwise, leave them out
+        if len(query) > 0 {
+                uri = fmt.Sprintf("%s://%s:%s%s?%s", Protocol, host, portNum, path, query)
+        } else {
+                uri = fmt.Sprintf("%s://%s:%s%s", Protocol, host, portNum, path)
+        }
+        req, err := http.NewRequest(method, uri, nil)
+        if err != nil {
+                return nil, err
+        }
+        req.Header.Add("Accept", "application/json")
+        req.Header.Add("User-Agent", "elasticSearch/"+Version+" ("+runtime.GOOS+"-"+runtime.GOARCH+")")
+
+        if Username != "" || Password != "" {
+                req.SetBasicAuth(Username, Password)
+        }
+
+        newRequest := &Request{
+                Request:      req,
+                hostResponse: hr,
+        }
+        return newRequest, nil
+}
+
+func SetHosts(newhosts []string) {
+
+        // Store the new host list
+        Hosts = newhosts
+
+        // Reinitialise the host pool
+        // Pretty naive as this will nuke the current hostpool, and therefore reset any scoring
+        initializeHostPool()
+
+}
+
+func (r *Request) SetBodyJson(data interface{}) error {
+        body, err := json.Marshal(data)
+        if err != nil {
+                return err
+        }
+        r.SetBodyBytes(body)
+        r.Header.Set("Content-Type", "application/json")
+        return nil
+}
+
+func (r *Request) SetBodyString(body string) {
+        r.SetBody(strings.NewReader(body))
+}
+
+func (r *Request) SetBodyBytes(body []byte) {
+        r.SetBody(bytes.NewReader(body))
+}
+
+func (r *Request) SetBody(body io.Reader) {
+        rc, ok := body.(io.ReadCloser)
+        if !ok && body != nil {
+                rc = ioutil.NopCloser(body)
+        }
+        r.Body = rc
+        if body != nil {
+                switch v := body.(type) {
+                case *strings.Reader:
+                        r.ContentLength = int64(v.Len())
+                case *bytes.Reader:
+                        r.ContentLength = int64(v.Len())
+                }
+        }
+}
+
+func (r *Request) Do(v interface{}) (int, []byte, error) {
+        response, bodyBytes, err := r.DoResponse(v)
+        if err != nil {
+                return -1, nil, err
+        }
+        return response.StatusCode, bodyBytes, err
+}
+
+func (r *Request) DoResponse(v interface{}) (*http.Response, []byte, error) {
+        res, err := http.DefaultClient.Do(r.Request)
+        // Inform the HostPool of what happened to the request and allow it to update
+        r.hostResponse.Mark(err)
+        if err != nil {
+                return nil, nil, err
+        }
+
+        defer res.Body.Close()
+        bodyBytes, err := ioutil.ReadAll(res.Body)
+
+        if err != nil {
+                return nil, nil, err
+        }
+
+        if res.StatusCode > 304 && v != nil {
+                jsonErr := json.Unmarshal(bodyBytes, v)
+                if jsonErr != nil {
+                        return nil, nil, jsonErr
+                }
+        }
+        return res, bodyBytes, err
+}
+
+func QueryString(args map[string]interface{}) (s string, err error) {
+        vals := url.Values{}
+        for key, val := range args {
+                switch v := val.(type) {
+                case string:
+                        vals.Add(key, v)
+                case bool:
+                        vals.Add(key, strconv.FormatBool(v))
+                case int, int32, int64:
+                        vals.Add(key, strconv.Itoa(v.(int)))
+                case float32, float64:
+                        vals.Add(key, strconv.FormatFloat(v.(float64), 'f', -1, 64))
+                case []string:
+                        vals.Add(key, strings.Join(v, ","))
+                default:
+                        err = fmt.Errorf("Could not format URL argument: %s", key)
+                        return
+                }
+        }
+        s = vals.Encode()
+        return
+}
+
+// Set up the host pool to be used
+func initializeHostPool() {
+
+        // If no hosts are set, fallback to defaults
+        if len(Hosts) == 0 {
+                Hosts = append(Hosts, fmt.Sprintf("%s:%s", Domain, Port))
+        }
+
+        // Epsilon Greedy is an algorithm that allows HostPool not only to track failure state,
+        // but also to learn about "better" options in terms of speed, and to pick from available hosts
+        // based on how well they perform. This gives a weighted request rate to better
+        // performing hosts, while still distributing requests to all hosts (proportionate to their performance).
+        // The interface is the same as the standard HostPool, but be sure to mark the HostResponse immediately
+        // after executing the request to the host, as that will stop the implicitly running request timer.
+        //
+        // A good overview of Epsilon Greedy is here http://stevehanov.ca/blog/index.php?id=132
+
+        hp = hostpool.NewEpsilonGreedy(Hosts, DecayDuration, &hostpool.LinearEpsilonValueCalculator{})
+
+}
+
+// Split apart the hostname on colon
+// Return the host and a default port if there is no separator
+func splitHostnamePartsFromHost(fullHost string, defaultPortNum string) (string, string) {
+
+        h := strings.Split(fullHost, ":")
+
+        if len(h) == 2 {
+                return h[0], h[1]
+        }
+
+        return h[0], defaultPortNum
+}
diff -Nur a/src/github.com/buger/elastigo/api/request_test.go b/src/github.com/buger/elastigo/api/request_test.go
--- a/src/github.com/buger/elastigo/api/request_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/request_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,59 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License"); // you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+import (
+	"fmt"
+	"testing"
+
+	"github.com/bmizerany/assert"
+)
+
+func TestQueryString(t *testing.T) {
+	// Test nil argument
+	s, err := QueryString(nil)
+	assert.T(t, s == "" && err == nil, fmt.Sprintf("Nil should not fail and yield empty string"))
+
+	// Test single string argument
+	s, err = QueryString(map[string]interface{}{"foo": "bar"})
+	exp := "foo=bar"
+	assert.T(t, s == exp && err == nil, fmt.Sprintf("Expected %s, got: %s", exp, s))
+
+	// Test single int argument
+	s, err = QueryString(map[string]interface{}{"foo": 1})
+	exp = "foo=1"
+	assert.T(t, s == exp && err == nil, fmt.Sprintf("Expected %s, got: %s", exp, s))
+
+	// Test single float argument
+	s, err = QueryString(map[string]interface{}{"foo": 3.141592})
+	exp = "foo=3.141592"
+	assert.T(t, s == exp && err == nil, fmt.Sprintf("Expected %s, got: %s", exp, s))
+
+	// Test single []string argument
+	s, err = QueryString(map[string]interface{}{"foo": []string{"bar", "baz"}})
+	exp = "foo=bar%2Cbaz"
+	assert.T(t, s == exp && err == nil, fmt.Sprintf("Expected %s, got: %s", exp, s))
+
+	// Test combination of all arguments
+	s, err = QueryString(map[string]interface{}{
+		"foo":  "bar",
+		"bar":  1,
+		"baz":  3.141592,
+		"test": []string{"a", "b"},
+	})
+	// url.Values also orders arguments alphabetically.
+	exp = "bar=1&baz=3.141592&foo=bar&test=a%2Cb"
+	assert.T(t, s == exp && err == nil, fmt.Sprintf("Expected %s, got: %s", exp, s))
+
+	// Test invalid datatype
+	s, err = QueryString(map[string]interface{}{"foo": []int{}})
+	assert.T(t, err != nil, fmt.Sprintf("Expected err to not be nil"))
+}
diff -Nur a/src/github.com/buger/elastigo/api/searchdsl.go b/src/github.com/buger/elastigo/api/searchdsl.go
--- a/src/github.com/buger/elastigo/api/searchdsl.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/searchdsl.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,31 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+type SearchRequest struct {
+	From   int    `json:"from,omitempty"`
+	Size   int    `json:"size,omitempty"`
+	Query  Query  `json:"query,omitempty"`
+	Filter Filter `json:"filter,omitempty"`
+}
+
+type Filter struct {
+	Term Term `json:"term"`
+}
+
+type Facets struct {
+	Tag Terms `json:"tag"`
+}
+
+type Terms struct {
+	Terms string `json:"terms"`
+}
diff -Nur a/src/github.com/buger/elastigo/api/shared.go b/src/github.com/buger/elastigo/api/shared.go
--- a/src/github.com/buger/elastigo/api/shared.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/api/shared.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,24 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package api
+
+type Query struct {
+	Query Term `json:"query"`
+}
+
+type Term struct {
+	Term string `json:"term"`
+}
+
+func (q Query) setQuery(query string) {
+	q.Query.Term = query
+}
diff -Nur a/src/github.com/buger/elastigo/client.go b/src/github.com/buger/elastigo/client.go
--- a/src/github.com/buger/elastigo/client.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/client.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,86 @@
+// Copyright 2012 Matthew Baird
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+package main
+
+import (
+	"encoding/json"
+	"flag"
+	"github.com/buger/elastigo/api"
+	"github.com/buger/elastigo/cluster"
+	"github.com/buger/elastigo/core"
+	"github.com/buger/elastigo/indices"
+	"log"
+	"time"
+)
+
+var (
+	eshost *string = flag.String("host", "localhost", "Elasticsearch Server Host Address")
+)
+
+// for testing
+func main() {
+	flag.Parse()
+	log.SetFlags(log.Ltime | log.Lshortfile)
+	api.Domain = *eshost
+	core.VerboseLogging = true
+	response, _ := core.Index("twitter", "tweet", "1", nil, NewTweet("kimchy", "Search is cool"))
+	indices.Flush()
+	log.Printf("Index OK: %v", response.Ok)
+	searchresponse, err := core.SearchRequest("twitter", "tweet", nil, "{\"query\" : {\"term\" : { \"user\" : \"kimchy\" }}}")
+	if err != nil {
+		log.Println("error during search:" + err.Error())
+		log.Fatal(err)
+	}
+	// try marshalling to tweet type
+	var t Tweet
+	bytes, err := searchresponse.Hits.Hits[0].Source.MarshalJSON()
+	if err != nil {
+		log.Fatalf("err calling marshalJson:%v", err)
+	}
+	json.Unmarshal(bytes, t)
+	log.Printf("Search Found: %s", t)
+	response, _ = core.Get("twitter", "tweet", "1", nil)
+	log.Printf("Get: %v", response.Exists)
+	exists, _ := core.Exists("twitter", "tweet", "1", nil)
+	log.Printf("Exists: %v", exists)
+	indices.Flush()
+	countResponse, _ := core.Count("twitter", "tweet", nil)
+	log.Printf("Count: %v", countResponse.Count)
+	response, _ = core.Delete("twitter", "tweet", "1", map[string]interface{}{"version": -1, "routing": ""})
+	log.Printf("Delete OK: %v", response.Ok)
+	response, _ = core.Get("twitter", "tweet", "1", nil)
+	log.Printf("Get: %v", response.Exists)
+
+	healthResponse, _ := cluster.Health()
+	log.Printf("Health: %v", healthResponse.Status)
+
+	cluster.UpdateSettings("transient", "discovery.zen.minimum_master_nodes", 2)
+
+}
+
+// used in test suite, chosen to be similar to the documentation
+type Tweet struct {
+	User     string    `json:"user"`
+	PostDate time.Time `json:"postDate"`
+	Message  string    `json:"message"`
+}
+
+func NewTweet(user string, message string) Tweet {
+	return Tweet{User: user, PostDate: time.Now(), Message: message}
+}
+
+func (t *Tweet) String() string {
+	b, _ := json.Marshal(t)
+	return string(b)
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/clusterreroute.go b/src/github.com/buger/elastigo/cluster/clusterreroute.go
--- a/src/github.com/buger/elastigo/cluster/clusterreroute.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/clusterreroute.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,84 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// The cluster health API allows to get a very simple status on the health of the cluster.
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-health.html
+// information returned. Defaults to cluster.)
+func Reroute(dryRun bool, commands Commands) (api.ClusterHealthResponse, error) {
+	var url string
+	var retval api.ClusterHealthResponse
+
+	if len(commands.Commands) > 0 {
+		url = fmt.Sprintf("/_cluster/reroute%s&%s", dryRunOption(dryRun))
+	} else {
+		return retval, errors.New("Must pass at least one command")
+	}
+	m := map[string]interface{}{"commands": commands.Commands}
+	body, err := api.DoCommand("POST", url, m, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func dryRunOption(isDryRun bool) string {
+	if isDryRun {
+		return "dry_run"
+	} else {
+		return ""
+	}
+	return ""
+}
+
+// supported commands are
+// move (index, shard, from_node, to_node)
+// cancel (index, shard, node, allow_primary)
+// allocate (index, shard, node, allow_primary)
+
+type Commands struct {
+	Commands []interface{} `json:"commands"`
+}
+
+type MoveCommand struct {
+	Index    string `json:"index"`
+	Shard    string `json:"shard"`
+	FromNode string `json:"from_node"`
+	ToNode   string `json:"to_node"`
+}
+
+type CancelCommand struct {
+	Index        string `json:"index"`
+	Shard        string `json:"shard"`
+	Node         string `json:"node"`
+	AllowPrimary bool   `json:"allow_primary,omitempty"`
+}
+type AllocateCommand struct {
+	Index        string `json:"index"`
+	Shard        string `json:"shard"`
+	Node         string `json:"node"`
+	AllowPrimary bool   `json:"allow_primary,omitempty"`
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/health.go b/src/github.com/buger/elastigo/cluster/health.go
--- a/src/github.com/buger/elastigo/cluster/health.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/health.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,104 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+package cluster
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// The cluster health API allows to get a very simple status on the health of the cluster.
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-health.html
+// TODO: implement wait_for_status, timeout, wait_for_relocating_shards, wait_for_nodes
+// TODO: implement level (Can be one of cluster, indices or shards. Controls the details level of the health
+// information returned. Defaults to cluster.)
+func Health(indices ...string) (api.ClusterHealthResponse, error) {
+	var url string
+	var retval api.ClusterHealthResponse
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/_cluster/health/%s", strings.Join(indices, ","))
+	} else {
+		url = "/_cluster/health"
+	}
+	body, err := api.DoCommand("GET", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	//fmt.Println(body)
+	return retval, err
+}
+
+type ClusterStateFilter struct {
+	FilterNodes        bool
+	FilterRoutingTable bool
+	FilterMetadata     bool
+	FilterBlocks       bool
+	FilterIndices      []string
+}
+
+func (f ClusterStateFilter) Parameterize() []string {
+	var parts []string
+
+	if f.FilterNodes {
+		parts = append(parts, "filter_nodes=true")
+	}
+
+	if f.FilterRoutingTable {
+		parts = append(parts, "filter_routing_table=true")
+	}
+
+	if f.FilterMetadata {
+		parts = append(parts, "filter_metadata=true")
+	}
+
+	if f.FilterBlocks {
+		parts = append(parts, "filter_blocks=true")
+	}
+
+	if f.FilterIndices != nil && len(f.FilterIndices) > 0 {
+		parts = append(parts, strings.Join([]string{"filter_indices=", strings.Join(f.FilterIndices, ",")}, ""))
+	}
+
+	return parts
+}
+
+func ClusterState(filter ClusterStateFilter) (api.ClusterStateResponse, error) {
+	var parameters []string
+	var url string
+	var retval api.ClusterStateResponse
+
+	parameters = filter.Parameterize()
+
+	url = fmt.Sprintf("/_cluster/state?%s", strings.Join(parameters, "&"))
+
+	body, err := api.DoCommand("GET", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/nodesHotThreads.go b/src/github.com/buger/elastigo/cluster/nodesHotThreads.go
--- a/src/github.com/buger/elastigo/cluster/nodesHotThreads.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/nodesHotThreads.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
diff -Nur a/src/github.com/buger/elastigo/cluster/nodesInfo.go b/src/github.com/buger/elastigo/cluster/nodesInfo.go
--- a/src/github.com/buger/elastigo/cluster/nodesInfo.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/nodesInfo.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,186 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+package cluster
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// The cluster nodes info API allows to retrieve one or more (or all) of the cluster nodes information.
+// informatino can be one of jvm, process
+func AllNodesInfo() (NodeInfo, error) {
+	return NodesInfo([]string{"_all"}, "_all")
+}
+
+func NodesInfo(information []string, nodes ...string) (NodeInfo, error) {
+	var url string
+	var retval NodeInfo
+	url = fmt.Sprintf("/_nodes/%s/%s", strings.Join(nodes, ","), strings.Join(information, ","))
+	body, err := api.DoCommand("GET", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type NodeInfo struct {
+	ClusterName string          `json:"cluster_name"`
+	Nodes       map[string]Node `json:"nodes"` // node name is random string
+}
+
+type Node struct {
+	Name             string      `json:"name,omitempty"`
+	TransportAddress string      `json:"transport_address,omitempty"`
+	Host             string      `json:"host,omitempty"`
+	Ip               string      `json:"ip,omitempty"`
+	Version          string      `json:"version,omitempty"`
+	Build            string      `json:"build,omitempty"`
+	Hostname         string      `json:"hostname,omitempty"`
+	HttpAddress      string      `json:"http_address,omitempty"`
+	Settings         *Settings   `json:"settings,omitempty"`
+	OS               *OS         `json:"os,omitempty"`
+	Process          *Process    `json:"process,omitempty"`
+	JVM              *JVM        `json:"jvm,omitempty"`
+	ThreadPool       *ThreadPool `json:"thread_pool,omitempty"`
+	Network          *Network    `json:"network,omitempty"`
+	Transport        *Transport  `json:"transport,omitempty"`
+	Http             *Http       `json:"http,omitempty"`
+	Plugins          []*Plugin   `json:"plugins,omitempty"`
+}
+
+type Settings struct {
+	Path       *Path  `json:"path,omitempty"`
+	Foreground string `json:"foreground,omitempty"`
+	Name       string `json:"name,omitempty"`
+}
+
+type Path struct {
+	Logs string `json:"logs,omitempty"`
+	home string `json:"home,omitempty"`
+}
+
+type Cluster struct {
+	Name string `json:"name"`
+}
+
+type OS struct {
+	RefreshInterval     int `json:"refresh_interval,omitempty"`
+	AvailableProcessors int `json:"available_processors,omitempty"`
+}
+
+type CPU struct {
+	Vendor           string `json:"vendor,omitempty"`
+	Model            string `json:"model,omitempty"`
+	Mhz              int    `json:"mhz,omitempty"`
+	TotalCores       int    `json:"total_cores,omitempty"`
+	TotalSockets     int    `json:"total_sockets,omitempty"`
+	CoresPerSocket   int    `json:"cores_per_socket,omitempty"`
+	CacheSizeInBytes int    `json:"cache_size_in_bytes,omitempty"`
+}
+
+type MEM struct {
+	TotalInBytes int `json:"total_in_bytes,omitempty"`
+}
+
+type SWAP struct {
+	TotalInBytes int `json:"total_in_bytes,omitempty"`
+}
+
+type Process struct {
+	RefreshInterval    int  `json:"refresh_interval,omitempty"`
+	Id                 int  `json:"id,omitempty"`
+	MaxFileDescriptors int  `json:"max_file_descriptors,omitempty"`
+	Mlockall           bool `json:"mlockall,omitempty"`
+}
+
+type JVM struct {
+	Pid          int      `json:"pid,omitempty"`
+	Version      string   `json:"version,omitempty"`
+	VMName       string   `json:"vm_name,omitempty"`
+	VMVersion    string   `json:"vm_version,omitempty"`
+	VMVendor     string   `json:"vm_vendor,omitempty"`
+	StartTime    int      `json:"start_time,omitempty"`
+	Mem          *JvmMem  `json:"mem,omitempty"`
+	GcCollectors []string `json:"gc_collectors,omitempty"`
+	MemoryPools  []string `json:"memory_pools,omitempty"`
+}
+
+type JvmMem struct {
+	HeapInitInBytes    int `json:"heap_init_in_bytes,omitempty"`
+	HeapMaxInBytes     int `json:"heap_max_in_bytes,omitempty"`
+	NonHeapInitInBytes int `json:"non_heap_init_in_bytes,omitempty"`
+	NonHeapMaxInBytes  int `json:"non_heap_max_in_bytes,omitempty"`
+	DirectMaxInBytes   int `json:"direct_max_in_bytes,omitempty"`
+}
+
+type ThreadPool struct {
+	Generic    *ThreadPoolConfig `json:"generic,omitempty"`
+	Index      *ThreadPoolConfig `json:"index,omitempty"`
+	Get        *ThreadPoolConfig `json:"get,omitempty"`
+	Snapshot   *ThreadPoolConfig `json:"snapshot,omitempty"`
+	Merge      *ThreadPoolConfig `json:"merge,omitempty"`
+	Suggest    *ThreadPoolConfig `json:"suggest,omitempty"`
+	Bulk       *ThreadPoolConfig `json:"bulk,omitempty"`
+	Optimize   *ThreadPoolConfig `json:"optimize,omitempty"`
+	Warmer     *ThreadPoolConfig `json:"warmer,omitempty"`
+	Flush      *ThreadPoolConfig `json:"flush,omitempty"`
+	Search     *ThreadPoolConfig `json:"search,omitempty"`
+	Percolate  *ThreadPoolConfig `json:"percolate,omitempty"`
+	Management *ThreadPoolConfig `json:"management,omitempty"`
+	Refresh    *ThreadPoolConfig `json:"refresh,omitempty"`
+}
+
+type ThreadPoolConfig struct {
+	Type      string `json:"type,omitempty"`
+	Min       int    `json:"min,omitempty"`
+	Max       int    `json:"max,omitempty"`
+	QueueSize string `json:"queue_size,omitempty"`
+	KeepAlive string `json:"keep_alive,omitempty"`
+}
+
+type Network struct {
+	RefreshInterval  int        `json:"refresh_interval,omitempty"`
+	PrimaryInterface *Interface `json:"primary_interface,omitempty"`
+}
+
+type Interface struct {
+	Address    string `json:"address,omitempty"`
+	Name       string `json:"name,omitempty"`
+	MacAddress string `json:"mac_address,omitempty"`
+}
+
+type Transport struct {
+	BoundAddress   string `json:"bound_address,omitempty"`
+	PublishAddress string `json:"publish_address,omitempty"`
+}
+
+type Http struct {
+	BoundAddress   string `json:"bound_address,omitempty"`
+	PublishAddress string `json:"publish_address,omitempty"`
+}
+
+type Plugin struct {
+	Name        string `json:"name,omitempty"`
+	Description string `json:"description,omitempty"`
+	Site        bool   `json:"site,omitempty"`
+	Jvm         bool   `json:"jvm,omitempty"`
+	Url         string `json:"url,omitempty"`
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/nodesShutdown.go b/src/github.com/buger/elastigo/cluster/nodesShutdown.go
--- a/src/github.com/buger/elastigo/cluster/nodesShutdown.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/nodesShutdown.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,38 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"net/url"
+	"strconv"
+	"strings"
+)
+
+// NodesShutdown allows the caller to shutdown between one and all nodes in the cluster
+// delay is a integer representing number of seconds
+// passing "" or "_all" for the nodes parameter will shut down all nodes
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-nodes-shutdown/
+func NodesShutdown(delay int, nodes ...string) error {
+	shutdownUrl := fmt.Sprintf("/_cluster/nodes/%s/_shutdown", strings.Join(nodes, ","))
+	if delay > 0 {
+		var values url.Values = url.Values{}
+		values.Add("delay", strconv.Itoa(delay))
+		shutdownUrl += "?" + values.Encode()
+	}
+	_, err := api.DoCommand("POST", shutdownUrl, nil, nil)
+	if err != nil {
+		return err
+	}
+	return nil
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/nodesinfo_test.go b/src/github.com/buger/elastigo/cluster/nodesinfo_test.go
--- a/src/github.com/buger/elastigo/cluster/nodesinfo_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/nodesinfo_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,36 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"fmt"
+	"github.com/bmizerany/assert"
+	"testing"
+)
+
+func TestGetAll(t *testing.T) {
+	nodesInfo, err := AllNodesInfo()
+	//log.Println(out)
+	assert.T(t, err == nil, fmt.Sprintf("should not have gotten error, received :%v", err))
+	assert.T(t, nodesInfo.ClusterName == "elasticsearch", fmt.Sprintf("clustername should have been elasticsearch, received :%v", err))
+	for _, node := range nodesInfo.Nodes {
+		assert.T(t, node.Settings != nil, fmt.Sprintf("Settings should not have been null"))
+		assert.T(t, node.OS != nil, fmt.Sprintf("OS should not have been null"))
+		assert.T(t, node.Process != nil, fmt.Sprintf("Process should not have been null"))
+		assert.T(t, node.JVM != nil, fmt.Sprintf("JVM should not have been null"))
+		assert.T(t, node.ThreadPool != nil, fmt.Sprintf("ThreadPool should not have been null"))
+		assert.T(t, node.Network != nil, fmt.Sprintf("Network should not have been null"))
+		assert.T(t, node.Transport != nil, fmt.Sprintf("Transport should not have been null"))
+		assert.T(t, node.Http != nil, fmt.Sprintf("Http should not have been null"))
+		assert.T(t, node.Plugins != nil, fmt.Sprintf("Plugins should not have been null"))
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/state.go b/src/github.com/buger/elastigo/cluster/state.go
--- a/src/github.com/buger/elastigo/cluster/state.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/state.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,42 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"github.com/buger/elastigo/api"
+)
+
+// State gets the comprehensive state information for the whole cluster
+// see http://www.elasticsearch.org/guide/reference/api/admin-cluster-state/
+func UpdateSetting(args map[string]interface{}, filter_indices ...string) (ClusterStateResponse, error) {
+	var url string
+	var retval ClusterStateResponse
+
+	url = "/_cluster/state"
+
+	body, err := api.DoCommand("GET", url, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type ClusterStateResponse struct {
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/stats.go b/src/github.com/buger/elastigo/cluster/stats.go
--- a/src/github.com/buger/elastigo/cluster/stats.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/stats.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,168 @@
+package cluster
+
+type NodeStatsReponse struct {
+	ClusterName string `json:"cluster_name"`
+	Nodes       map[string]NodeStatsNodeResponse
+}
+type NodeStatsNodeResponse struct {
+	Name             string                                     `json:"name"`
+	Timestamp        int64                                      `json:"timestamp"`
+	TransportAddress string                                     `json:"transport_address"`
+	Hostname         string                                     `json:"hostname"`
+	Indices          NodeStatsIndicesResponse                   `json:"indices"`
+	OS               NodeStatsOSResponse                        `json:"os"`
+	Network          NodeStatsNetworkResponse                   `json:"network"`
+	ThreadPool       map[string]NodeStatsThreadPoolPoolResponse `json:"thread_pool"`
+}
+
+type NodeStatsNetworkResponse struct {
+	TCP NodeStatsTCPResponse `json:"tcp"`
+}
+
+type NodeStatsTransportResponse struct {
+	ServerOpen int64 `json:"server_open"`
+	RxCount    int64 `json:"rx_count"`
+	RxSize     int64 `json:"rx_size_in_bytes"`
+	TxCount    int64 `json:"tx_count"`
+	TxSize     int64 `json:"tx_size_in_bytes"`
+}
+
+type NodeStatsThreadPoolPoolResponse struct {
+	Threads   int64 `json:"threads"`
+	Queue     int64 `json:"queue"`
+	Active    int64 `json:"active"`
+	Rejected  int64 `json:"rejected"`
+	Largest   int64 `json:"largest"`
+	Completed int64 `json:"completed"`
+}
+
+type NodeStatsTCPResponse struct {
+	ActiveOpens  int64 `json:"active_opens"`
+	PassiveOpens int64 `json:"passive_opens"`
+	CurrEstab    int64 `json:"curr_estab"`
+	InSegs       int64 `json:"in_segs"`
+	OutSegs      int64 `json:"out_segs"`
+	RetransSegs  int64 `json:"retrans_segs"`
+	EstabResets  int64 `json:"estab_resets"`
+	AttemptFails int64 `json:"attempt_fails"`
+	InErrs       int64 `json:"in_errs"`
+	OutRsts      int64 `json:"out_rsts"`
+}
+
+type NodeStatsIndicesResponse struct {
+	Docs     NodeStatsIndicesDocsResponse
+	Store    NodeStatsIndicesStoreResponse
+	Indexing NodeStatsIndicesIndexingResponse
+	Get      NodeStatsIndicesGetResponse
+	Search   NodeStatsIndicesStoreResponse
+}
+
+type NodeStatsIndicesDocsResponse struct {
+	Count   int64 `json:"count"`
+	Deleted int64 `json:"deleted"`
+}
+
+type NodeStatsIndicesStoreResponse struct {
+	Size         int64 `json:"size_in_bytes"`
+	ThrottleTime int64 `json:"throttle_time_in_millis"`
+}
+
+type NodeStatsIndicesIndexingResponse struct {
+	IndexTotal    int64 `json:"index_total"`
+	IndexTime     int64 `json:"index_time_in_millis"`
+	IndexCurrent  int64 `json:"index_current"`
+	DeleteTotal   int64 `json:"delete_total"`
+	DeleteTime    int64 `json:"delete_time_in_millis"`
+	DeleteCurrent int64 `json:"delete_current"`
+}
+
+type NodeStatsIndicesGetResponse struct {
+	Total        int64 `json:"total"`
+	Time         int64 `json:"time_in_millis"`
+	ExistsTotal  int64 `json:"exists_total"`
+	ExistsTime   int64 `json:"exists_time_in_millis"`
+	MissingTotal int64 `json:"missing_total"`
+	MissingTime  int64 `json:"missing_time_in_millis"`
+	Current      int64 `json:"current"`
+}
+
+type NodeStatsIndicesSearchResponse struct {
+	OpenContext  int64 `json:"open_contexts"`
+	QueryTotal   int64 `json:"query_total"`
+	QueryTime    int64 `json:"query_time_in_millis"`
+	QueryCurrent int64 `json:"query_current"`
+	FetchTotal   int64 `json:"fetch_total"`
+	FetchTime    int64 `json:"fetch_time_in_millis"`
+	FetchCurrent int64 `json:"fetch_current"`
+}
+
+type NodeStatsOSResponse struct {
+	Timestamp int64                   `json:"timestamp"`
+	Uptime    int64                   `json:"uptime_in_millis"`
+	LoadAvg   []float64               `json:"load_average"`
+	CPU       NodeStatsOSCPUResponse  `json:"cpu"`
+	Mem       NodeStatsOSMemResponse  `json:"mem"`
+	Swap      NodeStatsOSSwapResponse `json:"swap"`
+}
+
+type NodeStatsOSMemResponse struct {
+	Free       int64 `json:"free_in_bytes"`
+	Used       int64 `json:"used_in_bytes"`
+	ActualFree int64 `json:"actual_free_in_bytes"`
+	ActualUsed int64 `json:"actual_used_in_bytes"`
+}
+
+type NodeStatsOSSwapResponse struct {
+	Used int64 `json:"used_in_bytes"`
+	Free int64 `json:"free_in_bytes"`
+}
+
+type NodeStatsOSCPUResponse struct {
+	Sys   int64 `json:"sys"`
+	User  int64 `json:"user"`
+	Idle  int64 `json:"idle"`
+	Steal int64 `json:"stolen"`
+}
+
+type NodeStatsProcessResponse struct {
+	Timestamp int64                       `json:"timestamp"`
+	OpenFD    int64                       `json:"open_file_descriptors"`
+	CPU       NodeStatsProcessCPUResponse `json:"cpu"`
+	Memory    NodeStatsProcessMemResponse `json:"mem"`
+}
+
+type NodeStatsProcessMemResponse struct {
+	Resident     int64 `json:"resident_in_bytes"`
+	Share        int64 `json:"share_in_bytes"`
+	TotalVirtual int64 `json:"total_virtual_in_bytes"`
+}
+
+type NodeStatsProcessCPUResponse struct {
+	Percent int64 `json:"percent"`
+	Sys     int64 `json:"sys_in_millis"`
+	User    int64 `json:"user_in_millis"`
+	Total   int64 `json:"total_in_millis"`
+}
+
+type NodeStatsHTTPResponse struct {
+	CurrentOpen int64 `json:"current_open"`
+	TotalOpen   int64 `json:"total_open"`
+}
+
+type NodeStatsFSResponse struct {
+	Timestamp int64                              `json:"timestamp"`
+	Data      map[string]NodeStatsFSDataResponse `json:"data"`
+}
+
+type NodeStatsFSDataResponse struct {
+	Path          string `json:"path"`
+	Mount         string `json:"mount"`
+	Device        string `json:"dev"`
+	Total         int64  `json:"total_in_bytes"`
+	Free          int64  `json:"free_in_bytes"`
+	Available     int64  `json:"available_in_bytes"`
+	DiskReads     int64  `json:"disk_reads"`
+	DiskWrites    int64  `json:"disk_writes"`
+	DiskReadSize  int64  `json:"disk_read_size_in_bytes"`
+	DiskWriteSize int64  `json:"disk_write_size_in_bytes"`
+}
diff -Nur a/src/github.com/buger/elastigo/cluster/updateSettings.go b/src/github.com/buger/elastigo/cluster/updateSettings.go
--- a/src/github.com/buger/elastigo/cluster/updateSettings.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cluster/updateSettings.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,47 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package cluster
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// UpdateSettings allows to update cluster wide specific settings. Defaults to Transient setting
+// Settings updated can either be persistent (applied cross restarts) or transient (will not survive a full cluster restart).
+// http://www.elasticsearch.org/guide/reference/api/admin-cluster-update-settings.html
+func UpdateSettings(settingType string, key string, value int) (ClusterSettingsResponse, error) {
+	var retval ClusterSettingsResponse
+	if settingType != "transient" && settingType != "persistent" {
+		return retval, fmt.Errorf("settingType must be one of transient or persistent, you passed %s", settingType)
+	}
+	var url string = "/_cluster/state"
+	m := map[string]map[string]int{settingType: map[string]int{key: value}}
+	body, err := api.DoCommand("PUT", url, nil, m)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type ClusterSettingsResponse struct {
+	Transient  map[string]int `json:"transient"`
+	Persistent map[string]int `json:"persistent"`
+}
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/CHANGELOG.md b/src/github.com/buger/elastigo/cookbooks/build-essential/CHANGELOG.md
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/CHANGELOG.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/CHANGELOG.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,15 @@
+## v1.1.2:
+
+* [COOK-1620] - support OS X 10.8
+
+## v1.1.0:
+
+* [COOK-1098] - support amazon linux
+* [COOK-1149] - support Mac OS X
+* [COOK-1296] - allow for compile-time installation of packages
+  through an attribute (see README)
+
+## v1.0.2:
+
+* [COOK-1098] - Add Amazon Linux platform support
+* [COOK-1149] - Add OS X platform support
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/CONTRIBUTING b/src/github.com/buger/elastigo/cookbooks/build-essential/CONTRIBUTING
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/CONTRIBUTING	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/CONTRIBUTING	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,29 @@
+If you would like to contribute, please open a ticket in JIRA:
+
+* http://tickets.opscode.com
+
+Create the ticket in the COOK project and use the cookbook name as the
+component.
+
+For all code contributions, we ask that contributors sign a
+contributor license agreement (CLA). Instructions may be found here:
+
+* http://wiki.opscode.com/display/chef/How+to+Contribute
+
+When contributing changes to individual cookbooks, please do not
+modify the version number in the metadata.rb. Also please do not
+update the CHANGELOG.md for a new version. Not all changes to a
+cookbook may be merged and released in the same versions. Opscode will
+handle the version updates during the release process. You are welcome
+to correct typos or otherwise make updates to documentation in the
+README.
+
+If a contribution adds new platforms or platform versions, indicate
+such in the body of the commit message(s), and update the relevant
+COOK ticket. When writing commit messages, it is helpful for others if
+you indicate the COOK ticket. For example:
+
+    git commit -m '[COOK-1041] Updated pool resource to correctly delete.'
+
+In the ticket itself, it is also helpful if you include log output of
+a successful Chef run, but this is not absolutely required.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/LICENSE b/src/github.com/buger/elastigo/cookbooks/build-essential/LICENSE
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/LICENSE	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/README.md b/src/github.com/buger/elastigo/cookbooks/build-essential/README.md
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/README.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,124 @@
+Description
+===========
+
+Installs packages required for compiling C software from source. Use
+this cookbook if you wish to compile C programs, or install RubyGems
+with native extensions.
+
+Requirements
+============
+
+## Platform
+
+Supported platforms by platform family:
+
+* Linux (debian, rhel, fedora)
+* Darwin (`mac_os_x` 10.6+)
+
+Attributes
+==========
+
+* `node['build_essential']['compiletime']` - Whether the resources in
+the default recipe should be configured at the "Compile" phase of the
+Chef run. Defaults to false, see __Usage__ for more information.
+* `node['build_essential']['osx']['gcc_installer_url']` - The URL of
+  the OS X GCC package installer (.pkg).
+* `node['build_essential']['osx']['gcc_installer_checksum']` - The
+  SHA256 checksum of the OS X GCC installer.
+
+Recipes
+=======
+
+This cookbook has one recipe, default.
+
+On Linux platforms (see __Platform__ above for a supported list of
+families), packages required to build C source projects are installed.
+This includes GCC, make, autconf and others. On Debian-family
+distributions, the apt-cache may need to be updated, especially during
+compile time installation. See __Usage__ for further information.
+
+On Mac OS X, the GCC standalone installer by Kenneth Reitz is
+installed. Note that this is *not* the Xcode CLI package, as that does
+not include all programs and headers required to build some common
+GNU-style C projects, such as those that are available from projects
+such as MacPorts or Homebrew. Changing the attributes for the GCC
+installer URL and checksum to the Xcode values may work, but this is
+untested.
+
+Usage
+=====
+
+Simply include the `build-essential` and the required tools will be
+installed to the system, and later recipes will be able to compile
+software from C source code.
+
+For RubyGems that include native C extensions you wish to use with
+Chef, you should do two things.
+
+0. Ensure that the C libraries, include files and other assorted "dev"
+type packages are installed. You should do this in the compile phase
+after the build-essential recipe.
+1. Use the `chef_gem` resource in your recipes. This requires Chef version 0.10.10+.
+2. Set the `compiletime` attribute in roles where such recipes are
+required. This will ensure that the build tools are available to
+compile the RubyGems' extensions, as `chef_gem` happens during the
+compile phase, too.
+
+Example installation of a devel package at compile-time in a recipe:
+
+    package "mypackage-dev" do
+      action :nothing
+    end.run_action(:install)
+
+Example use of `chef_gem`:
+
+    chef_gem "mygem"
+
+Example role:
+
+    name "myapp"
+    run_list(
+      "recipe[build-essential]",
+      "recipe[myapp]"
+    )
+    default_attributes(
+      "build_essential" => {
+        "compiletime" => true
+      }
+    )
+
+The compile time option (via the attribute) is to ensure that the
+proper packages are available at the right time in the Chef run. It is
+recommended that the build-essential recipe appear early in the run
+list.
+
+The Chef wiki has documentation on
+[the anatomy of a chef run](http://wiki.opscode.com/display/chef/Anatomy+of+a+Chef+Run).
+
+Limitations
+===========
+
+It is not in the scope of this cookbook to handle installing the
+required headers for individual software projects in order to compile
+them, or to compile RubyGems with native C extensions. You should
+create a cookbook for handling that.
+
+License and Author
+==================
+
+Author:: Joshua Timberman (<joshua@opscode.com>)
+Author:: Seth Chisamore (<schisamo@opscode.com>)
+
+Copyright 2009-2011, Opscode, Inc. (<legal@opscode.com>)
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/attributes/default.rb b/src/github.com/buger/elastigo/cookbooks/build-essential/attributes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/attributes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/attributes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,33 @@
+#
+# Cookbook Name:: build-essential
+# Attributes:: default
+#
+# Copyright 2008-2012, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+default['build_essential']['compiletime'] = false
+
+case platform
+when "mac_os_x"
+  case
+  when Chef::VersionConstraint.new("~> 10.7.0").include?(platform_version),
+       Chef::VersionConstraint.new("~> 10.8.0").include?(platform_version)
+    default['build_essential']['osx']['gcc_installer_url'] = "https://github.com/downloads/kennethreitz/osx-gcc-installer/GCC-10.7-v2.pkg"
+    default['build_essential']['osx']['gcc_installer_checksum'] = "df36aa87606feb99d0db9ac9a492819e"
+  when Chef::VersionConstraint.new("~> 10.6.0").include?(platform_version)
+    default['build_essential']['osx']['gcc_installer_url'] = "https://github.com/downloads/kennethreitz/osx-gcc-installer/GCC-10.6.pkg"
+    default['build_essential']['osx']['gcc_installer_checksum'] = "d1db5bab6a3f6b9f3b5577a130baeefa"
+  end
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/metadata.rb b/src/github.com/buger/elastigo/cookbooks/build-essential/metadata.rb
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/metadata.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+maintainer        "Opscode, Inc."
+maintainer_email  "cookbooks@opscode.com"
+license           "Apache 2.0"
+description       "Installs C compiler / build tools"
+version           "1.1.2"
+recipe            "build-essential", "Installs packages required for compiling C software from source."
+
+%w{ fedora redhat centos ubuntu debian amazon }.each do |os|
+  supports os
+end
+
+supports "mac_os_x", ">= 10.6.0"
diff -Nur a/src/github.com/buger/elastigo/cookbooks/build-essential/recipes/default.rb b/src/github.com/buger/elastigo/cookbooks/build-essential/recipes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/build-essential/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/build-essential/recipes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,79 @@
+#
+# Cookbook Name:: build-essential
+# Recipe:: default
+#
+# Copyright 2008-2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+require 'chef/shell_out'
+
+compiletime = node['build_essential']['compiletime']
+
+case node['os']
+when "linux"
+
+  # on apt-based platforms when first provisioning we need to force
+  # apt-get update at compiletime if we are going to try to install at compiletime
+  if node['platform_family'] == "debian"
+    execute "apt-get update" do
+      action :nothing
+      # tip: to suppress this running every time, just use the apt cookbook
+      not_if do
+        ::File.exists?('/var/lib/apt/periodic/update-success-stamp') &&
+        ::File.mtime('/var/lib/apt/periodic/update-success-stamp') > Time.now - 86400*2
+      end
+    end.run_action(:run) if compiletime
+  end
+
+  packages = case node['platform_family']
+    when "debian"
+      %w{build-essential binutils-doc}
+    when "rhel", "fedora"
+      %w{gcc gcc-c++ kernel-devel make}
+    end
+
+  packages.each do |pkg|
+    r = package pkg do
+      action ( compiletime ? :nothing : :install )
+    end
+    r.run_action(:install) if compiletime
+  end
+
+  %w{autoconf flex bison}.each do |pkg|
+    r = package pkg do
+      action ( compiletime ? :nothing : :install )
+    end
+    r.run_action(:install) if compiletime
+  end
+when "darwin"
+  result = Chef::ShellOut.new("pkgutil --pkgs").run_command
+  installed = result.stdout.split("\n").include?("com.apple.pkg.gcc4.2Leo")
+  pkg_filename = File.basename(node['build_essential']['osx']['gcc_installer_url'])
+  pkg_path = "#{Chef::Config[:file_cache_path]}/#{pkg_filename}"
+
+  r = remote_file pkg_path do
+    source node['build_essential']['osx']['gcc_installer_url']
+    checksum node['build_essential']['osx']['gcc_installer_checksum']
+    action ( compiletime ? :nothing : :create )
+    not_if { installed }
+  end
+  r.run_action(:create) if compiletime
+
+  r = execute "sudo installer -pkg \"#{pkg_path}\" -target /" do
+    action ( compiletime ? :nothing : :run )
+    not_if { installed }
+  end
+  r.run_action(:run) if compiletime
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/CHANGELOG.md b/src/github.com/buger/elastigo/cookbooks/git/CHANGELOG.md
--- a/src/github.com/buger/elastigo/cookbooks/git/CHANGELOG.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/CHANGELOG.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,16 @@
+## v1.0.2:
+
+* [COOK-1537] - add recipe for source installation
+
+## v1.0.0:
+
+* [COOK-1152] - Add support for Mac OS X
+* [COOK-1112] - Add support for Windows
+
+## v0.10.0:
+
+* [COOK-853] - Git client installation on CentOS
+
+## v0.9.0:
+
+* Current public release.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/CONTRIBUTING b/src/github.com/buger/elastigo/cookbooks/git/CONTRIBUTING
--- a/src/github.com/buger/elastigo/cookbooks/git/CONTRIBUTING	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/CONTRIBUTING	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,29 @@
+If you would like to contribute, please open a ticket in JIRA:
+
+* http://tickets.opscode.com
+
+Create the ticket in the COOK project and use the cookbook name as the
+component.
+
+For all code contributions, we ask that contributors sign a
+contributor license agreement (CLA). Instructions may be found here:
+
+* http://wiki.opscode.com/display/chef/How+to+Contribute
+
+When contributing changes to individual cookbooks, please do not
+modify the version number in the metadata.rb. Also please do not
+update the CHANGELOG.md for a new version. Not all changes to a
+cookbook may be merged and released in the same versions. Opscode will
+handle the version updates during the release process. You are welcome
+to correct typos or otherwise make updates to documentation in the
+README.
+
+If a contribution adds new platforms or platform versions, indicate
+such in the body of the commit message(s), and update the relevant
+COOK ticket. When writing commit messages, it is helpful for others if
+you indicate the COOK ticket. For example:
+
+    git commit -m '[COOK-1041] Updated pool resource to correctly delete.'
+
+In the ticket itself, it is also helpful if you include log output of
+a successful Chef run, but this is not absolutely required.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/LICENSE b/src/github.com/buger/elastigo/cookbooks/git/LICENSE
--- a/src/github.com/buger/elastigo/cookbooks/git/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/LICENSE	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/README.md b/src/github.com/buger/elastigo/cookbooks/git/README.md
--- a/src/github.com/buger/elastigo/cookbooks/git/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/README.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,62 @@
+Description
+===========
+
+Installs git and optionally sets up a git server as a daemon under runit.
+
+Requirements
+============
+
+## Platform:
+
+* Debian/Ubuntu
+* ArchLinux
+
+## Cookbooks:
+
+* runit
+
+Recipes
+=======
+
+## default
+
+Installs base git packages based on platform.
+
+## server
+
+Sets up a git daemon to provide a server.
+
+## source
+
+Installs git from source.
+
+Usage
+=====
+
+This cookbook primarily installs git core packages. It can also be
+used to serve git repositories.
+
+    include_recipe "git::server"
+
+This creates the directory /srv/git and starts a git daemon, exporting
+all repositories found. Repositories need to be added manually, but
+will be available once they are created.
+
+License and Author
+==================
+
+Author:: Joshua Timberman (<joshua@opscode.com>)
+
+Copyright:: 2009-2012, Opscode, Inc.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/attributes/default.rb b/src/github.com/buger/elastigo/cookbooks/git/attributes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/git/attributes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/attributes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,36 @@
+#
+# Author:: Jamie Winsor (<jamie@vialstudios.com>)
+# Cookbook Name:: git
+# Attributes:: default
+#
+# Copyright 2008-2012, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+case platform_family 
+when 'windows'
+  set[:git][:version] = "1.7.9-preview20120201"
+  set[:git][:url] = "http://msysgit.googlecode.com/files/Git-#{node[:git][:version]}.exe"
+  set[:git][:checksum] = "0627394709375140d1e54e923983d259a60f9d8e"
+when "mac_os_x"
+  default[:git][:osx_dmg][:app_name]    = "git-1.7.9.4-intel-universal-snow-leopard"
+  default[:git][:osx_dmg][:volumes_dir] = "Git 1.7.9.4 Snow Leopard Intel Universal"
+  default[:git][:osx_dmg][:package_id]  = "GitOSX.Installer.git1794.git.pkg"
+  default[:git][:osx_dmg][:url]         = "http://git-osx-installer.googlecode.com/files/git-1.7.9.4-intel-universal-snow-leopard.dmg"
+  default[:git][:osx_dmg][:checksum]    = "661c3fcf765572d3978df17c7636d59e"
+else
+  default[:git][:prefix] = "/usr/local"
+  default[:git][:version] = "1.7.11.4"
+  default[:git][:url] = "https://github.com/git/git/tarball/v#{node[:git][:version]}"
+  default[:git][:checksum] = "7a26d9bd0fd3384374bdc1afaae829f406bc123126817d994a460c49a3260ecc"
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/metadata.rb b/src/github.com/buger/elastigo/cookbooks/git/metadata.rb
--- a/src/github.com/buger/elastigo/cookbooks/git/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/metadata.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,19 @@
+maintainer        "Opscode, Inc."
+maintainer_email  "cookbooks@opscode.com"
+license           "Apache 2.0"
+description       "Installs git and/or sets up a Git server daemon"
+long_description  IO.read(File.join(File.dirname(__FILE__), 'README.md'))
+version           "1.0.2"
+recipe            "git", "Installs git"
+recipe            "git::server", "Sets up a runit_service for git daemon"
+recipe            "git::source", "Installs git from source"
+
+%w{ amazon arch centos debian fedora redhat scientific ubuntu windows }.each do |os|
+  supports os
+end
+
+supports "mac_os_x", ">= 10.6.0"
+
+%w{ build-essential dmg runit yum }.each do |cb|
+  depends cb
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/recipes/default.rb b/src/github.com/buger/elastigo/cookbooks/git/recipes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/git/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/recipes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,47 @@
+#
+# Cookbook Name:: git
+# Recipe:: default
+#
+# Copyright 2008-2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+case node[:platform]
+when "debian", "ubuntu"
+  package "git-core"
+when "centos","redhat","scientific","fedora"
+  case node[:platform_version].to_i
+  when 5
+    include_recipe "yum::epel"
+  end
+  package "git"
+when "windows"
+  windows_package "git" do
+    source node[:git][:url]
+    checksum node[:git][:checksum]
+    action :install
+    not_if { File.exists? 'C:\Program Files (x86)\Git\bin\git.exe' }
+  end
+when "mac_os_x"
+  dmg_package "GitOSX-Installer" do
+    app node[:git][:osx_dmg][:app_name]
+    package_id node[:git][:osx_dmg][:package_id]
+    volumes_dir node[:git][:osx_dmg][:volumes_dir]
+    source node[:git][:osx_dmg][:url]
+    checksum node[:git][:osx_dmg][:checksum]
+    type "pkg"
+    action :install
+  end
+else
+  package "git"
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/recipes/server.rb b/src/github.com/buger/elastigo/cookbooks/git/recipes/server.rb
--- a/src/github.com/buger/elastigo/cookbooks/git/recipes/server.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/recipes/server.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,34 @@
+#
+# Cookbook Name:: git
+# Recipe:: server
+#
+# Copyright 2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+include_recipe "git"
+
+directory "/srv/git" do
+  owner "root"
+  group "root"
+  mode 0755
+end
+
+case node[:platform]
+when "debian", "ubuntu"
+  include_recipe "runit"
+  runit_service "git-daemon"
+else
+  log "Platform requires setting up a git daemon service script."
+  log "Hint: /usr/bin/git daemon --export-all --user=nobody --group=daemon --base-path=/srv/git"
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/recipes/source.rb b/src/github.com/buger/elastigo/cookbooks/git/recipes/source.rb
--- a/src/github.com/buger/elastigo/cookbooks/git/recipes/source.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/recipes/source.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,44 @@
+#
+# Cookbook Name:: git
+# Recipe:: source
+#
+# Copyright 2012, Brian Flad, Fletcher Nichol
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+include_recipe "build-essential"
+
+pkgs = value_for_platform_family(
+  ["rhel"] => %w{ expat-devel gettext-devel libcurl-devel openssl-devel zlib-devel }
+)
+
+pkgs.each do |pkg|
+  package pkg
+end
+
+remote_file "#{Chef::Config[:file_cache_path]}/git-#{node[:git][:version]}.tar.gz" do
+  source    node[:git][:url]
+  checksum  node[:git][:checksum]
+  mode      "0644"
+  not_if "test -f #{Chef::Config[:file_cache_path]}/git-#{node[:git][:version]}.tar.gz"
+end
+
+execute "Extracting and Building Git #{node[:git][:version]} from Source" do
+  cwd Chef::Config[:file_cache_path]
+  command <<-COMMAND
+    (mkdir git-#{node[:git][:version]} && tar -zxf git-#{node[:git][:version]}.tar.gz -C git-#{node[:git][:version]} --strip-components 1)
+    (cd git-#{node[:git][:version]} && make prefix=#{node[:git][:prefix]} install)
+  COMMAND
+  creates "node[:git][:prefix]}/bin/git"
+  not_if "git --version | grep #{node[:git][:version]}"
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb b/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb
--- a/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-log-run.erb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,2 @@
+#!/bin/sh
+exec svlogd -tt ./main
diff -Nur a/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb b/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb
--- a/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/git/templates/default/sv-git-daemon-run.erb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,3 @@
+#!/bin/sh
+exec 2>&1
+exec /usr/bin/git daemon --export-all --user=nobody --group=daemon --base-path=/srv/git /srv/git 
diff -Nur a/src/github.com/buger/elastigo/cookbooks/golang/README.md b/src/github.com/buger/elastigo/cookbooks/golang/README.md
--- a/src/github.com/buger/elastigo/cookbooks/golang/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/golang/README.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,29 @@
+# Go Language Chef Cookbook
+
+This is an OpsCode Chef cookbook for [Go, the programming language](http://golang.org).
+
+It uses the ["Todd Vierling" Ubuntu PPA](https://launchpad.net/~duh/+archive/golang)
+and allows you to tweak version using Chef node attributes.
+
+It is released under the [Apache Public License 2.0](http://www.apache.org/licenses/LICENSE-2.0.html).
+
+
+## Recipes
+
+Main recipe is `golang::default`.
+
+## Supported OSes
+
+Ubuntu 10.10 to 12.04, will likely work just as well on Debian unstable.
+
+
+## Dependencies
+
+None.
+
+
+## Copyright & License
+
+Matthew Baird, 2013.
+
+Released under the [Apache Public License 2.0](http://www.apache.org/licenses/LICENSE-2.0.html).
diff -Nur a/src/github.com/buger/elastigo/cookbooks/golang/attributes/default.rb b/src/github.com/buger/elastigo/cookbooks/golang/attributes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/golang/attributes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/golang/attributes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,11 @@
+default[:golang] = {
+  # can be "stable" or "tip"
+  :version => "stable",
+  :multi => {
+    :versions => %w(go1.0.3 go1.1.1),
+    :default_version  => "go1.1.1",
+    :aliases => {
+      "go1" => "go1.1.1"
+    }
+  }
+}
diff -Nur a/src/github.com/buger/elastigo/cookbooks/golang/metadata.rb b/src/github.com/buger/elastigo/cookbooks/golang/metadata.rb
--- a/src/github.com/buger/elastigo/cookbooks/golang/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/golang/metadata.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,10 @@
+maintainer        "Matthew Baird"
+maintainer_email  "mattbaird@gmail.com"
+license           "Apache 2.0"
+description       "Installs go language from duh's Ubuntu PPA"
+long_description  IO.read(File.join(File.dirname(__FILE__), 'README.md'))
+version           "1.0.0"
+recipe            "golang", "Installs go"
+
+depends "apt"
+supports "ubuntu"
diff -Nur a/src/github.com/buger/elastigo/cookbooks/golang/recipes/default.rb b/src/github.com/buger/elastigo/cookbooks/golang/recipes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/golang/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/golang/recipes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,35 @@
+#
+# Cookbook Name:: golang
+# Recipe:: default
+#
+# Copyright 2012, Michael S. Klishin, Travis CI Development Team
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+include_recipe "golang::ppa"
+#    echo 'export GOBIN=#{node['golang']['gobin']}' >> /home/vagrant/.bash_golang
+#    echo 'export GOROOT=/usr/local/go/' >> /home/vagrant/.bash_golang
+
+bash "Export ENV Vars" do
+  code <<-EOC
+    mkdir -p /home/vagrant/code/go/
+    chown vagrant /home/vagrant/code/go/
+    echo 'export GOPATH=/home/vagrant/code/go/' >> /home/vagrant/.bash_golang
+    echo 'export GOROOT=/usr/lib/go/' >> /home/vagrant/.bash_golang
+    echo 'export PATH=$PATH:$GOBIN' >> /home/vagrant/.bash_golang
+    echo 'source /home/vagrant/.bash_golang' >> /home/vagrant/.bashrc
+    source /home/vagrant/.bashrc
+  EOC
+  creates "/home/vagrant/.bash_golang"
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/golang/recipes/ppa.rb b/src/github.com/buger/elastigo/cookbooks/golang/recipes/ppa.rb
--- a/src/github.com/buger/elastigo/cookbooks/golang/recipes/ppa.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/golang/recipes/ppa.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,33 @@
+#
+# Cookbook Name:: golang
+# Recipe:: ppa
+#
+# Copyright 2012, Michael S. Klishin, Travis CI Development Team
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+apt_repository "duh-ppa" do
+  uri          "http://ppa.launchpad.net/duh/golang/ubuntu"
+  distribution node['lsb']['codename']
+  components   ["main"]
+  key          "60480472"
+  keyserver    "keyserver.ubuntu.com"
+  action :add
+  notifies :run, "execute[apt-get update]", :immediately
+end
+
+package "golang" do
+#  version "1.1.1"
+  action :install
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/CHANGELOG.md b/src/github.com/buger/elastigo/cookbooks/mercurial/CHANGELOG.md
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/CHANGELOG.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/CHANGELOG.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+## v1.0.0:
+
+* [COOK-1373] - README example correction
+* [COOK-1179] - LWRP for repo management
+
+For further discussion about possible changes to the LWRP, see
+COOK-879, whereby it may become a fully fledged provider for chef's
+built in scm_repo resource.
+
+## v0.7.1:
+
+* Current public release
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/CONTRIBUTING b/src/github.com/buger/elastigo/cookbooks/mercurial/CONTRIBUTING
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/CONTRIBUTING	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/CONTRIBUTING	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,29 @@
+If you would like to contribute, please open a ticket in JIRA:
+
+* http://tickets.opscode.com
+
+Create the ticket in the COOK project and use the cookbook name as the
+component.
+
+For all code contributions, we ask that contributors sign a
+contributor license agreement (CLA). Instructions may be found here:
+
+* http://wiki.opscode.com/display/chef/How+to+Contribute
+
+When contributing changes to individual cookbooks, please do not
+modify the version number in the metadata.rb. Also please do not
+update the CHANGELOG.md for a new version. Not all changes to a
+cookbook may be merged and released in the same versions. Opscode will
+handle the version updates during the release process. You are welcome
+to correct typos or otherwise make updates to documentation in the
+README.
+
+If a contribution adds new platforms or platform versions, indicate
+such in the body of the commit message(s), and update the relevant
+COOK ticket. When writing commit messages, it is helpful for others if
+you indicate the COOK ticket. For example:
+
+    git commit -m '[COOK-1041] Updated pool resource to correctly delete.'
+
+In the ticket itself, it is also helpful if you include log output of
+a successful Chef run, but this is not absolutely required.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/LICENSE b/src/github.com/buger/elastigo/cookbooks/mercurial/LICENSE
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/LICENSE	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,201 @@
+                              Apache License
+                        Version 2.0, January 2004
+                     http://www.apache.org/licenses/
+
+TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+1. Definitions.
+
+   "License" shall mean the terms and conditions for use, reproduction,
+   and distribution as defined by Sections 1 through 9 of this document.
+
+   "Licensor" shall mean the copyright owner or entity authorized by
+   the copyright owner that is granting the License.
+
+   "Legal Entity" shall mean the union of the acting entity and all
+   other entities that control, are controlled by, or are under common
+   control with that entity. For the purposes of this definition,
+   "control" means (i) the power, direct or indirect, to cause the
+   direction or management of such entity, whether by contract or
+   otherwise, or (ii) ownership of fifty percent (50%) or more of the
+   outstanding shares, or (iii) beneficial ownership of such entity.
+
+   "You" (or "Your") shall mean an individual or Legal Entity
+   exercising permissions granted by this License.
+
+   "Source" form shall mean the preferred form for making modifications,
+   including but not limited to software source code, documentation
+   source, and configuration files.
+
+   "Object" form shall mean any form resulting from mechanical
+   transformation or translation of a Source form, including but
+   not limited to compiled object code, generated documentation,
+   and conversions to other media types.
+
+   "Work" shall mean the work of authorship, whether in Source or
+   Object form, made available under the License, as indicated by a
+   copyright notice that is included in or attached to the work
+   (an example is provided in the Appendix below).
+
+   "Derivative Works" shall mean any work, whether in Source or Object
+   form, that is based on (or derived from) the Work and for which the
+   editorial revisions, annotations, elaborations, or other modifications
+   represent, as a whole, an original work of authorship. For the purposes
+   of this License, Derivative Works shall not include works that remain
+   separable from, or merely link (or bind by name) to the interfaces of,
+   the Work and Derivative Works thereof.
+
+   "Contribution" shall mean any work of authorship, including
+   the original version of the Work and any modifications or additions
+   to that Work or Derivative Works thereof, that is intentionally
+   submitted to Licensor for inclusion in the Work by the copyright owner
+   or by an individual or Legal Entity authorized to submit on behalf of
+   the copyright owner. For the purposes of this definition, "submitted"
+   means any form of electronic, verbal, or written communication sent
+   to the Licensor or its representatives, including but not limited to
+   communication on electronic mailing lists, source code control systems,
+   and issue tracking systems that are managed by, or on behalf of, the
+   Licensor for the purpose of discussing and improving the Work, but
+   excluding communication that is conspicuously marked or otherwise
+   designated in writing by the copyright owner as "Not a Contribution."
+
+   "Contributor" shall mean Licensor and any individual or Legal Entity
+   on behalf of whom a Contribution has been received by Licensor and
+   subsequently incorporated within the Work.
+
+2. Grant of Copyright License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   copyright license to reproduce, prepare Derivative Works of,
+   publicly display, publicly perform, sublicense, and distribute the
+   Work and such Derivative Works in Source or Object form.
+
+3. Grant of Patent License. Subject to the terms and conditions of
+   this License, each Contributor hereby grants to You a perpetual,
+   worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+   (except as stated in this section) patent license to make, have made,
+   use, offer to sell, sell, import, and otherwise transfer the Work,
+   where such license applies only to those patent claims licensable
+   by such Contributor that are necessarily infringed by their
+   Contribution(s) alone or by combination of their Contribution(s)
+   with the Work to which such Contribution(s) was submitted. If You
+   institute patent litigation against any entity (including a
+   cross-claim or counterclaim in a lawsuit) alleging that the Work
+   or a Contribution incorporated within the Work constitutes direct
+   or contributory patent infringement, then any patent licenses
+   granted to You under this License for that Work shall terminate
+   as of the date such litigation is filed.
+
+4. Redistribution. You may reproduce and distribute copies of the
+   Work or Derivative Works thereof in any medium, with or without
+   modifications, and in Source or Object form, provided that You
+   meet the following conditions:
+
+   (a) You must give any other recipients of the Work or
+       Derivative Works a copy of this License; and
+
+   (b) You must cause any modified files to carry prominent notices
+       stating that You changed the files; and
+
+   (c) You must retain, in the Source form of any Derivative Works
+       that You distribute, all copyright, patent, trademark, and
+       attribution notices from the Source form of the Work,
+       excluding those notices that do not pertain to any part of
+       the Derivative Works; and
+
+   (d) If the Work includes a "NOTICE" text file as part of its
+       distribution, then any Derivative Works that You distribute must
+       include a readable copy of the attribution notices contained
+       within such NOTICE file, excluding those notices that do not
+       pertain to any part of the Derivative Works, in at least one
+       of the following places: within a NOTICE text file distributed
+       as part of the Derivative Works; within the Source form or
+       documentation, if provided along with the Derivative Works; or,
+       within a display generated by the Derivative Works, if and
+       wherever such third-party notices normally appear. The contents
+       of the NOTICE file are for informational purposes only and
+       do not modify the License. You may add Your own attribution
+       notices within Derivative Works that You distribute, alongside
+       or as an addendum to the NOTICE text from the Work, provided
+       that such additional attribution notices cannot be construed
+       as modifying the License.
+
+   You may add Your own copyright statement to Your modifications and
+   may provide additional or different license terms and conditions
+   for use, reproduction, or distribution of Your modifications, or
+   for any such Derivative Works as a whole, provided Your use,
+   reproduction, and distribution of the Work otherwise complies with
+   the conditions stated in this License.
+
+5. Submission of Contributions. Unless You explicitly state otherwise,
+   any Contribution intentionally submitted for inclusion in the Work
+   by You to the Licensor shall be under the terms and conditions of
+   this License, without any additional terms or conditions.
+   Notwithstanding the above, nothing herein shall supersede or modify
+   the terms of any separate license agreement you may have executed
+   with Licensor regarding such Contributions.
+
+6. Trademarks. This License does not grant permission to use the trade
+   names, trademarks, service marks, or product names of the Licensor,
+   except as required for reasonable and customary use in describing the
+   origin of the Work and reproducing the content of the NOTICE file.
+
+7. Disclaimer of Warranty. Unless required by applicable law or
+   agreed to in writing, Licensor provides the Work (and each
+   Contributor provides its Contributions) on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+   implied, including, without limitation, any warranties or conditions
+   of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+   PARTICULAR PURPOSE. You are solely responsible for determining the
+   appropriateness of using or redistributing the Work and assume any
+   risks associated with Your exercise of permissions under this License.
+
+8. Limitation of Liability. In no event and under no legal theory,
+   whether in tort (including negligence), contract, or otherwise,
+   unless required by applicable law (such as deliberate and grossly
+   negligent acts) or agreed to in writing, shall any Contributor be
+   liable to You for damages, including any direct, indirect, special,
+   incidental, or consequential damages of any character arising as a
+   result of this License or out of the use or inability to use the
+   Work (including but not limited to damages for loss of goodwill,
+   work stoppage, computer failure or malfunction, or any and all
+   other commercial damages or losses), even if such Contributor
+   has been advised of the possibility of such damages.
+
+9. Accepting Warranty or Additional Liability. While redistributing
+   the Work or Derivative Works thereof, You may choose to offer,
+   and charge a fee for, acceptance of support, warranty, indemnity,
+   or other liability obligations and/or rights consistent with this
+   License. However, in accepting such obligations, You may act only
+   on Your own behalf and on Your sole responsibility, not on behalf
+   of any other Contributor, and only if You agree to indemnify,
+   defend, and hold each Contributor harmless for any liability
+   incurred by, or claims asserted against, such Contributor by reason
+   of your accepting any such warranty or additional liability.
+
+END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+   To apply the Apache License to your work, attach the following
+   boilerplate notice, with the fields enclosed by brackets "[]"
+   replaced with your own identifying information. (Don't include
+   the brackets!)  The text should be enclosed in the appropriate
+   comment syntax for the file format. We also recommend that a
+   file or class name and description of purpose be included on the
+   same "printed page" as the copyright notice for easier
+   identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/README.md b/src/github.com/buger/elastigo/cookbooks/mercurial/README.md
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/README.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,69 @@
+Description
+===========
+
+Installs mercurial
+
+Requirements
+============
+
+A package named "mercurial" must exist in the platform package
+management system.
+
+Usage
+=====
+
+Install mercurial to make sure it is available to check out code from
+mercurial repositories.
+
+Resource/Provider
+=================
+
+This cookbook includes LWRPs for managing: mercurial
+
+mercurial
+---------
+
+### Actions
+
+- :clone - this will simply issue a clone of the repository at the revision specified (default tip).
+- :sync -  this will issue a clone of the repository if there is nothing at the path specified, otherwise a pull and update will be issued to bring the directory up-to-date.
+
+### Parameter Attributes
+
+- `path` - **Name attribute** path where the repository is checked
+  out.
+- `repository` - Repository to check out
+- `reference` - Reference in the repository
+- `key` - a private key on disk to use, for private repositories, must
+  already exist.
+- `owner` - local user that the clone is run as
+- `group` - local group that the clone is run as
+- `mode` - permissions of the cloned repository
+
+### Example
+
+	mercurial "/home/site/checkouts/www" do
+      repository "ssh://hg@bitbucket.org/niallsco/chef-hg"
+      reference "tip"
+      key "/home/site/.ssh/keyname"
+      action :sync
+    end
+
+License and Author
+==================
+
+Author:: Joshua Timberman <joshua@opscode.com>
+
+Copyright:: 2009, Opscode, Inc
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/metadata.rb b/src/github.com/buger/elastigo/cookbooks/mercurial/metadata.rb
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/metadata.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/metadata.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,11 @@
+maintainer        "Opscode, Inc."
+maintainer_email  "cookbooks@opscode.com"
+license           "Apache 2.0"
+description       "Installs mercurial"
+version           "0.8.0"
+
+recipe "mercurial", "Installs mercurial"
+
+%w{ debian ubuntu }.each do |os|
+  supports os
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/providers/default.rb b/src/github.com/buger/elastigo/cookbooks/mercurial/providers/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/providers/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/providers/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,34 @@
+action :sync do
+  execute "sync repository #{new_resource.path}" do    
+    not_if "hg identify #{new_resource.path}"
+    command "hg clone -e 'ssh -i #{new_resource.key} -o StrictHostKeyChecking=no' #{new_resource.repository} #{new_resource.path}"
+  end
+  execute "pull changes #{new_resource.path}" do
+      command "cd #{new_resource.path} && hg pull -e 'ssh -i #{new_resource.key} -o StrictHostKeyChecking=no' #{new_resource.repository}"
+  end
+  execute "update #{new_resource.path}" do
+      command "cd #{new_resource.path} && hg update -r #{new_resource.reference}"
+  end
+  execute "sync update owner #{new_resource.path}" do
+    command "chown -R #{new_resource.owner}:#{new_resource.group} #{new_resource.path}"
+  end
+  execute "sync update permissions #{new_resource.path}" do
+    command "chmod -R #{new_resource.mode} #{new_resource.path}"
+  end
+end
+ 
+action :clone do
+  execute "clone repository #{new_resource.path}" do
+    not_if "hg identify #{new_resource.path}"
+    command "hg clone -e 'ssh -i #{new_resource.key} -o StrictHostKeyChecking=no' #{new_resource.repository} #{new_resource.path}"
+  end
+  if new_resource.reference
+      command "cd #{new_resource.path} && hg update -r #{new_resource.reference}"
+  end
+  execute "update owner #{new_resource.path}" do
+    command "chown -R #{new_resource.owner}:#{new_resource.group} #{new_resource.path}"
+  end
+  execute "update permissions #{new_resource.path}" do
+    command "chmod -R #{new_resource.mode} #{new_resource.path}"
+  end
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/recipes/default.rb b/src/github.com/buger/elastigo/cookbooks/mercurial/recipes/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/recipes/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/recipes/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,21 @@
+#
+# Cookbook Name:: mercurial
+# Recipe:: default
+#
+# Copyright 2009, Opscode, Inc.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+package "mercurial" do
+  action :upgrade
+end
diff -Nur a/src/github.com/buger/elastigo/cookbooks/mercurial/resources/default.rb b/src/github.com/buger/elastigo/cookbooks/mercurial/resources/default.rb
--- a/src/github.com/buger/elastigo/cookbooks/mercurial/resources/default.rb	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/cookbooks/mercurial/resources/default.rb	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,9 @@
+actions :sync, :clone
+
+attribute :path, :kind_of => String, :name_attribute => true
+attribute :repository, :kind_of => String
+attribute :reference, :kind_of => [Integer, String]
+attribute :key, :kind_of => String
+attribute :owner, :kind_of => String
+attribute :group, :kind_of => String
+attribute :mode, :kind_of => String, :default => '0775'
diff -Nur a/src/github.com/buger/elastigo/core/bulk.go b/src/github.com/buger/elastigo/core/bulk.go
--- a/src/github.com/buger/elastigo/core/bulk.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/bulk.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,468 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"bytes"
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"io"
+	//	"log"
+	"strconv"
+	"sync"
+	"time"
+)
+
+var (
+	// Max buffer size in bytes before flushing to elasticsearch
+	BulkMaxBuffer = 1048576
+	// Max number of Docs to hold in buffer before forcing flush
+	BulkMaxDocs = 100
+	// Max delay before forcing a flush to Elasticearch
+	BulkDelaySeconds = 5
+	// Keep a running total of errors seen, since it is in the background
+	BulkErrorCt uint64
+	// maximum wait shutdown seconds
+	MAX_SHUTDOWN_SECS = 5
+
+	// There is one Global Bulk Indexer for convenience
+	GlobalBulkIndexer *BulkIndexer
+)
+
+type ErrorBuffer struct {
+	Err error
+	Buf *bytes.Buffer
+}
+
+// There is one global bulk indexer available for convenience so the IndexBulk() function can be called.
+// However, the recommended usage is create your own BulkIndexer to allow for multiple seperate elasticsearch
+// servers/host connections.
+//    @maxConns is the max number of in flight http requests
+//    @done is a channel to cause the indexer to stop
+//
+//   done := make(chan bool)
+//   BulkIndexerGlobalRun(100, done)
+func BulkIndexerGlobalRun(maxConns int, done chan bool) {
+	if GlobalBulkIndexer == nil {
+		GlobalBulkIndexer = NewBulkIndexer(maxConns)
+		GlobalBulkIndexer.Run(done)
+	}
+}
+
+// A bulk indexer creates goroutines, and channels for connecting and sending data
+// to elasticsearch in bulk, using buffers.
+type BulkIndexer struct {
+
+	// We are creating a variable defining the func responsible for sending
+	// to allow a mock sendor for test purposes
+	BulkSender func(*bytes.Buffer) error
+	// Deprecated, for backwards compatibility
+	BulkSendor func(*bytes.Buffer) error
+
+	// If we encounter an error in sending, we are going to retry for this long
+	// before returning an error
+	// if 0 it will not retry
+	RetryForSeconds int
+
+	// channel for getting errors
+	ErrorChannel chan *ErrorBuffer
+
+	// channel for sending to background indexer
+	bulkChannel chan []byte
+
+	// shutdown channel
+	shutdownChan chan bool
+	// Channel to shutdown http send go-routines
+	httpDoneChan chan bool
+	// channel to shutdown timer
+	timerDoneChan chan bool
+	// channel to shutdown doc go-routines
+	docDoneChan chan bool
+
+	// Channel to send a complete byte.Buffer to the http sendor
+	sendBuf chan *bytes.Buffer
+	// byte buffer for docs that have been converted to bytes, but not yet sent
+	buf *bytes.Buffer
+	// Buffer for Max number of time before forcing flush
+	BufferDelayMax time.Duration
+	// Max buffer size in bytes before flushing to elasticsearch
+	BulkMaxBuffer int // 1048576
+	// Max number of Docs to hold in buffer before forcing flush
+	BulkMaxDocs int // 100
+
+	// Number of documents we have send through so far on this session
+	docCt int
+	// Max number of http connections in flight at one time
+	maxConns int
+	// If we are indexing enough docs per bufferdelaymax, we won't need to do time
+	// based eviction, else we do.
+	needsTimeBasedFlush bool
+	// Lock for document writes/operations
+	mu sync.Mutex
+	// Wait Group for the http sends
+	sendWg *sync.WaitGroup
+}
+
+func NewBulkIndexer(maxConns int) *BulkIndexer {
+	b := BulkIndexer{sendBuf: make(chan *bytes.Buffer, maxConns)}
+	b.needsTimeBasedFlush = true
+	b.buf = new(bytes.Buffer)
+	b.maxConns = maxConns
+	b.BulkMaxBuffer = BulkMaxBuffer
+	b.BulkMaxDocs = BulkMaxDocs
+	b.BufferDelayMax = time.Duration(BulkDelaySeconds) * time.Second
+	b.bulkChannel = make(chan []byte, 100)
+	b.sendWg = new(sync.WaitGroup)
+	b.docDoneChan = make(chan bool)
+	b.timerDoneChan = make(chan bool)
+	b.httpDoneChan = make(chan bool)
+	return &b
+}
+
+// A bulk indexer with more control over error handling
+//    @maxConns is the max number of in flight http requests
+//    @retrySeconds is # of seconds to wait before retrying falied requests
+//
+//   done := make(chan bool)
+//   BulkIndexerGlobalRun(100, done)
+func NewBulkIndexerErrors(maxConns, retrySeconds int) *BulkIndexer {
+	b := NewBulkIndexer(maxConns)
+	b.RetryForSeconds = retrySeconds
+	b.ErrorChannel = make(chan *ErrorBuffer, 20)
+	return b
+}
+
+// Starts this bulk Indexer running, this Run opens a go routine so is
+// Non blocking
+func (b *BulkIndexer) Run(done chan bool) {
+
+	go func() {
+		if b.BulkSender == nil {
+			b.BulkSender = BulkSend
+		}
+		// Backwards compatibility
+		b.BulkSendor = b.BulkSender
+		b.shutdownChan = done
+		b.startHttpSender()
+		b.startDocChannel()
+		b.startTimer()
+		<-b.shutdownChan
+		b.Flush()
+		b.shutdown()
+	}()
+}
+
+// Make a channel that will close when the given WaitGroup is done.
+func wgChan(wg *sync.WaitGroup) <-chan interface{} {
+	ch := make(chan interface{})
+	go func() {
+		wg.Wait()
+		close(ch)
+	}()
+	return ch
+}
+
+func (b *BulkIndexer) PendingDocuments() int {
+	return b.docCt
+}
+
+// Flush all current documents to ElasticSearch
+func (b *BulkIndexer) Flush() {
+	b.mu.Lock()
+	if b.docCt > 0 {
+		b.send(b.buf)
+	}
+	b.mu.Unlock()
+	for {
+		select {
+		case <-wgChan(b.sendWg):
+			// done
+			return
+		case <-time.After(time.Second * time.Duration(MAX_SHUTDOWN_SECS)):
+			// timeout!
+			return
+		}
+	}
+}
+
+func (b *BulkIndexer) startHttpSender() {
+
+	// this sends http requests to elasticsearch it uses maxConns to open up that
+	// many goroutines, each of which will synchronously call ElasticSearch
+	// in theory, the whole set will cause a backup all the way to IndexBulk if
+	// we have consumed all maxConns
+	for i := 0; i < b.maxConns; i++ {
+		go func() {
+			for {
+				select {
+				case buf := <-b.sendBuf:
+					b.sendWg.Add(1)
+					err := b.BulkSender(buf)
+
+					// Perhaps a b.FailureStrategy(err)  ??  with different types of strategies
+					//  1.  Retry, then panic
+					//  2.  Retry then return error and let runner decide
+					//  3.  Retry, then log to disk?   retry later?
+					if err != nil {
+						if b.RetryForSeconds > 0 {
+							time.Sleep(time.Second * time.Duration(b.RetryForSeconds))
+							err = b.BulkSender(buf)
+							if err == nil {
+								// Successfully re-sent with no error
+								b.sendWg.Done()
+								continue
+							}
+						}
+						if b.ErrorChannel != nil {
+							b.ErrorChannel <- &ErrorBuffer{err, buf}
+						}
+					}
+					b.sendWg.Done()
+				case <-b.httpDoneChan:
+					// shutdown this go routine
+					return
+				}
+
+			}
+		}()
+	}
+}
+
+// start a timer for checking back and forcing flush ever BulkDelaySeconds seconds
+// even if we haven't hit max messages/size
+func (b *BulkIndexer) startTimer() {
+	ticker := time.NewTicker(b.BufferDelayMax)
+	go func() {
+		for {
+			select {
+			case <-ticker.C:
+				b.mu.Lock()
+				// don't send unless last sendor was the time,
+				// otherwise an indication of other thresholds being hit
+				// where time isn't needed
+				if b.buf.Len() > 0 && b.needsTimeBasedFlush {
+					b.needsTimeBasedFlush = true
+					b.send(b.buf)
+				} else if b.buf.Len() > 0 {
+					b.needsTimeBasedFlush = true
+				}
+				b.mu.Unlock()
+			case <-b.timerDoneChan:
+				// shutdown this go routine
+				return
+			}
+
+		}
+	}()
+}
+
+func (b *BulkIndexer) startDocChannel() {
+	// This goroutine accepts incoming byte arrays from the IndexBulk function and
+	// writes to buffer
+	go func() {
+		for {
+			select {
+			case docBytes := <-b.bulkChannel:
+				b.mu.Lock()
+				b.docCt += 1
+				b.buf.Write(docBytes)
+				if b.buf.Len() >= b.BulkMaxBuffer || b.docCt >= b.BulkMaxDocs {
+					b.needsTimeBasedFlush = false
+					//log.Printf("Send due to size:  docs=%d  bufsize=%d", b.docCt, b.buf.Len())
+					b.send(b.buf)
+				}
+				b.mu.Unlock()
+			case <-b.docDoneChan:
+				// shutdown this go routine
+				return
+			}
+		}
+	}()
+}
+
+func (b *BulkIndexer) send(buf *bytes.Buffer) {
+	//b2 := *b.buf
+	b.sendBuf <- buf
+	b.buf = new(bytes.Buffer)
+	//	b.buf.Reset()
+	b.docCt = 0
+}
+
+func (b *BulkIndexer) shutdown() {
+	// This must be called After flush
+	b.docDoneChan <- true
+	b.timerDoneChan <- true
+	for i := 0; i < b.maxConns; i++ {
+		b.httpDoneChan <- true
+	}
+}
+
+// The index bulk API adds or updates a typed JSON document to a specific index, making it searchable.
+// it operates by buffering requests, and ocassionally flushing to elasticsearch
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func (b *BulkIndexer) Index(index string, _type string, id, ttl string, date *time.Time, data interface{}, refresh bool) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	by, err := WriteBulkBytes("index", index, _type, id, ttl, date, data, refresh)
+	if err != nil {
+		return err
+	}
+	b.bulkChannel <- by
+	return nil
+}
+
+func (b *BulkIndexer) Update(index string, _type string, id, ttl string, date *time.Time, data interface{}, refresh bool) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	by, err := WriteBulkBytes("update", index, _type, id, ttl, date, data, refresh)
+	if err != nil {
+		return err
+	}
+	b.bulkChannel <- by
+	return nil
+}
+
+// This does the actual send of a buffer, which has already been formatted
+// into bytes of ES formatted bulk data
+func BulkSend(buf *bytes.Buffer) error {
+	_, err := api.DoCommand("POST", "/_bulk", nil, buf)
+	if err != nil {
+		BulkErrorCt += 1
+		return err
+	}
+	return nil
+}
+
+// Given a set of arguments for index, type, id, data create a set of bytes that is formatted for bulkd index
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func WriteBulkBytes(op string, index string, _type string, id, ttl string, date *time.Time, data interface{}, refresh bool) ([]byte, error) {
+	// only index and update are currently supported
+	if op != "index" && op != "update" {
+		return nil, errors.New(fmt.Sprintf("Operation '%s' is not yet supported", op))
+	}
+
+	// First line
+	buf := bytes.Buffer{}
+	buf.WriteString(fmt.Sprintf(`{"%s":{"_index":"`, op))
+	buf.WriteString(index)
+	buf.WriteString(`","_type":"`)
+	buf.WriteString(_type)
+	buf.WriteString(`"`)
+	if len(id) > 0 {
+		buf.WriteString(`,"_id":"`)
+		buf.WriteString(id)
+		buf.WriteString(`"`)
+	}
+
+	if op == "update" {
+		buf.WriteString(`,"retry_on_conflict":3`)
+	}
+
+	if len(ttl) > 0 {
+		buf.WriteString(`,"ttl":"`)
+		buf.WriteString(ttl)
+		buf.WriteString(`"`)
+	}
+	if date != nil {
+		buf.WriteString(`,"_timestamp":"`)
+		buf.WriteString(strconv.FormatInt(date.UnixNano()/1e6, 10))
+		buf.WriteString(`"`)
+	}
+	if refresh {
+		buf.WriteString(`,"refresh":true`)
+	}
+	buf.WriteString(`}}`)
+	buf.WriteRune('\n')
+	//buf.WriteByte('\n')
+	switch v := data.(type) {
+	case *bytes.Buffer:
+		io.Copy(&buf, v)
+	case []byte:
+		buf.Write(v)
+	case string:
+		buf.WriteString(v)
+	default:
+		body, jsonErr := json.Marshal(data)
+		if jsonErr != nil {
+			return nil, jsonErr
+		}
+		buf.Write(body)
+	}
+	buf.WriteRune('\n')
+	return buf.Bytes(), nil
+}
+
+// The index bulk API adds or updates a typed JSON document to a specific index, making it searchable.
+// it operates by buffering requests, and ocassionally flushing to elasticsearch
+//
+// This uses the one Global Bulk Indexer, you can also create your own non-global indexers and use the
+// Index functions of that
+//
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func IndexBulk(index string, _type string, id string, date *time.Time, data interface{}, refresh bool) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("index", index, _type, id, "", date, data, refresh)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
+
+func UpdateBulk(index string, _type string, id string, date *time.Time, data interface{}, refresh bool) error {
+	//{ "update" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("update", index, _type, id, "", date, data, refresh)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
+
+// The index bulk API adds or updates a typed JSON document to a specific index, making it searchable.
+// it operates by buffering requests, and ocassionally flushing to elasticsearch.
+//
+// This uses the one Global Bulk Indexer, you can also create your own non-global indexers and use the
+// IndexTtl functions of that
+//
+// http://www.elasticsearch.org/guide/reference/api/bulk.html
+func IndexBulkTtl(index string, _type string, id, ttl string, date *time.Time, data interface{}, refresh bool) error {
+	//{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("index", index, _type, id, ttl, date, data, refresh)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
+
+func UpdateBulkTtl(index string, _type string, id, ttl string, date *time.Time, data interface{}, refresh bool) error {
+	//{ "update" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
+	if GlobalBulkIndexer == nil {
+		panic("Must have Global Bulk Indexer to use this Func")
+	}
+	by, err := WriteBulkBytes("update", index, _type, id, ttl, date, data, refresh)
+	if err != nil {
+		return err
+	}
+	GlobalBulkIndexer.bulkChannel <- by
+	return nil
+}
diff -Nur a/src/github.com/buger/elastigo/core/bulkUDP.go b/src/github.com/buger/elastigo/core/bulkUDP.go
--- a/src/github.com/buger/elastigo/core/bulkUDP.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/bulkUDP.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
diff -Nur a/src/github.com/buger/elastigo/core/bulk_test.go b/src/github.com/buger/elastigo/core/bulk_test.go
--- a/src/github.com/buger/elastigo/core/bulk_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/bulk_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,264 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"bytes"
+	"crypto/rand"
+	"encoding/json"
+	"flag"
+	"fmt"
+	"github.com/araddon/gou"
+	"github.com/bmizerany/assert"
+	"github.com/buger/elastigo/api"
+	"log"
+	"strconv"
+	"testing"
+	"time"
+)
+
+//  go test -bench=".*"
+//  go test -bench="Bulk"
+
+var (
+	buffers        = make([]*bytes.Buffer, 0)
+	totalBytesSent int
+	messageSets    int
+)
+
+func init() {
+	flag.Parse()
+	if testing.Verbose() {
+		gou.SetupLogging("debug")
+	}
+}
+
+// take two ints, compare, need to be within 5%
+func CloseInt(a, b int) bool {
+	c := float64(a) / float64(b)
+	if c >= .95 && c <= 1.05 {
+		return true
+	}
+	return false
+}
+
+func TestBulkIndexerBasic(t *testing.T) {
+	InitTests(true)
+	indexer := NewBulkIndexer(3)
+	indexer.BulkSender = func(buf *bytes.Buffer) error {
+		messageSets += 1
+		totalBytesSent += buf.Len()
+		buffers = append(buffers, buf)
+		//		log.Printf("buffer:%s", string(buf.Bytes()))
+		return BulkSend(buf)
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+
+	date := time.Unix(1257894000, 0)
+	data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0).Format(time.RFC1123Z)}
+
+	err := indexer.Index("users", "user", "1", "", &date, data, true)
+
+	WaitFor(func() bool {
+		return len(buffers) > 0
+	}, 5)
+	// part of request is url, so lets factor that in
+	//totalBytesSent = totalBytesSent - len(*eshost)
+	assert.T(t, len(buffers) == 1, fmt.Sprintf("Should have sent one operation but was %d", len(buffers)))
+	assert.T(t, BulkErrorCt == 0 && err == nil, fmt.Sprintf("Should not have any errors. BulkErroCt: %v, err:%v", BulkErrorCt, err))
+	expectedBytes := 166
+	assert.T(t, totalBytesSent == expectedBytes, fmt.Sprintf("Should have sent %v bytes but was %v", expectedBytes, totalBytesSent))
+
+	err = indexer.Index("users", "user", "2", "", nil, data, true)
+	<-time.After(time.Millisecond * 10) // we need to wait for doc to hit send channel
+	// this will test to ensure that Flush actually catches a doc
+	indexer.Flush()
+	totalBytesSent = totalBytesSent - len(*eshost)
+	assert.T(t, err == nil, fmt.Sprintf("Should have nil error  =%v", err))
+	assert.T(t, len(buffers) == 2, fmt.Sprintf("Should have another buffer ct=%d", len(buffers)))
+
+	assert.T(t, BulkErrorCt == 0, fmt.Sprintf("Should not have any errors %d", BulkErrorCt))
+	expectedBytes = 282 // with refresh
+	assert.T(t, CloseInt(totalBytesSent, expectedBytes), fmt.Sprintf("Should have sent %v bytes but was %v", expectedBytes, totalBytesSent))
+
+	done <- true
+}
+
+// currently broken in drone.io
+func XXXTestBulkUpdate(t *testing.T) {
+	InitTests(true)
+	api.Port = "9200"
+	indexer := NewBulkIndexer(3)
+	indexer.BulkSender = func(buf *bytes.Buffer) error {
+		messageSets += 1
+		totalBytesSent += buf.Len()
+		buffers = append(buffers, buf)
+		return BulkSend(buf)
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+
+	date := time.Unix(1257894000, 0)
+	user := map[string]interface{}{
+		"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0), "count": 1,
+	}
+
+	// Lets make sure the data is in the index ...
+	_, err := Index("users", "user", "5", nil, user)
+
+	// script and params
+	data := map[string]interface{}{
+		"script": "ctx._source.count += 2",
+	}
+	err = indexer.Update("users", "user", "5", "", &date, data, true)
+	// So here's the deal. Flushing does seem to work, you just have to give the
+	// channel a moment to recieve the message ...
+	//	<- time.After(time.Millisecond * 20)
+	//	indexer.Flush()
+	done <- true
+
+	WaitFor(func() bool {
+		return len(buffers) > 0
+	}, 5)
+
+	assert.T(t, BulkErrorCt == 0 && err == nil, fmt.Sprintf("Should not have any errors, bulkErrorCt:%v, err:%v", BulkErrorCt, err))
+
+	response, err := Get("users", "user", "5", nil)
+	assert.T(t, err == nil, fmt.Sprintf("Should not have any errors  %v", err))
+	newCount := response.Source.(map[string]interface{})["count"]
+	assert.T(t, newCount.(float64) == 3,
+		fmt.Sprintf("Should have update count: %#v ... %#v", response.Source.(map[string]interface{})["count"], response))
+}
+
+func TestBulkSmallBatch(t *testing.T) {
+	InitTests(true)
+
+	done := make(chan bool)
+
+	date := time.Unix(1257894000, 0)
+	data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0)}
+
+	// Now tests small batches
+	indexersm := NewBulkIndexer(1)
+	indexersm.BufferDelayMax = 100 * time.Millisecond
+	indexersm.BulkMaxDocs = 2
+	messageSets = 0
+	indexersm.BulkSender = func(buf *bytes.Buffer) error {
+		messageSets += 1
+		return BulkSend(buf)
+	}
+	indexersm.Run(done)
+	<-time.After(time.Millisecond * 20)
+
+	indexersm.Index("users", "user", "2", "", &date, data, true)
+	indexersm.Index("users", "user", "3", "", &date, data, true)
+	indexersm.Index("users", "user", "4", "", &date, data, true)
+	<-time.After(time.Millisecond * 200)
+	//	indexersm.Flush()
+	done <- true
+	assert.T(t, messageSets == 2, fmt.Sprintf("Should have sent 2 message sets %d", messageSets))
+
+}
+
+func XXXTestBulkErrors(t *testing.T) {
+	// lets set a bad port, and hope we get a connection refused error?
+	api.Port = "27845"
+	defer func() {
+		api.Port = "9200"
+	}()
+	BulkDelaySeconds = 1
+	indexer := NewBulkIndexerErrors(10, 1)
+	done := make(chan bool)
+	indexer.Run(done)
+	errorCt := 0
+	go func() {
+		for i := 0; i < 20; i++ {
+			date := time.Unix(1257894000, 0)
+			data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0)}
+			indexer.Index("users", "user", strconv.Itoa(i), "", &date, data, true)
+		}
+	}()
+	var errBuf *ErrorBuffer
+	for errBuf = range indexer.ErrorChannel {
+		errorCt++
+		break
+	}
+	if errBuf.Buf.Len() > 0 {
+		gou.Debug(errBuf.Err)
+	}
+	assert.T(t, errorCt > 0, fmt.Sprintf("ErrorCt should be > 0 %d", errorCt))
+	done <- true
+}
+
+/*
+BenchmarkBulkSend	18:33:00 bulk_test.go:131: Sent 1 messages in 0 sets totaling 0 bytes
+18:33:00 bulk_test.go:131: Sent 100 messages in 1 sets totaling 145889 bytes
+18:33:01 bulk_test.go:131: Sent 10000 messages in 100 sets totaling 14608888 bytes
+18:33:05 bulk_test.go:131: Sent 20000 messages in 99 sets totaling 14462790 bytes
+   20000	    234526 ns/op
+
+*/
+func BenchmarkBulkSend(b *testing.B) {
+	InitTests(true)
+	b.StartTimer()
+	totalBytes := 0
+	sets := 0
+	GlobalBulkIndexer.BulkSender = func(buf *bytes.Buffer) error {
+		totalBytes += buf.Len()
+		sets += 1
+		//log.Println("got bulk")
+		return BulkSend(buf)
+	}
+	for i := 0; i < b.N; i++ {
+		about := make([]byte, 1000)
+		rand.Read(about)
+		data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0), "about": about}
+		IndexBulk("users", "user", strconv.Itoa(i), nil, data, true)
+	}
+	log.Printf("Sent %d messages in %d sets totaling %d bytes \n", b.N, sets, totalBytes)
+	if BulkErrorCt != 0 {
+		b.Fail()
+	}
+}
+
+/*
+TODO:  this should be faster than above
+
+BenchmarkBulkSendBytes	18:33:05 bulk_test.go:169: Sent 1 messages in 0 sets totaling 0 bytes
+18:33:05 bulk_test.go:169: Sent 100 messages in 2 sets totaling 292299 bytes
+18:33:09 bulk_test.go:169: Sent 10000 messages in 99 sets totaling 14473800 bytes
+   10000	    373529 ns/op
+
+*/
+func BenchmarkBulkSendBytes(b *testing.B) {
+	InitTests(true)
+	about := make([]byte, 1000)
+	rand.Read(about)
+	data := map[string]interface{}{"name": "smurfs", "age": 22, "date": time.Unix(1257894000, 0), "about": about}
+	body, _ := json.Marshal(data)
+	b.StartTimer()
+	totalBytes := 0
+	sets := 0
+	GlobalBulkIndexer.BulkSender = func(buf *bytes.Buffer) error {
+		totalBytes += buf.Len()
+		sets += 1
+		return BulkSend(buf)
+	}
+	for i := 0; i < b.N; i++ {
+		IndexBulk("users", "user", strconv.Itoa(i), nil, body, true)
+	}
+	log.Printf("Sent %d messages in %d sets totaling %d bytes \n", b.N, sets, totalBytes)
+	if BulkErrorCt != 0 {
+		b.Fail()
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/core/count.go b/src/github.com/buger/elastigo/core/count.go
--- a/src/github.com/buger/elastigo/core/count.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/count.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,46 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+type CountResponse struct {
+	Count int        `json:"count"`
+	Shard api.Status `json:"_shards"`
+}
+
+// Count allows the caller to easily execute a query and get the number of matches for that query.
+// It can be executed across one or more indices and across one or more types.
+// The query can either be provided using a simple query string as a parameter,
+// or using the Query DSL defined within the request body.
+// http://www.elasticsearch.org/guide/reference/api/count.html
+func Count(index string, _type string, args map[string]interface{}) (CountResponse, error) {
+	var url string
+	var retval CountResponse
+	url = fmt.Sprintf("/%s/%s/_count", index, _type)
+	body, err := api.DoCommand("GET", url, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/core/delete.go b/src/github.com/buger/elastigo/core/delete.go
--- a/src/github.com/buger/elastigo/core/delete.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/delete.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,38 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// Delete API allows to delete a typed JSON document from a specific index based on its id.
+// http://www.elasticsearch.org/guide/reference/api/delete.html
+func Delete(index string, _type string, id string, args map[string]interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/%s/%s/%s", index, _type, id)
+	body, err := api.DoCommand("DELETE", url, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/core/deleteByQuery.go b/src/github.com/buger/elastigo/core/deleteByQuery.go
--- a/src/github.com/buger/elastigo/core/deleteByQuery.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/deleteByQuery.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,58 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// DeleteByQuery allows the caller to delete documents from one or more indices and one or more types based on a query.
+// The query can either be provided using a simple query string as a parameter, or using the Query DSL defined within
+// the request body.
+// see: http://www.elasticsearch.org/guide/reference/api/delete-by-query.html
+func DeleteByQuery(indices []string, types []string, args map[string]interface{}, query interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(indices) > 0 && len(types) > 0 {
+		url = fmt.Sprintf("/%s/%s/_query", strings.Join(indices, ","), strings.Join(types, ","))
+	} else if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_query", strings.Join(indices, ","))
+	}
+	body, err := api.DoCommand("DELETE", url, args, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func buildQuery() string {
+	return ""
+}
+
+type DeleteByQueryResponse struct {
+	Status   bool                   `json:"ok"`
+	Indicies map[string]IndexStatus `json:"_indices"`
+}
+
+type IndexStatus struct {
+	Shards api.Status `json:"_shards"`
+}
diff -Nur a/src/github.com/buger/elastigo/core/example_test.go b/src/github.com/buger/elastigo/core/example_test.go
--- a/src/github.com/buger/elastigo/core/example_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/example_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,106 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core_test
+
+import (
+	"bytes"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"github.com/buger/elastigo/core"
+	"strconv"
+	"time"
+)
+
+// The simplest usage of background bulk indexing
+func ExampleBulkIndexer_simple() {
+	indexer := core.NewBulkIndexerErrors(10, 60)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	indexer.Index("twitter", "user", "1", "", nil, `{"name":"bob"}`, true)
+
+	<-done // wait forever
+}
+
+// The simplest usage of background bulk indexing with error channel
+func ExampleBulkIndexer_errorchannel() {
+	indexer := core.NewBulkIndexerErrors(10, 60)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	go func() {
+		for errBuf := range indexer.ErrorChannel {
+			// just blissfully print errors forever
+			fmt.Println(errBuf.Err)
+		}
+	}()
+	for i := 0; i < 20; i++ {
+		indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`, true)
+	}
+	done <- true
+}
+
+// The simplest usage of background bulk indexing with error channel
+func ExampleBulkIndexer_errorsmarter() {
+	indexer := core.NewBulkIndexerErrors(10, 60)
+	done := make(chan bool)
+	indexer.Run(done)
+
+	errorCt := 0 // use sync.atomic or something if you need
+	timer := time.NewTicker(time.Minute * 3)
+	go func() {
+		for {
+			select {
+			case _ = <-timer.C:
+				if errorCt < 2 {
+					errorCt = 0
+				}
+			case _ = <-done:
+				return
+			}
+		}
+	}()
+
+	go func() {
+		for errBuf := range indexer.ErrorChannel {
+			errorCt++
+			fmt.Println(errBuf.Err)
+			// log to disk?  db?   ????  Panic
+		}
+	}()
+	for i := 0; i < 20; i++ {
+		indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`, true)
+	}
+	done <- true // send shutdown signal
+}
+
+// The inspecting the response
+func ExampleBulkIndexer_responses() {
+	indexer := core.NewBulkIndexer(10)
+	// Create a custom Sender Func, to allow inspection of response/error
+	indexer.BulkSender = func(buf *bytes.Buffer) error {
+		// @buf is the buffer of docs about to be written
+		respJson, err := api.DoCommand("POST", "/_bulk", nil, buf)
+		if err != nil {
+			// handle it better than this
+			fmt.Println(string(respJson))
+		}
+		return err
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+
+	for i := 0; i < 20; i++ {
+		indexer.Index("twitter", "user", strconv.Itoa(i), "", nil, `{"name":"bob"}`, true)
+	}
+	done <- true // send shutdown signal
+}
diff -Nur a/src/github.com/buger/elastigo/core/explain.go b/src/github.com/buger/elastigo/core/explain.go
--- a/src/github.com/buger/elastigo/core/explain.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/explain.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,44 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// Explain computes a score explanation for a query and a specific document.
+// This can give useful feedback whether a document matches or didn’t match a specific query.
+// This feature is available from version 0.19.9 and up.
+// see http://www.elasticsearch.org/guide/reference/api/explain.html
+func Explain(index string, _type string, id string, args map[string]interface{}, query string) (api.Match, error) {
+	var url string
+	var retval api.Match
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/_explain", index, _type)
+	} else {
+		url = fmt.Sprintf("/%s/_explain", index)
+	}
+	body, err := api.DoCommand("GET", url, args, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/core/get.go b/src/github.com/buger/elastigo/core/get.go
--- a/src/github.com/buger/elastigo/core/get.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/get.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,129 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"net/http"
+)
+
+// Get allows caller to get a typed JSON document from the index based on its id.
+// GET - retrieves the doc
+// HEAD - checks for existence of the doc
+// http://www.elasticsearch.org/guide/reference/api/get.html
+// TODO: make this implement an interface
+func get(index string, _type string, id string, args map[string]interface{}, source interface{}) (api.BaseResponse, error) {
+	var url string
+	retval := api.BaseResponse{Source: source}
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/%s", index, _type, id)
+	} else {
+		url = fmt.Sprintf("/%s/%s", index, id)
+	}
+	body, err := api.DoCommand("GET", url, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+// The get API allows to get a typed JSON document from the index based on its id.
+// GET - retrieves the doc
+// HEAD - checks for existence of the doc
+// http://www.elasticsearch.org/guide/reference/api/get.html
+// TODO: make this implement an interface
+func Get(index string, _type string, id string, args map[string]interface{}) (api.BaseResponse, error) {
+	return get(index, _type, id, args, nil)
+}
+
+// Same as Get but with custom source type.
+func GetCustom(index string, _type string, id string, args map[string]interface{}, source interface{}) (api.BaseResponse, error) {
+	return get(index, _type, id, args, source)
+}
+
+// GetSource retrieves the document by id and converts it to provided interface
+func GetSource(index string, _type string, id string, args map[string]interface{}, source interface{}) error {
+	url := fmt.Sprintf("/%s/%s/%s/_source", index, _type, id)
+	body, err := api.DoCommand("GET", url, args, nil)
+	if err == nil {
+		err = json.Unmarshal(body, &source)
+	}
+	return err
+}
+
+// Exists allows caller to check for the existance of a document using HEAD
+func Exists(index string, _type string, id string, args map[string]interface{}) (bool, error) {
+
+	var url string
+
+	query, err := api.QueryString(args)
+	if err != nil {
+		return false, err
+	}
+
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/%s?fields=_id", index, _type, id)
+	} else {
+		url = fmt.Sprintf("/%s/%s?fields=_id", index, id)
+	}
+
+	req, err := api.ElasticSearchRequest("HEAD", url, query)
+
+	if err != nil {
+		return false, err
+	}
+
+	httpStatusCode, _, err := req.Do(nil)
+
+	if err != nil {
+		return false, err
+	}
+	if httpStatusCode == http.StatusOK {
+		return true, err
+	}
+	return false, err
+}
+
+// ExistsIndex allows caller to check for the existance of an index or a type using HEAD
+func ExistsIndex(index string, _type string, args map[string]interface{}) (bool, error) {
+	var url string
+
+	query, err := api.QueryString(args)
+	if err != nil {
+		return false, err
+	}
+
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s", index, _type)
+	} else {
+		url = fmt.Sprintf("/%s", index)
+	}
+	req, err := api.ElasticSearchRequest("HEAD", url, query)
+	httpStatusCode, _, err := req.Do(nil)
+
+	if err != nil {
+		return false, err
+	}
+	if httpStatusCode == http.StatusOK {
+		return true, err
+	}
+	return false, err
+}
diff -Nur a/src/github.com/buger/elastigo/core/index.go b/src/github.com/buger/elastigo/core/index.go
--- a/src/github.com/buger/elastigo/core/index.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/index.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,142 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"log"
+	"net/url"
+	"strconv"
+
+	"github.com/buger/elastigo/api"
+)
+
+// VerboseLogging controls whether elastigo will log more information
+// about its actions. Set it to false for less logging.
+var VerboseLogging bool = true;
+
+// Index adds or updates a typed JSON document in a specific index, making it searchable, creating an index
+// if it did not exist.
+// if id is omited, op_type 'create' will be passed and http method will default to "POST"
+// _type is optional
+// id is optional
+// parentId is optional
+// version is optional
+// op_type is optional
+// routing is optional
+// timestamp is optional
+// ttl is optional
+// percolate is optional
+// timeout is optional
+// http://www.elasticsearch.org/guide/reference/api/index_.html
+func Index(index string, _type string, id string, args map[string]interface{}, data interface{}) (api.BaseResponse, error) {
+	return IndexWithParameters(index, _type, id, "", 0, "", "", "", 0, "", "", false, args, data)
+}
+
+// IndexWithParameters takes all the potential parameters available
+func IndexWithParameters(index string, _type string, id string, parentId string, version int, op_type string,
+	routing string, timestamp string, ttl int, percolate string, timeout string, refresh bool,
+	args map[string]interface{}, data interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url, err := GetIndexUrl(index, _type, id, parentId, version, op_type, routing, timestamp, ttl, percolate, timeout, refresh)
+	if err != nil {
+		return retval, err
+	}
+	var method string
+	if len(id) == 0 {
+		method = "POST"
+	} else {
+		method = "PUT"
+	}
+	if VerboseLogging {
+		log.Printf("about to :%v %v %s", url, args, data)
+	}
+	body, err := api.DoCommand(method, url, args, data)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func GetIndexUrl(index string, _type string, id string, parentId string, version int, op_type string,
+	routing string, timestamp string, ttl int, percolate string, timeout string, refresh bool) (retval string, e error) {
+
+	if len(index) == 0 {
+		return "", errors.New("index can not be blank")
+	}
+	var partialURL string
+	var values url.Values = url.Values{}
+	if len(_type) == 0 && len(id) > 0 {
+		e = errors.New("Can't specify id when _type is blank")
+		return
+	}
+	if len(_type) > 0 && len(id) > 0 {
+		partialURL = fmt.Sprintf("/%s/%s/%s", index, _type, id)
+	} else if len(_type) > 0 {
+		partialURL = fmt.Sprintf("/%s/%s", index, _type)
+	} else {
+		partialURL = fmt.Sprintf("/%s", index)
+	}
+	// A child document can be indexed by specifying it’s parent when indexing.
+	if len(parentId) > 0 {
+		values.Add("parent", parentId)
+	}
+	// versions start at 1, so if greater than 0
+	if version > 0 {
+		values.Add("version", strconv.Itoa(version))
+	}
+	if len(op_type) > 0 {
+		if len(id) == 0 {
+			//if id is omited, op_type defaults to 'create'
+			values.Add("op_type", "create")
+		} else {
+			values.Add("op_type", op_type)
+		}
+	}
+	if len(routing) > 0 {
+		values.Add("routing", routing)
+	}
+	// A document can be indexed with a timestamp associated with it.
+	// The timestamp value of a document can be set using the timestamp parameter.
+	if len(timestamp) > 0 {
+		values.Add("timestamp", timestamp)
+	}
+	// A document can be indexed with a ttl (time to live) associated with it. Expired documents
+	// will be expunged automatically.
+	if ttl > 0 {
+		values.Add("ttl", strconv.Itoa(ttl))
+	}
+	if len(percolate) > 0 {
+		values.Add("percolate", percolate)
+	}
+	// example 5m
+	if len(timeout) > 0 {
+		values.Add("timeout", timeout)
+	}
+
+	if refresh {
+		values.Add("refresh", "true")
+	}
+
+	partialURL += "?" + values.Encode()
+	return partialURL, nil
+}
diff -Nur a/src/github.com/buger/elastigo/core/mget.go b/src/github.com/buger/elastigo/core/mget.go
--- a/src/github.com/buger/elastigo/core/mget.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/mget.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,63 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// MGet allows the caller to get multiple documents based on an index, type (optional) and id (and possibly routing).
+// The response includes a docs array with all the fetched documents, each element similar in structure to a document
+// provided by the get API.
+// see http://www.elasticsearch.org/guide/reference/api/multi-get.html
+func MGet(index string, _type string, mgetRequest MGetRequestContainer, args map[string]interface{}) (MGetResponseContainer, error) {
+	var url string
+	var retval MGetResponseContainer
+	if len(index) <= 0 {
+		url = fmt.Sprintf("/_mget")
+	}
+	if len(_type) > 0 && len(index) > 0 {
+		url = fmt.Sprintf("/%s/%s/_mget", index, _type)
+	} else if len(index) > 0 {
+		url = fmt.Sprintf("/%s/_mget", index)
+	}
+	body, err := api.DoCommand("GET", url, args, mgetRequest)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type MGetRequestContainer struct {
+	Docs []MGetRequest `json:"docs"`
+}
+
+type MGetRequest struct {
+	Index  string   `json:"_index"`
+	Type   string   `json:"_type"`
+	ID     string   `json:"_id"`
+	IDS    []string `json:"_ids,omitempty"`
+	Fields []string `json:"fields,omitempty"`
+}
+
+type MGetResponseContainer struct {
+	Docs []api.BaseResponse `json:"docs"`
+}
diff -Nur a/src/github.com/buger/elastigo/core/moreLikeThis.go b/src/github.com/buger/elastigo/core/moreLikeThis.go
--- a/src/github.com/buger/elastigo/core/moreLikeThis.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/moreLikeThis.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,58 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// MoreLikeThis allows the caller to get documents that are “like” a specified document.
+// http://www.elasticsearch.org/guide/reference/api/more-like-this.html
+func MoreLikeThis(index string, _type string, id string, args map[string]interface{}, query MoreLikeThisQuery) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/%s/%s/%s/_mlt", index, _type, id)
+	body, err := api.DoCommand("GET", url, args, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type MoreLikeThisQuery struct {
+	MoreLikeThis MLT `json:"more_like_this"`
+}
+
+type MLT struct {
+	Fields              []string `json:"fields"`
+	LikeText            string   `json:"like_text"`
+	PercentTermsToMatch float32  `json:"percent_terms_to_match"`
+	MinTermFrequency    int      `json:"min_term_freq"`
+	MaxQueryTerms       int      `json:"max_query_terms"`
+	StopWords           []string `json:"stop_words"`
+	MinDocFrequency     int      `json:"min_doc_freq"`
+	MaxDocFrequency     int      `json:"max_doc_freq"`
+	MinWordLength       int      `json:"min_word_len"`
+	MaxWordLength       int      `json:"max_word_len"`
+	BoostTerms          int      `json:"boost_terms"`
+	Boost               float32  `json:"boost"`
+	Analyzer            string   `json:"analyzer"`
+}
diff -Nur a/src/github.com/buger/elastigo/core/msearch.go b/src/github.com/buger/elastigo/core/msearch.go
--- a/src/github.com/buger/elastigo/core/msearch.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/msearch.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
diff -Nur a/src/github.com/buger/elastigo/core/percolate.go b/src/github.com/buger/elastigo/core/percolate.go
--- a/src/github.com/buger/elastigo/core/percolate.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/percolate.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,60 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// RegisterPercolate allows the caller to register queries against an index, and then send percolate requests which include a doc, and
+// getting back the queries that match on that doc out of the set of registered queries.
+// Think of it as the reverse operation of indexing and then searching. Instead of sending docs, indexing them,
+// and then running queries. One sends queries, registers them, and then sends docs and finds out which queries
+// match that doc.
+// see http://www.elasticsearch.org/guide/reference/api/percolate.html
+func RegisterPercolate(index string, name string, args map[string]interface{}, query api.Query) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	url = fmt.Sprintf("/_percolator/%s/%s", index, name)
+	body, err := api.DoCommand("PUT", url, args, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func Percolate(index string, _type string, name string, args map[string]interface{}, doc string) (api.Match, error) {
+	var url string
+	var retval api.Match
+	url = fmt.Sprintf("/%s/%s/_percolate", index, _type)
+	body, err := api.DoCommand("GET", url, args, doc)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/core/search.go b/src/github.com/buger/elastigo/core/search.go
--- a/src/github.com/buger/elastigo/core/search.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/search.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,191 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strconv"
+	"strings"
+)
+
+var (
+	DebugRequests = false
+)
+
+// SearchRequest performs a very basic search on an index via the request URI API.
+//
+// params:
+//   @index:  the elasticsearch index
+//   @_type:  optional ("" if not used) search specific type in this index
+//   @args:   a map of URL parameters. Allows all the URI-request parameters allowed by ElasticSearch.
+//   @query:  this can be one of 3 types:
+//              1)  string value that is valid elasticsearch
+//              2)  io.Reader that can be set in body (also valid elasticsearch string syntax..)
+//              3)  other type marshalable to json (also valid elasticsearch json)
+//
+//   out, err := SearchRequest(true, "github", map[string]interface{} {"from" : 10}, qryType)
+//
+// http://www.elasticsearch.org/guide/reference/api/search/uri-request.html
+func SearchRequest(index string, _type string, args map[string]interface{}, query interface{}) (SearchResult, error) {
+	var uriVal string
+	var retval SearchResult
+	if len(_type) > 0 && _type != "*" {
+		uriVal = fmt.Sprintf("/%s/%s/_search", index, _type)
+	} else {
+		uriVal = fmt.Sprintf("/%s/_search", index)
+	}
+	body, err := api.DoCommand("POST", uriVal, args, query)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal([]byte(body), &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+// SearchUri performs the simplest possible query in url string
+// params:
+//   @index:  the elasticsearch index
+//   @_type:  optional ("" if not used) search specific type in this index
+//   @args: a map of URL parameters. Most important one is q
+//
+//   out, err := SearchUri("github","", map[string]interface{} { "q" : `user:kimchy`})
+//
+// produces a request like this:    host:9200/github/_search?q=user:kimchy"
+//
+// http://www.elasticsearch.org/guide/reference/api/search/uri-request.html
+func SearchUri(index, _type string, args map[string]interface{}) (SearchResult, error) {
+	var uriVal string
+	var retval SearchResult
+	if len(_type) > 0 && _type != "*" {
+		uriVal = fmt.Sprintf("/%s/%s/_search", index, _type)
+	} else {
+		uriVal = fmt.Sprintf("/%s/_search", index)
+	}
+	//log.Println(uriVal)
+	body, err := api.DoCommand("GET", uriVal, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal([]byte(body), &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+func Scroll(args map[string]interface{}, scroll_id string) (SearchResult, error) {
+	var url string
+	var retval SearchResult
+
+	if _, ok := args["scroll"]; !ok {
+		return retval, fmt.Errorf("Cannot call scroll without 'scroll' in arguments")
+	}
+
+	url = "/_search/scroll"
+
+	body, err := api.DoCommand("POST", url, args, scroll_id)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal([]byte(body), &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type SearchResult struct {
+	Took         int             `json:"took"`
+	TimedOut     bool            `json:"timed_out"`
+	ShardStatus  api.Status      `json:"_shards"`
+	Hits         Hits            `json:"hits"`
+	Facets       json.RawMessage `json:"facets,omitempty"` // structure varies on query
+	ScrollId     string          `json:"_scroll_id,omitempty"`
+	Aggregations json.RawMessage `json:"aggregations,omitempty"` // structure varies on query
+}
+
+func (s *SearchResult) String() string {
+	return fmt.Sprintf("<Results took=%v Timeout=%v hitct=%v />", s.Took, s.TimedOut, s.Hits.Total)
+}
+
+type Hits struct {
+	Total int `json:"total"`
+	//	MaxScore float32 `json:"max_score"`
+	Hits []Hit `json:"hits"`
+}
+
+func (h *Hits) Len() int {
+	return len(h.Hits)
+}
+
+type Hit struct {
+	Index       string           `json:"_index"`
+	Type        string           `json:"_type,omitempty"`
+	Id          string           `json:"_id"`
+	Score       Float32Nullable  `json:"_score,omitempty"` // Filters (no query) dont have score, so is null
+	Source      *json.RawMessage `json:"_source"`          // marshalling left to consumer
+	Fields      *json.RawMessage `json:"fields"`           // when a field arg is passed to ES, instead of _source it returns fields
+	Explanation *Explanation     `json:"_explanation,omitempty"`
+}
+
+type Explanation struct {
+	Value       float32        `json:"value"`
+	Description string         `json:"description"`
+	Details     []*Explanation `json:"details,omitempty"`
+}
+
+func (e *Explanation) String(indent string) string {
+	if len(e.Details) == 0 {
+		return fmt.Sprintf("%s>>>  %v = %s", indent, e.Value, strings.Replace(e.Description, "\n", "", -1))
+	} else {
+		detailStrs := make([]string, 0)
+		for _, detail := range e.Details {
+			detailStrs = append(detailStrs, fmt.Sprintf("%s", detail.String(indent+"| ")))
+		}
+		return fmt.Sprintf("%s%v = %s(\n%s\n%s)", indent, e.Value, strings.Replace(e.Description, "\n", "", -1), strings.Join(detailStrs, "\n"), indent)
+	}
+}
+
+// Elasticsearch returns some invalid (according to go) json, with floats having...
+//
+// json: cannot unmarshal null into Go value of type float32 (see last field.)
+//
+// "hits":{"total":6808,"max_score":null,
+//    "hits":[{"_index":"10user","_type":"user","_id":"751820","_score":null,
+type Float32Nullable float32
+
+func (i *Float32Nullable) UnmarshalJSON(data []byte) error {
+	if len(data) == 0 || string(data) == "null" {
+		return nil
+	}
+
+	if in, err := strconv.ParseFloat(string(data), 32); err != nil {
+		return err
+	} else {
+		*i = Float32Nullable(in)
+	}
+	return nil
+}
diff -Nur a/src/github.com/buger/elastigo/core/search_test.go b/src/github.com/buger/elastigo/core/search_test.go
--- a/src/github.com/buger/elastigo/core/search_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/search_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,52 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/bmizerany/assert"
+	"testing"
+)
+
+func TestSearchRequest(t *testing.T) {
+	qry := map[string]interface{}{
+		"query": map[string]interface{}{
+			"wildcard": map[string]string{"actor": "a*"},
+		},
+	}
+	var args map[string]interface{}
+	out, err := SearchRequest("github", "", args, qry)
+	//log.Println(out)
+	assert.T(t, &out != nil && err == nil, fmt.Sprintf("Should get docs"))
+	assert.T(t, out.Hits.Len() == 10, fmt.Sprintf("Should have 10 docs but was %v", out.Hits.Len()))
+	expectedHits := 621
+	assert.T(t, CloseInt(out.Hits.Total, expectedHits), fmt.Sprintf("Should have %v hits but was %v", expectedHits, out.Hits.Total))
+}
+
+func TestSearchResultToJSON(t *testing.T) {
+	qry := map[string]interface{}{
+		"query": map[string]interface{}{
+			"wildcard": map[string]string{"actor": "a*"},
+		},
+	}
+	var args map[string]interface{}
+	out, err := SearchRequest("github", "", args, qry)
+
+	if err != nil {
+		t.Error(err)
+	}
+	_, err = json.Marshal(out.Hits.Hits)
+	if err != nil {
+		t.Error(err)
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/core/test_test.go b/src/github.com/buger/elastigo/core/test_test.go
--- a/src/github.com/buger/elastigo/core/test_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/test_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,190 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"bufio"
+	"bytes"
+	"compress/gzip"
+	"crypto/md5"
+	"encoding/json"
+	"flag"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"io"
+	"log"
+	"net/http"
+	"os"
+	"testing"
+	"time"
+)
+
+/*
+
+usage:
+
+	test -v -host eshost -loaddata
+
+*/
+
+var (
+	_                 = os.ModeDir
+	bulkStarted       bool
+	hasLoadedData     bool
+	hasStartedTesting bool
+	eshost            *string = flag.String("host", "localhost", "Elasticsearch Server Host Address")
+	loadData          *bool   = flag.Bool("loaddata", false, "This loads a bunch of test data into elasticsearch for testing")
+)
+
+func init() {
+
+}
+func InitTests(startIndexer bool) {
+	if !hasStartedTesting {
+		flag.Parse()
+		hasStartedTesting = true
+		log.SetFlags(log.Ltime | log.Lshortfile)
+		api.Domain = *eshost
+	}
+	if startIndexer && !bulkStarted {
+		BulkDelaySeconds = 1
+		bulkStarted = true
+		BulkIndexerGlobalRun(100, make(chan bool))
+		if *loadData && !hasLoadedData {
+			log.Println("loading test data ")
+			hasLoadedData = true
+			LoadTestData()
+		}
+	}
+}
+
+// dumb simple assert for testing, printing
+//    Assert(len(items) == 9, t, "Should be 9 but was %d", len(items))
+func Assert(is bool, t *testing.T, format string, args ...interface{}) {
+	if is == false {
+		log.Printf(format, args...)
+		t.Fail()
+	}
+}
+
+// Wait for condition (defined by func) to be true, a utility to create a ticker
+// checking every 100 ms to see if something (the supplied check func) is done
+//
+//   WaitFor(func() bool {
+//      return ctr.Ct == 0
+//   },10)
+//
+// @timeout (in seconds) is the last arg
+func WaitFor(check func() bool, timeoutSecs int) {
+	timer := time.NewTicker(100 * time.Millisecond)
+	tryct := 0
+	for _ = range timer.C {
+		if check() {
+			timer.Stop()
+			break
+		}
+		if tryct >= timeoutSecs*10 {
+			timer.Stop()
+			break
+		}
+		tryct++
+	}
+}
+
+func TestFake(t *testing.T) {
+
+}
+
+type GithubEvent struct {
+	Url     string
+	Created time.Time `json:"created_at"`
+	Type    string
+}
+
+// This loads test data from github archives (~6700 docs)
+func LoadTestData() {
+	docCt := 0
+	errCt := 0
+	indexer := NewBulkIndexer(1)
+	indexer.BulkSender = func(buf *bytes.Buffer) error {
+		//		log.Printf("Sent %d bytes total %d docs sent", buf.Len(), docCt)
+		req, err := api.ElasticSearchRequest("POST", "/_bulk", "")
+		if err != nil {
+			errCt += 1
+			log.Fatalf("ERROR: ", err)
+			return err
+		}
+		req.SetBody(buf)
+		//		res, err := http.DefaultClient.Do(*(api.Request(req)))
+		var response map[string]interface{}
+		httpStatusCode, _, err := req.Do(&response)
+		if err != nil {
+			errCt += 1
+			log.Fatalf("ERROR: %v", err)
+			return err
+		}
+		if httpStatusCode != 200 {
+			log.Fatalf("Not 200! %d \n", httpStatusCode)
+		}
+		return err
+	}
+	done := make(chan bool)
+	indexer.Run(done)
+	resp, err := http.Get("http://data.githubarchive.org/2012-12-10-15.json.gz")
+	if err != nil || resp == nil {
+		panic("Could not download data")
+	}
+	defer resp.Body.Close()
+	if err != nil {
+		log.Println(err)
+		return
+	}
+	gzReader, err := gzip.NewReader(resp.Body)
+	defer gzReader.Close()
+	if err != nil {
+		panic(err)
+	}
+	r := bufio.NewReader(gzReader)
+	var ge GithubEvent
+	docsm := make(map[string]bool)
+	h := md5.New()
+	for {
+		line, err := r.ReadBytes('\n')
+		if err != nil && err != io.EOF {
+			log.Println("FATAL:  could not read line? ", err)
+		} else if err != nil {
+			indexer.Flush()
+			break
+		}
+		if err := json.Unmarshal(line, &ge); err == nil {
+			// create an "ID"
+			h.Write(line)
+			id := fmt.Sprintf("%x", h.Sum(nil))
+			if _, ok := docsm[id]; ok {
+				log.Println("HM, already exists? ", ge.Url)
+			}
+			docsm[id] = true
+			indexer.Index("github", ge.Type, id, "", &ge.Created, line, true)
+			docCt++
+		} else {
+			log.Println("ERROR? ", string(line))
+		}
+	}
+	if errCt != 0 {
+		log.Println("FATAL, could not load ", errCt)
+	}
+	// lets wait a bit to ensure that elasticsearch finishes?
+	time.Sleep(time.Second * 5)
+	if len(docsm) != docCt {
+		panic(fmt.Sprintf("Docs didn't match?   %d:%d", len(docsm), docCt))
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/core/update.go b/src/github.com/buger/elastigo/core/update.go
--- a/src/github.com/buger/elastigo/core/update.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/update.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,95 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// Update updates a document based on a script provided. The operation gets the document
+// (collocated with the shard) from the index, runs the script (with optional script language and parameters),
+// and index back the result (also allows to delete, or ignore the operation). It uses versioning to make sure
+// no updates have happened during the “get” and “reindex”. (available from 0.19 onwards).
+// Note, this operation still means full reindex of the document, it just removes some network roundtrips
+// and reduces chances of version conflicts between the get and the index. The _source field need to be enabled
+// for this feature to work.
+//
+// http://www.elasticsearch.org/guide/reference/api/update.html
+// TODO: finish this, it's fairly complex
+func Update(index string, _type string, id string, args map[string]interface{}, data interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+
+	url = fmt.Sprintf("/%s/%s/%s/_update", index, _type, id)
+	body, err := api.DoCommand("POST", url, args, data)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+// UpdateWithPartialDoc updates a document based on partial document provided. The update API also
+// support passing a partial document (since 0.20), which will be merged into the existing
+// document (simple recursive merge, inner merging of objects, replacing core "keys/values" and arrays).
+// If both doc and script is specified, then doc is ignored. Best is to put your field pairs of the partial
+// document in the script itself.
+//
+// http://www.elasticsearch.org/guide/reference/api/update.html
+func UpdateWithPartialDoc(index string, _type string, id string, args map[string]interface{}, doc interface{}, upsert bool) (api.BaseResponse, error) {
+	switch v := doc.(type) {
+	case string:
+		upsertStr := ""
+		if upsert {
+			upsertStr = ", \"doc_as_upsert\":true"
+		}
+		content := fmt.Sprintf("{\"doc\":%s %s}", v, upsertStr)
+		return Update(index, _type, id, args, content)
+	}
+	var data map[string]interface{} = make(map[string]interface{})
+	data["doc"] = doc
+	if upsert {
+		data["doc_as_upsert"] = true
+	}
+	return Update(index, _type, id, args, data)
+}
+
+// UpdateWithScript updates a document based on a script provided.
+// The operation gets the document (collocated with the shard) from the index, runs the script
+// (with optional script language and parameters), and index back the result (also allows to
+// delete, or ignore the operation). It uses versioning to make sure no updates have happened
+// during the "get" and "reindex". (available from 0.19 onwards).
+//
+// Note, this operation still means full reindex of the document, it just removes some network
+// roundtrips and reduces chances of version conflicts between the get and the index. The _source
+// field need to be enabled for this feature to work.
+// http://www.elasticsearch.org/guide/reference/api/update.html
+func UpdateWithScript(index string, _type string, id string, args map[string]interface{}, script string, params interface{}) (api.BaseResponse, error) {
+	switch v := params.(type) {
+	case string:
+		paramsPart := fmt.Sprintf("{\"params\":%s}", v)
+		data := fmt.Sprintf("{\"script\":\"%s\", \"params\":%s}", script, paramsPart)
+		return Update(index, _type, id, args, data)
+	}
+	var data map[string]interface{} = make(map[string]interface{})
+	data["params"] = params
+	data["script"] = script
+	return Update(index, _type, id, args, data)
+}
diff -Nur a/src/github.com/buger/elastigo/core/validate.go b/src/github.com/buger/elastigo/core/validate.go
--- a/src/github.com/buger/elastigo/core/validate.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/core/validate.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,54 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package core
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// Validate allows a user to validate a potentially expensive query without executing it.
+// see http://www.elasticsearch.org/guide/reference/api/validate.html
+func Validate(index string, _type string, args map[string]interface{}) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(_type) > 0 {
+		url = fmt.Sprintf("/%s/%s/_validate/", index, _type)
+	} else {
+		url = fmt.Sprintf("/%s/_validate/", index)
+	}
+	body, err := api.DoCommand("GET", url, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type Validation struct {
+	Valid         bool           `json:"valid"`
+	Shards        api.Status     `json:"_shards"`
+	Explainations []Explaination `json:"explanations,omitempty"`
+}
+
+type Explaination struct {
+	Index string `json:"index"`
+	Valid bool   `json:"valid"`
+	Error string `json:"error"`
+}
diff -Nur a/src/github.com/buger/elastigo/doc.go b/src/github.com/buger/elastigo/doc.go
--- a/src/github.com/buger/elastigo/doc.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/doc.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,15 @@
+// Copyright 2012 Matthew Baird
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package main
diff -Nur a/src/github.com/buger/elastigo/indices/aliases.go b/src/github.com/buger/elastigo/indices/aliases.go
--- a/src/github.com/buger/elastigo/indices/aliases.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/aliases.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/analyze.go b/src/github.com/buger/elastigo/indices/analyze.go
--- a/src/github.com/buger/elastigo/indices/analyze.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/analyze.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,56 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"errors"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// AnalyzeIndices performs the analysis process on a text and return the tokens breakdown of the text.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-analyze/
+func AnalyzeIndices(index string, args map[string]interface{}) (AnalyzeResponse, error) {
+	var retval AnalyzeResponse
+	if len(args["text"].(string)) == 0 {
+		return retval, errors.New("text to analyze must not be blank")
+	}
+	var analyzeUrl string = "/_analyze"
+	if len(index) > 0 {
+		analyzeUrl = fmt.Sprintf("/%s/%s", index, analyzeUrl)
+	}
+
+	body, err := api.DoCommand("GET", analyzeUrl, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type AnalyzeResponse struct {
+	Tokens []Token `json:"tokens"`
+}
+type Token struct {
+	Name        string `json:"token"`
+	StartOffset int    `json:"start_offset"`
+	EndOffset   int    `json:"end_offset"`
+	Type        string `json:"type"`
+	Position    int    `json:"position"`
+}
diff -Nur a/src/github.com/buger/elastigo/indices/clearCache.go b/src/github.com/buger/elastigo/indices/clearCache.go
--- a/src/github.com/buger/elastigo/indices/clearCache.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/clearCache.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,45 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// ClearCache allows to clear either all caches or specific cached associated with one ore more indices.
+// see http://www.elasticsearch.org/guide/reference/api/admin-indices-clearcache/
+func ClearCache(clearId bool, clearBloom bool, args map[string]interface{}, indices ...string) (api.ExtendedStatus, error) {
+	var retval api.ExtendedStatus
+	var clearCacheUrl string
+	if len(indices) > 0 {
+		clearCacheUrl = fmt.Sprintf("/%s/_cache/clear", strings.Join(indices, ","))
+
+	} else {
+		clearCacheUrl = fmt.Sprintf("/_cache/clear")
+	}
+
+	body, err := api.DoCommand("POST", clearCacheUrl, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/indices/createIndex.go b/src/github.com/buger/elastigo/indices/createIndex.go
--- a/src/github.com/buger/elastigo/indices/createIndex.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/createIndex.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/deleteIndex.go b/src/github.com/buger/elastigo/indices/deleteIndex.go
--- a/src/github.com/buger/elastigo/indices/deleteIndex.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/deleteIndex.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,43 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+)
+
+// The delete API allows you to delete one or more indices through an API. This operation may fail
+// if the elasitsearch configuration has been set to forbid deleting indexes.
+func Delete(index string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+
+	if len(index) > 0 {
+		url = fmt.Sprintf("/%s", index)
+	} else {
+		return retval, fmt.Errorf("You must specify at least one index to delete")
+	}
+
+	body, err := api.DoCommand("DELETE", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+
+	jsonErr := json.Unmarshal(body, &retval)
+	if jsonErr != nil {
+		return retval, jsonErr
+	}
+
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/indices/deleteMapping.go b/src/github.com/buger/elastigo/indices/deleteMapping.go
--- a/src/github.com/buger/elastigo/indices/deleteMapping.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/deleteMapping.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/doc.go b/src/github.com/buger/elastigo/indices/doc.go
--- a/src/github.com/buger/elastigo/indices/doc.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/doc.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/flush.go b/src/github.com/buger/elastigo/indices/flush.go
--- a/src/github.com/buger/elastigo/indices/flush.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/flush.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,47 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// Flush flushes one or more indices through an API. The flush process of an index basically
+// frees memory from the index by flushing data to the index storage and clearing the internal transaction
+// log. By default, ElasticSearch uses memory heuristics in order to automatically trigger flush operations
+// as required in order to clear memory.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-flush.html
+// TODO: add Shards to response
+func Flush(indices ...string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_flush", strings.Join(indices, ","))
+	} else {
+		url = "/_flush"
+	}
+	body, err := api.DoCommand("POST", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/indices/getSettings.go b/src/github.com/buger/elastigo/indices/getSettings.go
--- a/src/github.com/buger/elastigo/indices/getSettings.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/getSettings.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/indicesExists.go b/src/github.com/buger/elastigo/indices/indicesExists.go
--- a/src/github.com/buger/elastigo/indices/indicesExists.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/indicesExists.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,37 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// IndicesExists checks for the existance of indices. uses http 404 if it does not exist, and 200 if it does
+// see http://www.elasticsearch.org/guide/reference/api/admin-indices-indices-exists/
+func IndicesExists(indices ...string) (bool, error) {
+	var url string
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s", strings.Join(indices, ","))
+	}
+	_, err := api.DoCommand("HEAD", url, nil, nil)
+	if err != nil {
+		eserror := err.(api.ESError)
+		if eserror.Code == 404 {
+			return false, err
+		} else {
+			return eserror.Code == 200, err
+		}
+	}
+	return true, nil
+}
diff -Nur a/src/github.com/buger/elastigo/indices/openCloseIndex.go b/src/github.com/buger/elastigo/indices/openCloseIndex.go
--- a/src/github.com/buger/elastigo/indices/openCloseIndex.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/openCloseIndex.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/optimize.go b/src/github.com/buger/elastigo/indices/optimize.go
--- a/src/github.com/buger/elastigo/indices/optimize.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/optimize.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,47 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// AnalyzeIndices performs the analysis process on a text and return the tokens breakdown of the text.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-analyze/
+func OptimizeIndices(args map[string]interface{}, indices ...string) (OptimizeResponse, error) {
+	var retval OptimizeResponse
+	var optimizeUrl string = "/_optimize"
+	if len(indices) > 0 {
+		optimizeUrl = fmt.Sprintf("/%s/%s", strings.Join(indices, ","), optimizeUrl)
+	}
+
+	body, err := api.DoCommand("POST", optimizeUrl, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
+
+type OptimizeResponse struct {
+	Ok     bool       `json:"ok"`
+	Shards api.Status `json:"_shards"`
+}
diff -Nur a/src/github.com/buger/elastigo/indices/putMapping.go b/src/github.com/buger/elastigo/indices/putMapping.go
--- a/src/github.com/buger/elastigo/indices/putMapping.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/putMapping.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,117 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	api "github.com/buger/elastigo/api"
+	"reflect"
+	"strings"
+)
+
+type Mapping map[string]MappingOptions
+
+type MappingOptions struct {
+	Id         IdOptions              `json:"_id"`
+	Timestamp  TimestampOptions       `json:"_timestamp"`
+	Properties map[string]interface{} `json:"properties"`
+}
+
+type TimestampOptions struct {
+	Enabled bool `json:"enabled"`
+}
+
+type IdOptions struct {
+	Index string `json:"index,omitempty"`
+	Path  string `json:"path,omitempty"`
+}
+
+func (m_ Mapping) Options() MappingOptions {
+	m := map[string]MappingOptions(m_)
+	for _, v := range m {
+		return v
+	}
+	panic(fmt.Errorf("Malformed input: %v", m_))
+}
+
+func MappingForType(typeName string, opts MappingOptions) Mapping {
+	return map[string]MappingOptions{typeName: opts}
+}
+
+func PutMapping(index string, typeName string, instance interface{}, opt MappingOptions) error {
+	instanceType := reflect.TypeOf(instance)
+	if instanceType.Kind() != reflect.Struct {
+		return fmt.Errorf("instance kind was not struct")
+	}
+
+	if opt.Properties == nil {
+		opt.Properties = make(map[string]interface{})
+	}
+	getProperties(instanceType, opt.Properties)
+	body, err := json.Marshal(MappingForType(typeName, opt))
+	if err != nil {
+		return err
+	}
+	_, err = api.DoCommand("PUT", fmt.Sprintf("/%s/%s/_mapping", index, typeName), nil, string(body))
+	if err != nil {
+		return err
+	}
+
+	return nil
+}
+
+func getProperties(t reflect.Type, prop map[string]interface{}) {
+	n := t.NumField()
+	for i := 0; i < n; i++ {
+		field := t.Field(i)
+
+		name := strings.Split(field.Tag.Get("json"), ",")[0]
+		if name == "-" {
+			continue
+		} else if name == "" {
+			name = field.Name
+		}
+
+		attrMap := make(map[string]string)
+		tag := field.Tag.Get("elastic")
+		if tag == "" {
+
+			// We are looking for tags on any nested struct, independently of
+			// whether the field is a struct, a pointer to struct, or a slice of structs
+			targetType := field.Type
+			if targetType.Kind() == reflect.Ptr ||
+				targetType.Kind() == reflect.Slice {
+				targetType = field.Type.Elem()
+			}
+
+			if targetType.Kind() == reflect.Struct {
+				if field.Anonymous {
+					getProperties(targetType, prop)
+				} else {
+					nestedProp := make(map[string]interface{})
+					getProperties(targetType, nestedProp)
+					prop[name] = map[string]interface{}{
+						"properties": nestedProp,
+					}
+				}
+			}
+			continue
+		}
+		attrs := strings.Split(tag, ",")
+		for _, attr := range attrs {
+			keyvalue := strings.Split(attr, ":")
+			attrMap[keyvalue[0]] = keyvalue[1]
+		}
+		prop[name] = attrMap
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/indices/putMapping_test.go b/src/github.com/buger/elastigo/indices/putMapping_test.go
--- a/src/github.com/buger/elastigo/indices/putMapping_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/putMapping_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,145 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	api "github.com/buger/elastigo/api"
+	"io/ioutil"
+	"net/http"
+	"net/http/httptest"
+	"net/url"
+	"strings"
+	"testing"
+)
+
+var (
+	mux    *http.ServeMux
+	server *httptest.Server
+)
+
+func setup(t *testing.T) {
+	mux = http.NewServeMux()
+	server = httptest.NewServer(mux)
+
+	serverURL, err := url.Parse(server.URL)
+	if err != nil {
+		t.Fatalf("Error: %v", err)
+	}
+
+	api.Domain = strings.Split(serverURL.Host, ":")[0]
+	api.Port = strings.Split(serverURL.Host, ":")[1]
+}
+
+func teardown() {
+	server.Close()
+}
+
+type TestStruct struct {
+	Id            string `json:"id" elastic:"index:not_analyzed"`
+	DontIndex     string `json:"dontIndex" elastic:"index:no"`
+	Number        int    `json:"number" elastic:"type:integer,index:analyzed"`
+	Omitted       string `json:"-"`
+	NoJson        string `elastic:"type:string"`
+	unexported    string
+	JsonOmitEmpty string `json:"jsonOmitEmpty,omitempty" elastic:"type:string"`
+	Embedded
+	Nested       NestedStruct   `json:"nested"`
+	NestedP      *NestedStruct  `json:"pointer_to_nested"`
+	NestedS      []NestedStruct `json:"slice_of_nested"`
+	MultiAnalyze string         `json:"multi_analyze"`
+}
+
+type Embedded struct {
+	EmbeddedField string `json:"embeddedField" elastic:"type:string"`
+}
+
+type NestedStruct struct {
+	NestedField string `json:"nestedField" elastic:"type:date"`
+}
+
+func TestPutMapping(t *testing.T) {
+	setup(t)
+	defer teardown()
+
+	options := MappingOptions{
+		Timestamp: TimestampOptions{Enabled: true},
+		Id:        IdOptions{Index: "analyzed", Path: "id"},
+		Properties: map[string]interface{}{
+			// special properties that can't be expressed as tags
+			"multi_analyze": map[string]interface{}{
+				"type": "multi_field",
+				"fields": map[string]map[string]string{
+					"ma_analyzed":   {"type": "string", "index": "analyzed"},
+					"ma_unanalyzed": {"type": "string", "index": "un_analyzed"},
+				},
+			},
+		},
+	}
+	expValue := MappingForType("myType", MappingOptions{
+		Timestamp: TimestampOptions{Enabled: true},
+		Id:        IdOptions{Index: "analyzed", Path: "id"},
+		Properties: map[string]interface{}{
+			"NoJson":        map[string]string{"type": "string"},
+			"dontIndex":     map[string]string{"index": "no"},
+			"embeddedField": map[string]string{"type": "string"},
+			"id":            map[string]string{"index": "not_analyzed"},
+			"jsonOmitEmpty": map[string]string{"type": "string"},
+			"number":        map[string]string{"index": "analyzed", "type": "integer"},
+			"multi_analyze": map[string]interface{}{
+				"type": "multi_field",
+				"fields": map[string]map[string]string{
+					"ma_analyzed":   {"type": "string", "index": "analyzed"},
+					"ma_unanalyzed": {"type": "string", "index": "un_analyzed"},
+				},
+			},
+			"nested": map[string]map[string]map[string]string{
+				"properties": {
+					"nestedField": {"type": "date"},
+				},
+			},
+			"pointer_to_nested": map[string]map[string]map[string]string{
+				"properties": {
+					"nestedField": {"type": "date"},
+				},
+			},
+			"slice_of_nested": map[string]map[string]map[string]string{
+				"properties": {
+					"nestedField": {"type": "date"},
+				},
+			},
+		},
+	})
+
+	mux.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
+		var value map[string]interface{}
+		bd, err := ioutil.ReadAll(r.Body)
+		json.NewDecoder(strings.NewReader(string(bd))).Decode(&value)
+		expValJson, err := json.MarshalIndent(expValue, "", "  ")
+		if err != nil {
+			t.Errorf("Got error: %v", err)
+		}
+		valJson, err := json.MarshalIndent(value, "", "  ")
+		if err != nil {
+			t.Errorf("Got error: %v", err)
+		}
+
+		if string(expValJson) != string(valJson) {
+			t.Errorf("Expected %s but got %s", string(expValJson), string(valJson))
+		}
+	})
+
+	err := PutMapping("myIndex", "myType", TestStruct{}, options)
+	if err != nil {
+		t.Errorf("Error: %v", err)
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/indices/refresh.go b/src/github.com/buger/elastigo/indices/refresh.go
--- a/src/github.com/buger/elastigo/indices/refresh.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/refresh.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,46 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// Refresh explicitly refreshes one or more index, making all operations performed since
+// the last refresh available for search. The (near) real-time capabilities depend on the index engine used.
+// For example, the robin one requires refresh to be called, but by default a refresh is scheduled periodically.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-refresh.html
+// TODO: add Shards to response
+func Refresh(indices ...string) (api.BaseResponse, error) {
+	var url string
+	var retval api.BaseResponse
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_refresh", strings.Join(indices, ","))
+	} else {
+		url = "/_refresh"
+	}
+	body, err := api.DoCommand("POST", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/indices/segments.go b/src/github.com/buger/elastigo/indices/segments.go
--- a/src/github.com/buger/elastigo/indices/segments.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/segments.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/snapshot.go b/src/github.com/buger/elastigo/indices/snapshot.go
--- a/src/github.com/buger/elastigo/indices/snapshot.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/snapshot.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,45 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// Snapshot  allows to explicitly perform a snapshot through the gateway of one or more indices (backup them).
+// By default, each index gateway periodically snapshot changes, though it can be disabled and be controlled completely through this API.
+// see http://www.elasticsearch.org/guide/reference/api/admin-indices-gateway-snapshot/
+func Snapshot(indices ...string) (api.ExtendedStatus, error) {
+	var retval api.ExtendedStatus
+	var url string
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_gateway/snapshot", strings.Join(indices, ","))
+
+	} else {
+		url = fmt.Sprintf("/_gateway/snapshot")
+	}
+	body, err := api.DoCommand("POST", url, nil, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/indices/stats.go b/src/github.com/buger/elastigo/indices/stats.go
--- a/src/github.com/buger/elastigo/indices/stats.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/stats.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/status.go b/src/github.com/buger/elastigo/indices/status.go
--- a/src/github.com/buger/elastigo/indices/status.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/status.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,44 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
+
+import (
+	"encoding/json"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"strings"
+)
+
+// Status lists status details of all indices or the specified index.
+// http://www.elasticsearch.org/guide/reference/api/admin-indices-status.html
+func Status(args map[string]interface{}, indices ...string) (api.BaseResponse, error) {
+	var retval api.BaseResponse
+	var url string
+	if len(indices) > 0 {
+		url = fmt.Sprintf("/%s/_status", strings.Join(indices, ","))
+
+	} else {
+		url = "/_status"
+	}
+	body, err := api.DoCommand("GET", url, args, nil)
+	if err != nil {
+		return retval, err
+	}
+	if err == nil {
+		// marshall into json
+		jsonErr := json.Unmarshal(body, &retval)
+		if jsonErr != nil {
+			return retval, jsonErr
+		}
+	}
+	return retval, err
+}
diff -Nur a/src/github.com/buger/elastigo/indices/templates.go b/src/github.com/buger/elastigo/indices/templates.go
--- a/src/github.com/buger/elastigo/indices/templates.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/templates.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/indices/updateSettings.go b/src/github.com/buger/elastigo/indices/updateSettings.go
--- a/src/github.com/buger/elastigo/indices/updateSettings.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/indices/updateSettings.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,12 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package indices
diff -Nur a/src/github.com/buger/elastigo/search/README b/src/github.com/buger/elastigo/search/README
--- a/src/github.com/buger/elastigo/search/README	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/README	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,4 @@
+
+
+To run tests on this, you must first have run/imported data inside of *core*
+
diff -Nur a/src/github.com/buger/elastigo/search/aggregate.go b/src/github.com/buger/elastigo/search/aggregate.go
--- a/src/github.com/buger/elastigo/search/aggregate.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/aggregate.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,218 @@
+package search
+
+import "encoding/json"
+
+func Aggregate(name string) *AggregateDsl {
+	return &AggregateDsl{Name: name}
+}
+
+type AggregateDsl struct {
+	Name          string
+	TypeName      string
+	Type          interface{}
+	Filters       *FilterWrap              `json:"filters,omitempty"`
+	AggregatesVal map[string]*AggregateDsl `json:"aggregations,omitempty"`
+}
+
+type FieldAggregate struct {
+	Field string `json:"field"`
+}
+
+/**
+ * Aggregates accepts n "sub-aggregates" to be applied to this aggregate
+ *
+ * agg := Aggregate("user").Term("user_id")
+ * agg.Aggregates(
+ *   Aggregate("total_spent").Sum("price"),
+ *   Aggregate("total_saved").Sum("discount"),
+ * )
+ */
+func (d *AggregateDsl) Aggregates(aggs ...*AggregateDsl) *AggregateDsl {
+	if len(aggs) < 1 {
+		return d
+	}
+	if len(d.AggregatesVal) == 0 {
+		d.AggregatesVal = make(map[string]*AggregateDsl)
+	}
+
+	for _, agg := range aggs {
+		d.AggregatesVal[agg.Name] = agg
+	}
+	return d
+}
+
+func (d *AggregateDsl) Min(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "min"
+	return d
+}
+
+func (d *AggregateDsl) Max(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "max"
+	return d
+}
+
+func (d *AggregateDsl) Sum(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "sum"
+	return d
+}
+
+func (d *AggregateDsl) Avg(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "avg"
+	return d
+}
+
+func (d *AggregateDsl) Stats(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "stats"
+	return d
+}
+
+func (d *AggregateDsl) ExtendedStats(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "extended_stats"
+	return d
+}
+
+func (d *AggregateDsl) ValueCount(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "value_count"
+	return d
+}
+
+func (d *AggregateDsl) Percentiles(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "percentiles"
+	return d
+}
+
+type Cardinality struct {
+	Field              string  `json:"field"`
+	PrecisionThreshold float64 `json:"precision_threshold,omitempty"`
+	Rehash             bool    `json:"rehash,omitempty"`
+}
+
+/**
+ * Cardinality(
+ *	 "field_name",
+ *	 true,
+ *   0,
+ * )
+ */
+func (d *AggregateDsl) Cardinality(field string, rehash bool, threshold int) *AggregateDsl {
+	c := Cardinality{Field: field}
+
+	// Only set if it's false, since the default is true
+	if !rehash {
+		c.Rehash = false
+	}
+
+	if threshold > 0 {
+		c.PrecisionThreshold = float64(threshold)
+	}
+	d.Type = c
+	d.TypeName = "cardinality"
+	return d
+}
+
+func (d *AggregateDsl) Global() *AggregateDsl {
+	d.Type = struct{}{}
+	d.TypeName = "global"
+	return d
+}
+
+func (d *AggregateDsl) Filter(filters ...interface{}) *AggregateDsl {
+
+	if len(filters) == 0 {
+		return d
+	}
+
+	if d.Filters == nil {
+		d.Filters = NewFilterWrap()
+	}
+
+	d.Filters.addFilters(filters)
+	return d
+}
+
+func (d *AggregateDsl) Missing(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "missing"
+	return d
+}
+
+func (d *AggregateDsl) Terms(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "terms"
+	return d
+}
+
+func (d *AggregateDsl) SignificantTerms(field string) *AggregateDsl {
+	d.Type = FieldAggregate{Field: field}
+	d.TypeName = "significant_terms"
+	return d
+}
+
+type Histogram struct {
+	Field    string  `json:"field"`
+	Interval float64 `json:"interval"`
+}
+
+func (d *AggregateDsl) Histogram(field string, interval int) *AggregateDsl {
+	d.Type = Histogram{
+		Field:    field,
+		Interval: float64(interval),
+	}
+	d.TypeName = "histogram"
+	return d
+}
+
+type DateHistogram struct {
+	Field    string `json:"field"`
+	Interval string `json:"interval"`
+}
+
+func (d *AggregateDsl) DateHistogram(field, interval string) *AggregateDsl {
+	d.Type = DateHistogram{
+		Field:    field,
+		Interval: interval,
+	}
+	d.TypeName = "date_histogram"
+	return d
+}
+
+func (d *AggregateDsl) MarshalJSON() ([]byte, error) {
+	return json.Marshal(d.toMap())
+}
+
+func (d *AggregateDsl) toMap() map[string]interface{} {
+	root := map[string]interface{}{}
+
+	if d.Type != nil {
+		root[d.TypeName] = d.Type
+	}
+	aggregates := d.aggregatesMap()
+
+	if d.Filters != nil {
+		root["filter"] = d.Filters
+	}
+
+	if len(aggregates) > 0 {
+		root["aggregations"] = aggregates
+	}
+	return root
+
+}
+func (d *AggregateDsl) aggregatesMap() map[string]interface{} {
+	root := map[string]interface{}{}
+
+	if len(d.AggregatesVal) > 0 {
+		for _, agg := range d.AggregatesVal {
+			root[agg.Name] = agg.toMap()
+		}
+	}
+	return root
+}
diff -Nur a/src/github.com/buger/elastigo/search/aggregate_test.go b/src/github.com/buger/elastigo/search/aggregate_test.go
--- a/src/github.com/buger/elastigo/search/aggregate_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/aggregate_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,172 @@
+package search
+
+import (
+	"encoding/json"
+	"reflect"
+	"testing"
+)
+
+// Test all aggregate types and nested aggregations
+func TestAggregateDsl(t *testing.T) {
+
+	min := Aggregate("min_price").Min("price")
+	max := Aggregate("max_price").Max("price")
+	sum := Aggregate("sum_price").Sum("price")
+	avg := Aggregate("avg_price").Avg("price")
+	stats := Aggregate("stats_price").Stats("price")
+	extendedStats := Aggregate("extended_stats_price").ExtendedStats("price")
+	valueCount := Aggregate("value_count_price").ValueCount("price")
+	percentiles := Aggregate("percentiles_price").Percentiles("price")
+	cardinality := Aggregate("cardinality_price").Cardinality("price", true, 50)
+	global := Aggregate("global").Global()
+	missing := Aggregate("missing_price").Missing("price")
+	terms := Aggregate("terms_price").Terms("price")
+	significantTerms := Aggregate("significant_terms_price").SignificantTerms("price")
+	histogram := Aggregate("histogram_price").Histogram("price", 50)
+
+	dateAgg := Aggregate("articles_over_time").DateHistogram("date", "month")
+	dateAgg.Aggregates(
+		min,
+		max,
+		sum,
+		avg,
+		stats,
+		extendedStats,
+		valueCount,
+		percentiles,
+		cardinality,
+		global,
+		missing,
+		terms,
+		significantTerms,
+		histogram,
+	)
+
+	qry := Search("github").Aggregates(dateAgg)
+
+	marshaled, err := json.MarshalIndent(qry.AggregatesVal, "", "  ")
+	if err != nil {
+		t.Errorf("Failed to marshal AggregatesVal: %s", err.Error())
+		return
+	}
+
+	assertJsonMatch(
+		t,
+		marshaled,
+		[]byte(`
+			{
+				"articles_over_time": {
+					"date_histogram" : {
+						"field" : "date",
+						"interval" : "month"
+					},
+					"aggregations": {
+						"min_price":{
+							"min": { "field": "price" }
+						},
+						"max_price":{
+							"max": { "field": "price" }
+						},
+						"sum_price":{
+							"sum": { "field": "price" }
+						},
+						"avg_price": {
+							"avg": { "field": "price" }
+						},
+						"stats_price":{
+							"stats": { "field": "price" }
+						},
+						"extended_stats_price":{
+							"extended_stats": { "field": "price" }
+						},
+						"value_count_price":{
+							"value_count": { "field": "price" }
+						},
+						"percentiles_price":{
+							"percentiles": { "field": "price" }
+						},
+						"cardinality_price":{
+							"cardinality": { "field": "price", "precision_threshold": 50 }
+						},
+						"global":{
+							"global": {}
+						},
+						"missing_price":{
+							"missing": { "field": "price" }
+						},
+						"terms_price":{
+							"terms": { "field": "price" }
+						},
+						"significant_terms_price":{
+							"significant_terms": { "field": "price" }
+						},
+						"histogram_price":{
+							"histogram": { "field": "price", "interval": 50 }
+						}
+					}
+				}
+			}
+	`),
+	)
+
+}
+
+func TestAggregateFilter(t *testing.T) {
+
+	avg := Aggregate("avg_price").Avg("price")
+
+	dateAgg := Aggregate("in_stock_products").Filter(
+		Range().Field("stock").Gt(0),
+	)
+
+	dateAgg.Aggregates(
+		avg,
+	)
+
+	qry := Search("github").Aggregates(dateAgg)
+
+	marshaled, err := json.MarshalIndent(qry.AggregatesVal, "", "  ")
+	if err != nil {
+		t.Errorf("Failed to marshal AggregatesVal: %s", err.Error())
+		return
+	}
+
+	assertJsonMatch(
+		t,
+		marshaled,
+		[]byte(`
+	{
+		"in_stock_products" : {
+			"filter" : {
+				"range" : { "stock" : { "gt" : 0 } }
+			},
+			"aggregations" : {
+				"avg_price" : { "avg" : { "field" : "price" } }
+			}
+		}
+	}
+	`),
+	)
+}
+
+func assertJsonMatch(t *testing.T, match, expected []byte) {
+	var m interface{}
+	var e interface{}
+
+	err := json.Unmarshal(expected, &e)
+	if err != nil {
+		t.Errorf("Failed to unmarshal expectation: %s", err.Error())
+		return
+	}
+	err = json.Unmarshal(match, &m)
+	if err != nil {
+		t.Errorf("Failed to unmarshal match: %s", err.Error())
+		return
+	}
+
+	if !reflect.DeepEqual(m, e) {
+		t.Errorf("Expected %s but got %s", string(expected), string(match))
+		return
+	}
+
+}
diff -Nur a/src/github.com/buger/elastigo/search/facet.go b/src/github.com/buger/elastigo/search/facet.go
--- a/src/github.com/buger/elastigo/search/facet.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/facet.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,142 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+
+	u "github.com/araddon/gou"
+)
+
+var (
+	_ = u.DEBUG
+)
+
+/*
+"facets": {
+    "terms": {
+		"terms": {
+			"field": [
+			  "@fields.category"
+			],
+			"size": 25
+		}
+    }
+}
+
+
+"facets": {
+  "actors": { "terms": {"field": ["actor"],"size": "10" }}
+  , "langauge": { "terms": {"field": ["repository.language"],"size": "10" }}
+}
+
+*/
+func Facet() *FacetDsl {
+	return &FacetDsl{}
+}
+
+func FacetRange(field string) *RangeDsl {
+	out := &RangeDsl{&RangeDef{}, nil}
+	out.RangeDef.Field = field
+	return out
+}
+
+type FacetDsl struct {
+	size   string
+	Terms  map[string]*Term     `json:"terms,omitempty"`
+	Ranges map[string]*RangeDsl `json:"terms,omitempty"`
+}
+
+type RangeDsl struct {
+	RangeDef  *RangeDef   `json:"range,omitempty"`
+	FilterVal *FilterWrap `json:"facet_filter,omitempty"`
+}
+
+type RangeDef struct {
+	Field  string      `json:"field,omitempty"`
+	Values []*RangeVal `json:"ranges,omitempty"`
+}
+
+type RangeVal struct {
+	From string `json:"from,omitempty"`
+	To   string `json:"to,omitempty"`
+}
+
+func (m *RangeDsl) Range(from, to string) *RangeDsl {
+	if len(m.RangeDef.Values) == 0 {
+		m.RangeDef.Values = make([]*RangeVal, 0)
+	}
+
+	m.RangeDef.Values = append(m.RangeDef.Values, &RangeVal{From: from, To: to})
+	return m
+}
+
+func (s *RangeDsl) Filter(fl ...interface{}) *RangeDsl {
+	if s.FilterVal == nil {
+		s.FilterVal = NewFilterWrap()
+	}
+
+	s.FilterVal.addFilters(fl)
+	return s
+}
+
+func (m *FacetDsl) Size(size string) *FacetDsl {
+	m.size = size
+	return m
+}
+
+func (m *FacetDsl) Fields(fields ...string) *FacetDsl {
+	if len(fields) < 1 {
+		return m
+	}
+	if len(m.Terms) == 0 {
+		m.Terms = make(map[string]*Term)
+	}
+	m.Terms[fields[0]] = &Term{Terms{Fields: fields}, nil}
+	return m
+}
+
+func (m *FacetDsl) Regex(field, match string) *FacetDsl {
+	if len(m.Terms) == 0 {
+		m.Terms = make(map[string]*Term)
+	}
+	m.Terms[field] = &Term{Terms{Fields: []string{field}, Regex: match}, nil}
+	return m
+}
+
+func (m *FacetDsl) Term(t *Term) *FacetDsl {
+	if len(m.Terms) == 0 {
+		m.Terms = make(map[string]*Term)
+	}
+	m.Terms[t.Terms.Fields[0]] = t
+	return m
+}
+
+func (m *FacetDsl) Range(r *RangeDsl) *FacetDsl {
+	if len(m.Ranges) == 0 {
+		m.Ranges = make(map[string]*RangeDsl)
+	}
+	m.Ranges[r.RangeDef.Field] = r
+	return m
+}
+
+func (m *FacetDsl) MarshalJSON() ([]byte, error) {
+	data := map[string]interface{}{}
+	for key, t := range m.Terms {
+		t.Terms.Size = m.size
+		data[key] = t
+	}
+	for key, r := range m.Ranges {
+		data[key] = r
+	}
+	return json.Marshal(&data)
+}
diff -Nur a/src/github.com/buger/elastigo/search/facet_test.go b/src/github.com/buger/elastigo/search/facet_test.go
--- a/src/github.com/buger/elastigo/search/facet_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/facet_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,38 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	//"encoding/json"
+	"fmt"
+	"github.com/araddon/gou"
+	"github.com/bmizerany/assert"
+	"testing"
+)
+
+func TestFacetRegex(t *testing.T) {
+	// This is a possible solution for auto-complete
+	out, _ := Search("github").Size("0").Facet(
+		Facet().Regex("repository.name", "no.*").Size("8"),
+	).Result()
+	if out == nil || &out.Hits == nil {
+		t.Fail()
+		return
+	}
+	//Debug(string(out.Facets))
+	fh := gou.NewJsonHelper([]byte(out.Facets))
+	facets := fh.Helpers("/repository.name/terms")
+	assert.T(t, len(facets) == 8, fmt.Sprintf("Should have 8? but was %v", len(facets)))
+	// for _, f := range facets {
+	// 	Debug(f)
+	// }
+}
diff -Nur a/src/github.com/buger/elastigo/search/filter.go b/src/github.com/buger/elastigo/search/filter.go
--- a/src/github.com/buger/elastigo/search/filter.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/filter.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,210 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+
+	. "github.com/araddon/gou"
+)
+
+var (
+	_ = DEBUG
+)
+
+// A bool (and/or) clause
+type BoolClause string
+
+// Filter clause is either a boolClause or FilterOp
+type FilterClause interface {
+	String() string
+}
+
+// A wrapper to allow for custom serialization
+type FilterWrap struct {
+	boolClause string
+	filters    []interface{}
+}
+
+func NewFilterWrap() *FilterWrap {
+	return &FilterWrap{filters: make([]interface{}, 0), boolClause: "and"}
+}
+
+func (f *FilterWrap) String() string {
+	return fmt.Sprintf(`fopv: %d:%v`, len(f.filters), f.filters)
+}
+
+// Custom marshalling to support the query dsl
+func (f *FilterWrap) addFilters(fl []interface{}) {
+	if len(fl) > 1 {
+		fc := fl[0]
+		switch fc.(type) {
+		case BoolClause, string:
+			f.boolClause = fc.(string)
+			fl = fl[1:]
+		}
+	}
+	f.filters = append(f.filters, fl...)
+}
+
+// Custom marshalling to support the query dsl
+func (f *FilterWrap) MarshalJSON() ([]byte, error) {
+	var root interface{}
+	if len(f.filters) > 1 {
+		root = map[string]interface{}{f.boolClause: f.filters}
+	} else if len(f.filters) == 1 {
+		root = f.filters[0]
+	}
+	return json.Marshal(root)
+}
+
+/*
+	"filter": {
+		"range": {
+		  "@timestamp": {
+		    "from": "2012-12-29T16:52:48+00:00",
+		    "to": "2012-12-29T17:52:48+00:00"
+		  }
+		}
+	}
+	"filter": {
+	    "missing": {
+	        "field": "repository.name"
+	    }
+	}
+
+	"filter" : {
+	    "terms" : {
+	        "user" : ["kimchy", "elasticsearch"],
+	        "execution" : "bool",
+	        "_cache": true
+	    }
+	}
+
+	"filter" : {
+	    "term" : { "user" : "kimchy"}
+	}
+
+	"filter" : {
+	    "and" : [
+	        {
+	            "range" : {
+	                "postDate" : {
+	                    "from" : "2010-03-01",
+	                    "to" : "2010-04-01"
+	                }
+	            }
+	        },
+	        {
+	            "prefix" : { "name.second" : "ba" }
+	        }
+	    ]
+	}
+
+*/
+
+// Filter Operation
+//
+//   Filter().Term("user","kimchy")
+//
+//   // we use variadics to allow n arguments, first is the "field" rest are values
+//   Filter().Terms("user", "kimchy", "elasticsearch")
+//
+//   Filter().Exists("repository.name")
+//
+func Filter() *FilterOp {
+	return &FilterOp{}
+}
+
+func CompoundFilter(fl ...interface{}) *FilterWrap {
+	FilterVal := NewFilterWrap()
+	FilterVal.addFilters(fl)
+	return FilterVal
+}
+
+type FilterOp struct {
+	curField    string
+	TermsMap    map[string][]interface{}          `json:"terms,omitempty"`
+	Range       map[string]map[string]interface{} `json:"range,omitempty"`
+	Exist       map[string]string                 `json:"exists,omitempty"`
+	MisssingVal map[string]string                 `json:"missing,omitempty"`
+}
+
+// A range is a special type of Filter operation
+//
+//    Range().Exists("repository.name")
+func Range() *FilterOp {
+	return &FilterOp{Range: make(map[string]map[string]interface{})}
+}
+
+func (f *FilterOp) Field(fld string) *FilterOp {
+	f.curField = fld
+	if _, ok := f.Range[fld]; !ok {
+		m := make(map[string]interface{})
+		f.Range[fld] = m
+	}
+	return f
+}
+
+// Filter Terms
+//
+//   Filter().Terms("user","kimchy")
+//
+//   // we use variadics to allow n arguments, first is the "field" rest are values
+//   Filter().Terms("user", "kimchy", "elasticsearch")
+//
+func (f *FilterOp) Terms(field string, values ...interface{}) *FilterOp {
+	if len(f.TermsMap) == 0 {
+		f.TermsMap = make(map[string][]interface{})
+	}
+	for _, val := range values {
+		f.TermsMap[field] = append(f.TermsMap[field], val)
+	}
+
+	return f
+}
+func (f *FilterOp) From(from string) *FilterOp {
+	f.Range[f.curField]["from"] = from
+	return f
+}
+func (f *FilterOp) To(to string) *FilterOp {
+	f.Range[f.curField]["to"] = to
+	return f
+}
+func (f *FilterOp) Gt(gt int) *FilterOp {
+	f.Range[f.curField]["gt"] = float64(gt)
+	return f
+}
+func (f *FilterOp) Exists(name string) *FilterOp {
+	f.Exist = map[string]string{"field": name}
+	return f
+}
+func (f *FilterOp) Missing(name string) *FilterOp {
+	f.MisssingVal = map[string]string{"field": name}
+	return f
+}
+
+// Add another Filterop, "combines" two filter ops into one
+func (f *FilterOp) Add(fop *FilterOp) *FilterOp {
+	// TODO, this is invalid, refactor
+	if len(fop.Exist) > 0 {
+		f.Exist = fop.Exist
+	}
+	if len(fop.MisssingVal) > 0 {
+		f.MisssingVal = fop.MisssingVal
+	}
+	if len(fop.Range) > 0 {
+		f.Range = fop.Range
+	}
+	return f
+}
diff -Nur a/src/github.com/buger/elastigo/search/filter_test.go b/src/github.com/buger/elastigo/search/filter_test.go
--- a/src/github.com/buger/elastigo/search/filter_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/filter_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,104 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"fmt"
+	//"github.com/araddon/gou"
+	"github.com/bmizerany/assert"
+	"testing"
+)
+
+func TestFilters(t *testing.T) {
+	// search for docs that are missing repository.name
+	qry := Search("github").Filter(
+		Filter().Exists("repository.name"),
+	)
+	out, err := qry.Result()
+	assert.T(t, err == nil, t, "should not have error")
+	expectedDocs := 10
+	expectedHits := 7695
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total got %v", expectedHits, out.Hits.Total))
+	qry = Search("github").Filter(
+		Filter().Missing("repository.name"),
+	)
+	expectedHits = 389
+	out, _ = qry.Result()
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total got %v", expectedHits, out.Hits.Total))
+
+	//actor_attributes: {type: "User",
+	qry = Search("github").Filter(
+		Filter().Terms("actor_attributes.location", "portland"),
+	)
+	out, _ = qry.Result()
+	expectedDocs = 10
+	expectedHits = 71
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total got %v", expectedHits, out.Hits.Total))
+
+	/*
+		Should this be an AND by default?
+	*/
+	qry = Search("github").Filter(
+		Filter().Terms("actor_attributes.location", "portland"),
+		Filter().Terms("repository.has_wiki", true),
+	)
+	out, err = qry.Result()
+	expectedDocs = 10
+	expectedHits = 44
+	assert.T(t, err == nil, t, "should not have error")
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total got %v", expectedHits, out.Hits.Total))
+
+	// NOW, lets try with two query calls instead of one
+	qry = Search("github").Filter(
+		Filter().Terms("actor_attributes.location", "portland"),
+	)
+	qry.Filter(
+		Filter().Terms("repository.has_wiki", true),
+	)
+	out, err = qry.Result()
+	//gou.Debug(out)
+	assert.T(t, err == nil, t, "should not have error")
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total got %v", expectedHits, out.Hits.Total))
+
+	qry = Search("github").Filter(
+		"or",
+		Filter().Terms("actor_attributes.location", "portland"),
+		Filter().Terms("repository.has_wiki", true),
+	)
+	out, err = qry.Result()
+	expectedHits = 6676
+	assert.T(t, err == nil, t, "should not have error")
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total got %v", expectedHits, out.Hits.Total))
+}
+
+func TestFilterRange(t *testing.T) {
+
+	// now lets filter range for repositories with more than 100 forks
+	out, _ := Search("github").Size("25").Filter(
+		Range().Field("repository.forks").From("100"),
+	).Result()
+	if out == nil || &out.Hits == nil {
+		t.Fail()
+		return
+	}
+	expectedDocs := 25
+	expectedHits := 725
+
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs got %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have total %v got %v", expectedHits, out.Hits.Total))
+}
diff -Nur a/src/github.com/buger/elastigo/search/query.go b/src/github.com/buger/elastigo/search/query.go
--- a/src/github.com/buger/elastigo/search/query.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/query.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,229 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+	//"log"
+	"strings"
+)
+
+// QueryDsl creates a new Query Dsl
+func Query() *QueryDsl {
+	return &QueryDsl{}
+}
+
+/*
+
+some ways to serialize
+"query": {
+	"filtered": {
+	  "query": {
+	    "query_string": {
+	      "default_operator": "OR",
+	      "default_field": "_all",
+	      "query": " actor:\"bob\"  AND type:\"EventType\""
+	    }
+	  },
+	  "filter": {
+	    "range": {
+	      "@timestamp": {
+	        "from": "2012-12-29T16:52:48+00:00",
+	        "to": "2012-12-29T17:52:48+00:00"
+	      }
+	    }
+	  }
+	}
+},
+
+"query" : {
+    "term" : { "user" : "kimchy" }
+}
+
+"query" : {
+    "match_all" : {}
+},
+*/
+type QueryDsl struct {
+	QueryEmbed
+	FilterVal *FilterOp `json:"filter,omitempty"`
+}
+
+// The core Query Syntax can be embedded as a child of a variety of different parents
+type QueryEmbed struct {
+	MatchAll *MatchAll         `json:"match_all,omitempty"`
+	Terms    map[string]string `json:"term,omitempty"`
+	Qs       *QueryString      `json:"query_string,omitempty"`
+	//Exist    string            `json:"_exists_,omitempty"`
+}
+
+// MarshalJSON provides custom marshalling to support the query dsl which is a conditional
+// json format, not always the same parent/children
+func (qd *QueryDsl) MarshalJSON() ([]byte, error) {
+	q := qd.QueryEmbed
+	hasQuery := false
+	if q.Qs != nil || len(q.Terms) > 0 || q.MatchAll != nil {
+		hasQuery = true
+	}
+	// If a query has a
+	if qd.FilterVal != nil && hasQuery {
+		queryB, err := json.Marshal(q)
+		if err != nil {
+			return queryB, err
+		}
+		filterB, err := json.Marshal(qd.FilterVal)
+		if err != nil {
+			return filterB, err
+		}
+		return []byte(fmt.Sprintf(`{"filtered":{"query":%s,"filter":%s}}`, queryB, filterB)), nil
+	}
+	return json.Marshal(q)
+}
+
+// get all
+func (q *QueryDsl) All() *QueryDsl {
+	q.MatchAll = &MatchAll{""}
+	return q
+}
+
+// Limit the query to this range
+func (q *QueryDsl) Range(fop *FilterOp) *QueryDsl {
+	if q.FilterVal == nil {
+		q.FilterVal = fop
+		return q
+	}
+	// TODO:  this is not valid, refactor
+	q.FilterVal.Add(fop)
+	return q
+}
+
+// Add a term search for a specific field
+//    Term("user","kimchy")
+func (q *QueryDsl) Term(name, value string) *QueryDsl {
+	if len(q.Terms) == 0 {
+		q.Terms = make(map[string]string)
+	}
+	q.Terms[name] = value
+	return q
+}
+
+// The raw search strings (lucene valid)
+func (q *QueryDsl) Search(searchFor string) *QueryDsl {
+	//I don't think this is right, it is not a filter.query, it should be q query?
+	qs := NewQueryString("", "")
+	q.QueryEmbed.Qs = &qs
+	q.QueryEmbed.Qs.Query = searchFor
+	return q
+}
+
+// Querystring operations
+func (q *QueryDsl) Qs(qs *QueryString) *QueryDsl {
+	q.QueryEmbed.Qs = qs
+	return q
+}
+
+// Fields in query_string search
+//     Fields("fieldname","search_for","","")
+//
+//     Fields("fieldname,field2,field3","search_for","","")
+//
+//     Fields("fieldname,field2,field3","search_for","field_exists","")
+func (q *QueryDsl) Fields(fields, search, exists, missing string) *QueryDsl {
+	fieldList := strings.Split(fields, ",")
+	qs := NewQueryString("", "")
+	q.QueryEmbed.Qs = &qs
+	q.QueryEmbed.Qs.Query = search
+	if len(fieldList) == 1 {
+		q.QueryEmbed.Qs.DefaultField = fields
+	} else {
+		q.QueryEmbed.Qs.Fields = fieldList
+	}
+	q.QueryEmbed.Qs.Exists = exists
+	q.QueryEmbed.Qs.Missing = missing
+	return q
+}
+
+// Filter this query
+func (q *QueryDsl) Filter(f *FilterOp) *QueryDsl {
+	q.FilterVal = f
+	return q
+}
+
+type MatchAll struct {
+	All string `json:"-"`
+}
+
+// should we reuse QueryDsl here?
+type QueryWrap struct {
+	Qs QueryString `json:"query_string,omitempty"`
+}
+
+// QueryString based search
+func NewQueryString(field, query string) QueryString {
+	return QueryString{"", field, query, "", "", nil}
+}
+
+type QueryString struct {
+	DefaultOperator string   `json:"default_operator,omitempty"`
+	DefaultField    string   `json:"default_field,omitempty"`
+	Query           string   `json:"query,omitempty"`
+	Exists          string   `json:"_exists_,omitempty"`
+	Missing         string   `json:"_missing_,omitempty"`
+	Fields          []string `json:"fields,omitempty"`
+	//_exists_:field1,
+	//_missing_:field1,
+}
+
+// Generic Term based (used in query, facet, filter)
+type Term struct {
+	Terms     Terms       `json:"terms,omitempty"`
+	FilterVal *FilterWrap `json:"facet_filter,omitempty"`
+}
+
+type Terms struct {
+	Fields []string `json:"field,omitempty"`
+	Size   string   `json:"size,omitempty"`
+	Regex  string   `json:"regex,omitempty"`
+}
+
+func NewTerm(fields ...string) *Term {
+	m := &Term{Terms{Fields: fields}, nil}
+	return m
+}
+
+func (s *Term) Filter(fl ...interface{}) *Term {
+	if s.FilterVal == nil {
+		s.FilterVal = NewFilterWrap()
+	}
+
+	s.FilterVal.addFilters(fl)
+	return s
+}
+
+// Custom marshalling
+func (t *Terms) MarshalJSON() ([]byte, error) {
+	m := make(map[string]interface{})
+	// TODO:  this isn't getting called!?
+	if len(t.Fields) == 1 {
+		m["field"] = t.Fields[0]
+	} else if len(t.Fields) > 1 {
+		m["fields"] = t.Fields
+	}
+	if len(t.Regex) > 0 {
+		m["regex"] = t.Regex
+	}
+	if len(t.Size) > 0 {
+		m["size"] = t.Size
+	}
+	return json.Marshal(m)
+}
diff -Nur a/src/github.com/buger/elastigo/search/search.go b/src/github.com/buger/elastigo/search/search.go
--- a/src/github.com/buger/elastigo/search/search.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/search.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,204 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+	u "github.com/araddon/gou"
+	"github.com/buger/elastigo/api"
+	"github.com/buger/elastigo/core"
+	"log"
+	"strconv"
+	"strings"
+)
+
+var (
+	_ = u.DEBUG
+)
+
+// Search is the entry point to the SearchDsl, it is a chainable set of utilities
+// to create searches.
+//
+// params
+//    @index = elasticsearch index to search
+//
+//    out, err := Search("github").Type("Issues").Pretty().Query(
+//    Query().Range(
+//         Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+//       ).Search("add"),
+//     ).Result()
+func Search(index string) *SearchDsl {
+	return &SearchDsl{Index: index, args: map[string]interface{}{}}
+}
+
+type SearchDsl struct {
+	args          map[string]interface{}
+	types         []string
+	FromVal       int                      `json:"from,omitempty"`
+	SizeVal       int                      `json:"size,omitempty"`
+	Index         string                   `json:"-"`
+	FacetVal      *FacetDsl                `json:"facets,omitempty"`
+	QueryVal      *QueryDsl                `json:"query,omitempty"`
+	SortBody      []*SortDsl               `json:"sort,omitempty"`
+	FilterVal     *FilterWrap              `json:"filter,omitempty"`
+	AggregatesVal map[string]*AggregateDsl `json:"aggregations,omitempty"`
+}
+
+func (s *SearchDsl) Bytes() ([]byte, error) {
+	return api.DoCommand("POST", s.url(), s.args, s)
+}
+
+func (s *SearchDsl) Result() (*core.SearchResult, error) {
+	var retval core.SearchResult
+	if core.DebugRequests {
+		sb, _ := json.MarshalIndent(s, "  ", "  ")
+		log.Println(s.url())
+		log.Println(string(sb))
+	}
+	body, err := s.Bytes()
+	if err != nil {
+		u.Errorf("%v", err)
+		return nil, err
+	}
+	jsonErr := json.Unmarshal(body, &retval)
+	if jsonErr != nil {
+		u.Errorf("%v \n\t%s", jsonErr, string(body))
+	}
+	//Debug(string(body))
+	return &retval, jsonErr
+}
+
+func (s *SearchDsl) url() string {
+	url := fmt.Sprintf("/%s%s/_search", s.Index, s.getType())
+	return url
+}
+
+func (s *SearchDsl) Pretty() *SearchDsl {
+	s.args["pretty"] = "1"
+	return s
+}
+
+// Type is the elasticsearch *Type* within a specific index
+func (s *SearchDsl) Type(indexType string) *SearchDsl {
+	if len(s.types) == 0 {
+		s.types = make([]string, 0)
+	}
+	s.types = append(s.types, indexType)
+	return s
+}
+
+func (s *SearchDsl) getType() string {
+	if len(s.types) > 0 {
+		return "/" + strings.Join(s.types, ",")
+	}
+	return ""
+}
+
+func (s *SearchDsl) From(from string) *SearchDsl {
+	s.args["from"] = from
+	return s
+}
+
+// Search is a simple interface to search, doesn't have the power of query
+// but uses a simple query_string search
+func (s *SearchDsl) Search(srch string) *SearchDsl {
+	s.QueryVal = Query().Search(srch)
+	return s
+}
+
+func (s *SearchDsl) Size(size string) *SearchDsl {
+	s.args["size"] = size
+	return s
+}
+
+func (s *SearchDsl) Fields(fields ...string) *SearchDsl {
+	s.args["fields"] = strings.Join(fields, ",")
+	return s
+}
+
+func (s *SearchDsl) Source(returnSource bool) *SearchDsl {
+	s.args["_source"] = strconv.FormatBool(returnSource)
+	return s
+}
+
+// Facet passes a Query expression to this search
+//
+//		qry := Search("github").Size("0").Facet(
+//					Facet().Regex("repository.name", "no.*").Size("8"),
+//				)
+//
+//		qry := Search("github").Pretty().Facet(
+//					Facet().Fields("type").Size("25"),
+//				)
+func (s *SearchDsl) Facet(f *FacetDsl) *SearchDsl {
+	s.FacetVal = f
+	return s
+}
+
+func (s *SearchDsl) Aggregates(aggs ...*AggregateDsl) *SearchDsl {
+	if len(aggs) < 1 {
+		return s
+	}
+	if len(s.AggregatesVal) == 0 {
+		s.AggregatesVal = make(map[string]*AggregateDsl)
+	}
+
+	for _, agg := range aggs {
+		s.AggregatesVal[agg.Name] = agg
+	}
+	return s
+}
+
+func (s *SearchDsl) Query(q *QueryDsl) *SearchDsl {
+	s.QueryVal = q
+	return s
+}
+
+// Filter adds a Filter Clause with optional Boolean Clause.  This accepts n number of
+// filter clauses.  If more than one, and missing Boolean Clause it assumes "and"
+//
+//     qry := Search("github").Filter(
+//         Filter().Exists("repository.name"),
+//     )
+//
+//     qry := Search("github").Filter(
+//         "or",
+//         Filter().Exists("repository.name"),
+//         Filter().Terms("actor_attributes.location", "portland"),
+//     )
+//
+//     qry := Search("github").Filter(
+//         Filter().Exists("repository.name"),
+//         Filter().Terms("repository.has_wiki", true)
+//     )
+func (s *SearchDsl) Filter(fl ...interface{}) *SearchDsl {
+	if s.FilterVal == nil {
+		s.FilterVal = NewFilterWrap()
+	}
+
+	s.FilterVal.addFilters(fl)
+	return s
+}
+
+func (s *SearchDsl) Sort(sort ...*SortDsl) *SearchDsl {
+	if s.SortBody == nil {
+		s.SortBody = make([]*SortDsl, 0)
+	}
+	s.SortBody = append(s.SortBody, sort...)
+	return s
+}
+
+func (s *SearchDsl) Scroll(duration string) *SearchDsl {
+	s.args["scroll"] = duration
+	return s
+}
diff -Nur a/src/github.com/buger/elastigo/search/search_test.go b/src/github.com/buger/elastigo/search/search_test.go
--- a/src/github.com/buger/elastigo/search/search_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/search_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,353 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"fmt"
+	"github.com/araddon/gou"
+	"github.com/bmizerany/assert"
+	"github.com/buger/elastigo/core"
+	"log"
+	"testing"
+)
+
+var (
+	_ = log.Ldate
+)
+
+func TestSearchRequest(t *testing.T) {
+	qry := map[string]interface{}{
+		"query": map[string]interface{}{
+			"wildcard": map[string]string{"actor": "a*"},
+		},
+	}
+	out, err := core.SearchRequest("github", "", nil, qry)
+	//log.Println(out)
+	assert.T(t, &out != nil && err == nil, t, "Should get docs")
+	expectedDocs := 10
+	expectedHits := 621
+	assert.T(t, out.Hits.Len() == expectedDocs, t, fmt.Sprintf("Should have %v docs but was %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, t, fmt.Sprintf("Should have %v hits but was %v", expectedHits, out.Hits.Total))
+}
+
+func TestSearchSimple(t *testing.T) {
+
+	// searching without faceting
+	qry := Search("github").Pretty().Query(
+		Query().Search("add"),
+	)
+	out, _ := qry.Result()
+	// how many different docs used the word "add"
+	expectedDocs := 10
+	expectedHits := 494
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total= %v", expectedHits, out.Hits.Total))
+
+	// now the same result from a "Simple" search
+	out, _ = Search("github").Search("add").Result()
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total= %v", expectedHits, out.Hits.Total))
+}
+
+func TestSearchRequestQueryString(t *testing.T) {
+	out, err := core.SearchUri("github", "", map[string]interface{}{"q": "actor:a*"})
+	expectedHits := 621
+	assert.T(t, &out != nil && err == nil, "Should get docs")
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v hits but was %v", expectedHits, out.Hits.Total))
+}
+
+func TestSearchFacetOne(t *testing.T) {
+	/*
+		A faceted search for what "type" of events there are
+		- since we are not specifying an elasticsearch type it searches all ()
+
+		{
+		    "terms" : {
+		      "_type" : "terms",
+		      "missing" : 0,
+		      "total" : 7561,
+		      "other" : 0,
+		      "terms" : [ {
+		        "term" : "pushevent",
+		        "count" : 4185
+		      }, {
+		        "term" : "createevent",
+		        "count" : 786
+		      }.....]
+		    }
+		 }
+
+	*/
+	qry := Search("github").Pretty().Facet(
+		Facet().Fields("type").Size("25"),
+	).Query(
+		Query().All(),
+	).Size("1")
+	out, err := qry.Result()
+	//log.Println(string(out.Facets))
+	//gou.Debug(out)
+	assert.T(t, out != nil && err == nil, "Should have output")
+	if out == nil {
+		t.Fail()
+		return
+	}
+	h := gou.NewJsonHelper(out.Facets)
+	expectedTotal := 8084
+	expectedTerms := 16
+	assert.T(t, h.Int("type.total") == expectedTotal, fmt.Sprintf("Should have %v results %v", expectedTotal, h.Int("type.total")))
+	assert.T(t, len(h.List("type.terms")) == expectedTerms, fmt.Sprintf("Should have %v event types, %v", expectedTerms, len(h.List("type.terms"))))
+
+	// Now, lets try changing size to 10
+	qry.FacetVal.Size("10")
+	out, err = qry.Result()
+	h = gou.NewJsonHelper(out.Facets)
+
+	// still same doc count
+	assert.T(t, h.Int("type.total") == expectedTotal, fmt.Sprintf("Should have %v results %v", expectedTotal, h.Int("type.total")))
+	// make sure size worked
+	expectedTerms = 10
+	assert.T(t, len(h.List("type.terms")) == expectedTerms, fmt.Sprintf("Should have %v event types, got %v", expectedTerms, len(h.List("type.terms"))))
+
+	// now, lets add a type (out of the 16)
+	out, _ = Search("github").Type("IssueCommentEvent").Pretty().Facet(
+		Facet().Fields("type").Size("25"),
+	).Query(
+		Query().All(),
+	).Result()
+	h = gou.NewJsonHelper(out.Facets)
+	//log.Println(string(out.Facets))
+	// still same doc count
+	expectedTotal = 685
+	assert.T(t, h.Int("type.total") == expectedTotal, fmt.Sprintf("Should have %v results %v", expectedTotal, h.Int("type.total")))
+	// we should only have one facettype because we limited to one type
+	assert.T(t, len(h.List("type.terms")) == 1, fmt.Sprintf("Should have 1 event types, %v", len(h.List("type.terms"))))
+
+	// now, add a second type (chained)
+	out, _ = Search("github").Type("IssueCommentEvent").Type("PushEvent").Pretty().Facet(
+		Facet().Fields("type").Size("25"),
+	).Query(
+		Query().All(),
+	).Result()
+	h = gou.NewJsonHelper(out.Facets)
+	// still same doc count
+	expectedTotal = 4941
+	expectedTerms = 2
+	assert.T(t, h.Int("type.total") == expectedTotal, fmt.Sprintf("Should have %v results %v", expectedTotal, h.Int("type.total")))
+	// make sure we now have 2 types
+	assert.T(t, len(h.List("type.terms")) == expectedTerms, fmt.Sprintf("Should have %v event types, %v", expectedTerms, len(h.List("type.terms"))))
+
+	//and instead of faceting on type, facet on userid
+	// now, add a second type (chained)
+	out, _ = Search("github").Type("IssueCommentEvent,PushEvent").Pretty().Facet(
+		Facet().Fields("actor").Size("500"),
+	).Query(
+		Query().All(),
+	).Result()
+	h = gou.NewJsonHelper(out.Facets)
+	// still same doc count
+	expectedTotal = 5168
+	expectedTerms = 500
+	assert.T(t, h.Int("actor.total") == expectedTotal, t, fmt.Sprintf("Should have %v results %v", expectedTotal, h.Int("actor.total")))
+	// make sure size worked
+	assert.T(t, len(h.List("actor.terms")) == expectedTerms, t, fmt.Sprintf("Should have %v users, %v", expectedTerms, len(h.List("actor.terms"))))
+
+}
+
+func TestSearchFacetRange(t *testing.T) {
+	// ok, now lets try facet but on actor field with a range
+	qry := Search("github").Pretty().Facet(
+		Facet().Fields("actor").Size("500"),
+	).Query(
+		Query().Search("add"),
+	)
+	out, err := qry.Result()
+	assert.T(t, out != nil && err == nil, t, "Should have output")
+
+	if out == nil {
+		t.Fail()
+		return
+	}
+	//log.Println(string(out.Facets))
+	h := gou.NewJsonHelper(out.Facets)
+	expectedActorTotal := 521
+	// how many different docs used the word "add", during entire time range
+	assert.T(t, h.Int("actor.total") == expectedActorTotal, fmt.Sprintf("Should have %v results %v", expectedActorTotal, h.Int("actor.total")))
+	// make sure size worked
+	expectedTerms := 366
+	assert.T(t, len(h.List("actor.terms")) == expectedTerms,
+		fmt.Sprintf("Should have %v unique userids, %v", expectedTerms, len(h.List("actor.terms"))))
+
+	// ok, repeat but with a range showing different results
+	qry = Search("github").Pretty().Facet(
+		Facet().Fields("actor").Size("500"),
+	).Query(
+		Query().Range(
+			Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+		).Search("add"),
+	)
+	out, err = qry.Result()
+	assert.T(t, out != nil && err == nil, t, "Should have output")
+
+	if out == nil {
+		t.Fail()
+		return
+	}
+	//log.Println(string(out.Facets))
+	h = gou.NewJsonHelper(out.Facets)
+	// how many different events used the word "add", during time range?
+	expectedActorTotal = 97
+	expectedTerms = 71
+	assert.T(t, h.Int("actor.total") == expectedActorTotal, fmt.Sprintf("Should have %v results %v", expectedActorTotal, h.Int("actor.total")))
+	// make sure size worked
+	assert.T(t, len(h.List("actor.terms")) == expectedTerms,
+		fmt.Sprintf("Should have %v event types, %v", expectedTerms, len(h.List("actor.terms"))))
+
+}
+
+func TestSearchTerm(t *testing.T) {
+
+	// ok, now lets try searching with term query (specific field/term)
+	qry := Search("github").Query(
+		Query().Term("repository.name", "jasmine"),
+	)
+	out, _ := qry.Result()
+	// how many different docs have jasmine in repository.name?
+	expectedDocs := 4
+	expectedHits := 4
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total= %v", expectedHits, out.Hits.Total))
+
+}
+
+func TestSearchFields(t *testing.T) {
+	// same as terms, search using fields:
+	//    how many different docs have jasmine in repository.name?
+	qry := Search("github").Query(
+		Query().Fields("repository.name", "jasmine", "", ""),
+	)
+	out, _ := qry.Result()
+	expectedDocs := 4
+	expectedHits := 4
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedHits, fmt.Sprintf("Should have %v total= %v", expectedHits, out.Hits.Total))
+}
+
+func TestSearchMissingExists(t *testing.T) {
+	// search for docs that are missing repository.name
+	qry := Search("github").Filter(
+		Filter().Exists("repository.name"),
+	)
+	out, _ := qry.Result()
+	expectedDocs := 10
+	expectedTotal := 7695
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedTotal, fmt.Sprintf("Should have %v total= %v", expectedTotal, out.Hits.Total))
+
+	qry = Search("github").Filter(
+		Filter().Missing("repository.name"),
+	)
+	out, _ = qry.Result()
+	expectedDocs = 10
+	expectedTotal = 389
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedTotal, fmt.Sprintf("Should have %v total= %v", expectedTotal, out.Hits.Total))
+}
+
+func TestSearchFilterQuery(t *testing.T) {
+
+	// compound query + filter with query being wildcard
+	out, _ := Search("github").Size("25").Query(
+		Query().Fields("repository.name", "jas*", "", ""),
+	).Filter(
+		Filter().Terms("repository.has_wiki", true),
+	).Result()
+	if out == nil || &out.Hits == nil {
+		t.Fail()
+		return
+	}
+
+	expectedDocs := 7
+	expectedTotal := 7
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedTotal, fmt.Sprintf("Should have %v total= %v", expectedTotal, out.Hits.Total))
+}
+
+func TestSearchRange(t *testing.T) {
+
+	// now lets filter by a subset of the total time
+	out, _ := Search("github").Size("25").Query(
+		Query().Range(
+			Range().Field("created_at").From("2012-12-10T15:00:00-08:00").To("2012-12-10T15:10:00-08:00"),
+		).Search("add"),
+	).Result()
+	assert.T(t, out != nil && &out.Hits != nil, "Must not have nil results, or hits")
+	assert.T(t, out.Hits.Len() == 25, fmt.Sprintf("Should have 25 docs %v", out.Hits.Len()))
+	assert.T(t, out.Hits.Total == 92, fmt.Sprintf("Should have total=92 but was %v", out.Hits.Total))
+}
+
+func TestSearchSortOrder(t *testing.T) {
+
+	// ok, now lets try sorting by repository watchers descending
+	qry := Search("github").Pretty().Query(
+		Query().All(),
+	).Sort(
+		Sort("repository.watchers").Desc(),
+	)
+	out, _ := qry.Result()
+
+	// how many different docs used the word "add", during entire time range
+	expectedDocs := 10
+	expectedTotal := 8084
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedTotal, fmt.Sprintf("Should have %v total= %v", expectedTotal, out.Hits.Total))
+	b, err := out.Hits.Hits[0].Source.MarshalJSON()
+	assert.T(t, err == nil, fmt.Sprintf("Should not have returned an error: %v", err))
+	h1 := gou.NewJsonHelper(b)
+	assert.T(t, h1.Int("repository.watchers") == 41377,
+		fmt.Sprintf("Should have 41377 watchers= %v", h1.Int("repository.watchers")))
+
+	// ascending
+	out, _ = Search("github").Pretty().Query(
+		Query().All(),
+	).Sort(
+		Sort("repository.watchers"),
+	).Result()
+	// how many different docs used the word "add", during entire time range
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedTotal, fmt.Sprintf("Should have %v total got %v", expectedTotal, out.Hits.Total))
+	b, err = out.Hits.Hits[0].Source.MarshalJSON()
+	assert.T(t, err == nil, fmt.Sprintf("Should not have returned an error: %v", err))
+	h2 := gou.NewJsonHelper(b)
+	assert.T(t, h2.Int("repository.watchers") == 0,
+		fmt.Sprintf("Should have 0 watchers= %v", h2.Int("repository.watchers")))
+
+	// sort descending with search
+	out, _ = Search("github").Pretty().Size("5").Query(
+		Query().Search("python"),
+	).Sort(
+		Sort("repository.watchers").Desc(),
+	).Result()
+	// how many different docs used the word "add", during entire time range
+	expectedDocs = 5
+	expectedTotal = 734
+
+	assert.T(t, out.Hits.Len() == expectedDocs, fmt.Sprintf("Should have %v docs %v", expectedDocs, out.Hits.Len()))
+	assert.T(t, out.Hits.Total == expectedTotal, fmt.Sprintf("Should have %v total got %v", expectedTotal, out.Hits.Total))
+
+	b, err = out.Hits.Hits[0].Source.MarshalJSON()
+	assert.T(t, err == nil, fmt.Sprintf("Should not have returned an error: %v", err))
+	h3 := gou.NewJsonHelper(b)
+	watchers := 8659
+	assert.T(t, h3.Int("repository.watchers") == watchers,
+		fmt.Sprintf("Should have %v watchers, got %v", watchers, h3.Int("repository.watchers")))
+
+}
diff -Nur a/src/github.com/buger/elastigo/search/sort.go b/src/github.com/buger/elastigo/search/sort.go
--- a/src/github.com/buger/elastigo/search/sort.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/sort.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,52 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"encoding/json"
+	"fmt"
+)
+
+// SortDsl accepts any number of Sort commands
+//
+//     Query().Sort(
+//         Sort("last_name").Desc(),
+//         Sort("age"),
+//     )
+func Sort(field string) *SortDsl {
+	return &SortDsl{Name: field}
+}
+
+type SortBody []interface{}
+type SortDsl struct {
+	Name   string
+	IsDesc bool
+}
+
+func (s *SortDsl) Desc() *SortDsl {
+	s.IsDesc = true
+	return s
+}
+func (s *SortDsl) Asc() *SortDsl {
+	s.IsDesc = false
+	return s
+}
+
+func (s *SortDsl) MarshalJSON() ([]byte, error) {
+	if s.IsDesc {
+		return json.Marshal(map[string]string{s.Name: "desc"})
+	}
+	if s.Name == "_score" {
+		return []byte(`"_score"`), nil
+	}
+	return []byte(fmt.Sprintf(`"%s"`, s.Name)), nil // "user"  assuming default = asc?
+}
diff -Nur a/src/github.com/buger/elastigo/search/test_test.go b/src/github.com/buger/elastigo/search/test_test.go
--- a/src/github.com/buger/elastigo/search/test_test.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/search/test_test.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,55 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package search
+
+import (
+	"flag"
+	"github.com/araddon/gou"
+	"github.com/buger/elastigo/api"
+	"github.com/buger/elastigo/core"
+	"log"
+	"os"
+	//"testing"
+)
+
+var (
+	_                 = log.Ldate
+	hasStartedTesting bool
+	eshost            *string = flag.String("host", "localhost", "Elasticsearch Server Host Address")
+	logLevel          *string = flag.String("logging", "info", "Which log level: [debug,info,warn,error,fatal]")
+)
+
+/*
+
+usage:
+
+	test -v -host eshost
+
+*/
+
+func init() {
+	InitTests(false)
+	if *logLevel == "debug" {
+		//*logLevel = "debug"
+		core.DebugRequests = true
+	}
+}
+
+func InitTests(startIndexer bool) {
+	if !hasStartedTesting {
+		flag.Parse()
+		hasStartedTesting = true
+		gou.SetLogger(log.New(os.Stderr, "", log.Ltime|log.Lshortfile), *logLevel)
+		log.SetFlags(log.Ltime | log.Lshortfile)
+		api.Domain = *eshost
+	}
+}
diff -Nur a/src/github.com/buger/elastigo/tutorial/README.md b/src/github.com/buger/elastigo/tutorial/README.md
--- a/src/github.com/buger/elastigo/tutorial/README.md	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/tutorial/README.md	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,11 @@
+
+
+Tutorials
+=======================================
+
+To run these tutorials::
+	
+
+	go run start_1.go
+
+	# etc
\ No newline at end of file
diff -Nur a/src/github.com/buger/elastigo/tutorial/start_1.go b/src/github.com/buger/elastigo/tutorial/start_1.go
--- a/src/github.com/buger/elastigo/tutorial/start_1.go	1970-01-01 01:00:00.000000000 +0100
+++ b/src/github.com/buger/elastigo/tutorial/start_1.go	2015-08-10 16:28:38.000000000 +0100
@@ -0,0 +1,71 @@
+// Copyright 2013 Matthew Baird
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//     http://www.apache.org/licenses/LICENSE-2.0
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package main
+
+import (
+	"flag"
+	"fmt"
+	"github.com/buger/elastigo/api"
+	"github.com/buger/elastigo/core"
+	"log"
+	"os"
+)
+
+var (
+	host *string = flag.String("host", "localhost", "Elasticsearch Host")
+)
+
+func main() {
+	core.DebugRequests = true
+	log.SetFlags(log.LstdFlags)
+	flag.Parse()
+
+	fmt.Println("host = ", *host)
+	// Set the Elasticsearch Host to Connect to
+	api.Domain = *host
+
+	// Index a document
+	_, err := core.Index("testindex", "user", "docid_1", nil, `{"name":"bob"}`)
+	exitIfErr(err)
+
+	// Index a doc using a map of values
+	_, err = core.Index("testindex", "user", "docid_2", nil, map[string]string{"name": "venkatesh"})
+	exitIfErr(err)
+
+	// Index a doc using Structs
+	_, err = core.Index("testindex", "user", "docid_3", nil, MyUser{"wanda", 22})
+	exitIfErr(err)
+
+	// Search Using Raw json String
+	searchJson := `{
+	    "query" : {
+	        "term" : { "Name" : "wanda" }
+	    }
+	}`
+	out, err := core.SearchRequest("testindex", "user", nil, searchJson)
+	if len(out.Hits.Hits) == 1 {
+		fmt.Println("%v", out.Hits.Hits[0].Source)
+	}
+	exitIfErr(err)
+
+}
+func exitIfErr(err error) {
+	if err != nil {
+		fmt.Fprintf(os.Stderr, "Error: %s\n", err.Error())
+		os.Exit(1)
+	}
+}
+
+type MyUser struct {
+	Name string
+	Age  int
+}
